# GEAK-OpenEvolve Configuration for Grouped FP8 GEMM Optimization
# This config is tailored for optimizing the grouped_gemm kernel

max_iterations: 20
checkpoint_interval: 5
log_level: "INFO"

# LLM configuration for Triton kernel optimization
llm:
  sampling: 
    fn: "random"
  models:
    # Configure your LLM provider here
    # Option 1: Claude (Anthropic)
    - name: "claude-sonnet-4.5"
      weight: 1.0
      api_base: https://llm-api.amd.com/claude3/deployments/claude-sonnet-4.5
      api_key: null  # Uses OPENAI_API_KEY from environment

  evaluator_models:
    - name: "claude-sonnet-4.5"
      weight: 1.0
      api_base: https://llm-api.amd.com/claude3/deployments/claude-sonnet-4.5
      api_key: null

prompt:
  template_dir: "./prompts"

# Database configuration
database:
  db_path: "./runs/grouped_gemm_db"
  population_size: 10
  archive_size: 10
  num_islands: 3
  elite_selection_ratio: 0.3
  exploitation_ratio: 0.65
  exploration_ratio: 0.35
  log_prompts: true

# Evaluator configuration for ROCm evaluator
evaluator:
  timeout: 1800  # 30 minutes - large GEMM can take time
  parallel_evaluations: 1
  use_llm_feedback: true
  cascade_evaluation: false
  verbose: false
  
# Evolution settings
diff_based_evolution: true
allow_full_rewrites: false
max_code_length: 60000
