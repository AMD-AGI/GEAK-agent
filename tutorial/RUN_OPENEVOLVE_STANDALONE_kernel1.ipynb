{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff34e819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifications Copyright(C)[2025] Advanced Micro Devices, Inc. All rights reserved.\n",
    "# https://github.com/algorithmicsuperintelligence/openevolve  - Apache License 2.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ea7604",
   "metadata": {},
   "source": [
    "# OpenEvolve Standalone Tutorial\n",
    "\n",
    "This notebook demonstrates how to use **GEAK-OpenEvolve** for GPU kernel optimization using LLM-guided evolution.\n",
    "\n",
    "## Prerequisites\n",
    " **Environment Variables**: Set `OPENAI_API_KEY`\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- How to set up GEAK-OpenEvolve\n",
    "- How to prepare an initial kernel program\n",
    "- How to configure evolution parameters\n",
    "- How to run the evolution pipeline\n",
    "- How to analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24c9f27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenEvolve Root: /home/sapmajum/neurips/geak-openevolve\n",
      "\n",
      "âœ… OpenEvolve root: /home/sapmajum/neurips/geak-openevolve\n",
      "âœ… Python path updated\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Environment Setup\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get geak-openevolve root\n",
    "OPENEVOLVE_ROOT = Path.cwd().parent\n",
    "print(f\"OpenEvolve Root: {OPENEVOLVE_ROOT}\")\n",
    "\n",
    "# Add to Python path\n",
    "if str(OPENEVOLVE_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(OPENEVOLVE_ROOT))\n",
    "\n",
    "print(f\"\\nâœ… OpenEvolve root: {OPENEVOLVE_ROOT}\")\n",
    "print(f\"âœ… Python path updated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1820113-3423-4838-baf8-33a2e27c48d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/nightly/rocm6.2.4/\n",
      "Requirement already satisfied: torch in /home/sapmajum/miniconda3/lib/python3.13/site-packages (2.7.0.dev20250310+rocm6.2.4)\n",
      "Requirement already satisfied: torchvision in /home/sapmajum/miniconda3/lib/python3.13/site-packages (0.22.0.dev20250310+rocm6.2.4)\n",
      "Requirement already satisfied: torchaudio in /home/sapmajum/miniconda3/lib/python3.13/site-packages (2.6.0.dev20250310+rocm6.2.4)\n",
      "Requirement already satisfied: filelock in /home/sapmajum/miniconda3/lib/python3.13/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/sapmajum/miniconda3/lib/python3.13/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /home/sapmajum/miniconda3/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/sapmajum/miniconda3/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/sapmajum/miniconda3/lib/python3.13/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/sapmajum/miniconda3/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/sapmajum/miniconda3/lib/python3.13/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: pytorch-triton-rocm==3.2.0+git4b3bb1f8 in /home/sapmajum/miniconda3/lib/python3.13/site-packages (from torch) (3.2.0+git4b3bb1f8)\n",
      "Requirement already satisfied: numpy in /home/sapmajum/miniconda3/lib/python3.13/site-packages (from torchvision) (2.3.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/sapmajum/miniconda3/lib/python3.13/site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/sapmajum/miniconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/sapmajum/miniconda3/lib/python3.13/site-packages (from jinja2->torch) (3.0.3)\n",
      "\u001b[31mERROR: torch-2.7.0a0+rocm7.0.0rc20250711-cp312-cp312-linux_x86_64.whl is not a supported wheel on this platform.\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: triton==3.3.0 in /home/sapmajum/miniconda3/lib/python3.13/site-packages (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/sapmajum/miniconda3/lib/python3.13/site-packages (from triton==3.3.0) (80.9.0)\n",
      "Requirement already satisfied: tenacity in /home/sapmajum/miniconda3/lib/python3.13/site-packages (9.1.2)\n",
      "Requirement already satisfied: loguru in /home/sapmajum/miniconda3/lib/python3.13/site-packages (0.7.3)\n",
      "Requirement already satisfied: parse_llm_code in /home/sapmajum/miniconda3/lib/python3.13/site-packages (0.1.31)\n",
      "Requirement already satisfied: rank_bm25 in /home/sapmajum/miniconda3/lib/python3.13/site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy in /home/sapmajum/miniconda3/lib/python3.13/site-packages (from rank_bm25) (2.3.5)\n",
      "âœ… All dependencies installed!\n"
     ]
    }
   ],
   "source": [
    "# Install all required packages\n",
    "!pip install -q ipykernel\n",
    "!python3 -m pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/rocm6.2.4/\n",
    "# PyTorch for ROCm (gfx94X)\n",
    "!python -m pip install https://rocm.nightlies.amd.com/v2/gfx94X-dcgpu/torch/torch-2.7.0a0+rocm7.0.0rc20250711-cp312-cp312-linux_x86_64.whl\n",
    "\n",
    "# Triton 3.3.0\n",
    "!python -m pip install -U triton==3.3.0\n",
    "\n",
    "# Other dependencies\n",
    "!pip install -q pyyaml openai pytest pytest-timeout\n",
    "!pip install tenacity loguru parse_llm_code rank_bm25\n",
    "\n",
    "print('âœ… All dependencies installed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d39b24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… GEAK-eval already exists at: /home/sapmajum/neurips/geak-openevolve/GEAK-eval-OE\n",
      "âœ… geak-eval command available: /home/sapmajum/.local/bin/geak-eval\n"
     ]
    }
   ],
   "source": [
    "# Step 1.5: Clone and Install GEAK-eval (if not already done)\n",
    "import os\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "OPENEVOLVE_ROOT = Path.cwd().parent\n",
    "GEAK_EVAL_DIR = OPENEVOLVE_ROOT / \"GEAK-eval-OE\"\n",
    "\n",
    "if not GEAK_EVAL_DIR.exists():\n",
    "    print(\"ğŸ“¥ Cloning GEAK-eval...\")\n",
    "    os.chdir(OPENEVOLVE_ROOT)\n",
    "    \n",
    "    # Clone and checkout\n",
    "    subprocess.run([\"git\", \"clone\", \"git@github.com:AMD-AGI/GEAK-eval.git\", \"GEAK-eval-OE\"], check=True)\n",
    "    os.chdir(\"GEAK-eval-OE\")\n",
    "    subprocess.run([\"git\", \"checkout\", \"geak-oe\"], check=True)\n",
    "    \n",
    "    print(\"âœ… GEAK-eval cloned\")\n",
    "    \n",
    "    # Install\n",
    "    print(\"ğŸ“¦ Installing GEAK-eval...\")\n",
    "    subprocess.run([\"pip\", \"install\", \"-e\", \".\", \"--no-deps\"], check=True)\n",
    "    print(\"âœ… GEAK-eval installed\")\n",
    "else:\n",
    "    print(f\"âœ… GEAK-eval already exists at: {GEAK_EVAL_DIR}\")\n",
    "    \n",
    "    # Check if installed\n",
    "    try:\n",
    "        result = subprocess.run([\"which\", \"geak-eval\"], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"âœ… geak-eval command available: {result.stdout.strip()}\")\n",
    "        else:\n",
    "            print(\"âš ï¸  geak-eval command not found, installing...\")\n",
    "            os.chdir(GEAK_EVAL_DIR)\n",
    "            subprocess.run([\"pip\", \"install\", \"-e\", \".\", \"--no-deps\"], check=True)\n",
    "            print(\"âœ… GEAK-eval installed\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Could not check geak-eval: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b9a1d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OPENAI_API_KEY set\n",
      "âœ… ROCM_GOLDEN_DATA_PATH = /home/sapmajum/neurips/geak-openevolve/GEAK-eval-OE/geak_eval/data/ROCm/data/performance/golden_results\n",
      "   Path exists: True\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Set Environment Variables\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set API key\n",
    "os.environ['OPENAI_API_KEY'] = \"<your-api-here>\"\n",
    "\n",
    "# Set ROCM_GOLDEN_DATA_PATH\n",
    "OPENEVOLVE_ROOT = Path.cwd().parent\n",
    "GOLDEN_DATA_PATH = OPENEVOLVE_ROOT / \"GEAK-eval-OE/geak_eval/data/ROCm/data/performance/golden_results\"\n",
    "os.environ['ROCM_GOLDEN_DATA_PATH'] = str(GOLDEN_DATA_PATH)\n",
    "\n",
    "print(f\"âœ… OPENAI_API_KEY set\")\n",
    "print(f\"âœ… ROCM_GOLDEN_DATA_PATH = {GOLDEN_DATA_PATH}\")\n",
    "print(f\"   Path exists: {GOLDEN_DATA_PATH.exists()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e398dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.13.9\n",
      "PyTorch: 2.7.0.dev20250310+rocm6.2.4\n",
      "GPU: AMD Instinct MI325X\n",
      "Triton: 3.2.0\n",
      "OpenEvolve: 0.1.0\n",
      "\n",
      "âœ… Environment ready!\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Verify OpenEvolve Installation\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A'}\")\n",
    "\n",
    "try:\n",
    "    import triton\n",
    "    print(f\"Triton: {triton.__version__}\")\n",
    "except:\n",
    "    print(\"âŒ Triton not found\")\n",
    "\n",
    "try:\n",
    "    import openevolve\n",
    "    print(f\"OpenEvolve: {openevolve.__version__ if hasattr(openevolve, '__version__') else 'installed'}\")\n",
    "except:\n",
    "    print(\"âŒ OpenEvolve not found - install with: pip install -e .\")\n",
    "\n",
    "print(\"\\nâœ… Environment ready!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9e193c",
   "metadata": {},
   "source": [
    "## Kernel Preparation\n",
    "\n",
    "OpenEvolve requires:\n",
    "1. **Initial Kernel**: The starting kernel code to optimize\n",
    "2. **Evaluator**: A function that evaluates kernel performance\n",
    "3. **Configuration**: Evolution parameters (iterations, population size, etc.)\n",
    "\n",
    "We'll use a validated ROCm Triton kernel as our example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25923f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Selected kernel: test_kernel_sub.py\n",
      "   Path: GEAK-eval-OE/geak_eval/data/ROCm/data/ROCm_v1/test_kernel_sub.py\n",
      "\n",
      "ğŸ“ Kernel Preview:\n",
      "   @triton.jit\n",
      "   def kernel_sub(a, b, o, N: tl.constexpr):\n",
      "       idx = tl.arange(0, N)\n",
      "       tl.store(o + idx, tl.load(a + idx) - tl.load(b + idx) * 777)\n",
      "   \n",
      "   \n",
      "   ##################################################################################################################################################\n",
      "   \n",
      "   import numpy as np\n",
      "   import random\n",
      "   import torch\n",
      "   import os\n",
      "   import pytest\n",
      "   from numpy.random import RandomState\n",
      "   import multiprocessing\n",
      "   ... (223 more lines)\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Select Example Kernel\n",
    "from pathlib import Path\n",
    "\n",
    "OPENEVOLVE_ROOT = Path.cwd().parent\n",
    "TUTORIAL_DIR = OPENEVOLVE_ROOT / \"tutorial\"\n",
    "\n",
    "# Use kernel from GEAK-eval-OE (cloned GEAK-eval repository)\n",
    "INITIAL_KERNEL = OPENEVOLVE_ROOT / \"GEAK-eval-OE/geak_eval/data/ROCm/data/ROCm_v1/test_kernel_sub.py\"\n",
    "\n",
    "if INITIAL_KERNEL.exists():\n",
    "    print(f\"âœ… Selected kernel: {INITIAL_KERNEL.name}\")\n",
    "    print(f\"   Path: {INITIAL_KERNEL.relative_to(OPENEVOLVE_ROOT)}\")\n",
    "    \n",
    "    # Quick peek at the kernel\n",
    "    with open(INITIAL_KERNEL, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Find the kernel function\n",
    "    in_kernel = False\n",
    "    kernel_lines = []\n",
    "    for line in lines:\n",
    "        if '@triton.jit' in line:\n",
    "            in_kernel = True\n",
    "        if in_kernel:\n",
    "            kernel_lines.append(line.rstrip())\n",
    "            if line.strip().startswith('tl.store') and 'output' in line:\n",
    "                break\n",
    "    \n",
    "    print(f\"\\nğŸ“ Kernel Preview:\")\n",
    "    for line in kernel_lines[:15]:\n",
    "        print(f\"   {line}\")\n",
    "    if len(kernel_lines) > 15:\n",
    "        print(f\"   ... ({len(kernel_lines)-15} more lines)\")\n",
    "else:\n",
    "    print(f\"âŒ Kernel not found at: {INITIAL_KERNEL}\")\n",
    "    INITIAL_KERNEL = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c269a124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Using evaluator: rocm_evaluator.py\n",
      "   Path: examples/tb/rocm_evaluator.py\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Setup Evaluator\n",
    "from pathlib import Path\n",
    "\n",
    "OPENEVOLVE_ROOT = Path.cwd().parent\n",
    "\n",
    "# Use the ROCm evaluator from examples\n",
    "EVALUATOR_PATH = OPENEVOLVE_ROOT / \"examples/tb/rocm_evaluator.py\"\n",
    "\n",
    "if EVALUATOR_PATH.exists():\n",
    "    print(f\"âœ… Using evaluator: {EVALUATOR_PATH.name}\")\n",
    "    print(f\"   Path: {EVALUATOR_PATH.relative_to(OPENEVOLVE_ROOT)}\")\n",
    "else:\n",
    "    print(f\"âŒ Evaluator not found at: {EVALUATOR_PATH}\")\n",
    "    EVALUATOR_PATH = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79472251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Found config template: configs/default_config.yaml\n",
      "âœ… Configuration saved to: tutorial_config.yaml\n",
      "\n",
      "ğŸ“ Evolution Parameters:\n",
      "  Max Iterations:  10\n",
      "  Population Size: 50\n",
      "  Num Islands:     4\n",
      "  Log Level:       WARNING\n",
      "  LLM Model:       claude-sonnet-4-5\n",
      "  LLM API:         claude-sonnet-4-5\n",
      "  Max Tokens:      10000\n",
      "  Timeout:         200s\n",
      "  LLM Sampling:    random\n",
      "  Prompt Dir:      ./prompts_tutorial\n",
      "  Database Path:   program_database\n",
      "  LLM  Feedback:   True\n",
      "  Parallel  Evaluation:   1\n",
      "\n",
      "ğŸ” Prompt Configuration Details:\n",
      "  âœ… No inline system_message (will load from template)\n",
      "  âœ… No inline evaluator_system_message (will load from template)\n",
      "\n",
      "ğŸ“ Template Files:\n",
      "  system_message.txt: âœ… EXISTS\n",
      "  evaluator_system_message.txt: âœ… EXISTS\n",
      "\n",
      "  system_message.txt: 14058 chars\n",
      "  âœ… Contains advanced prompt keywords!\n",
      "\n",
      "âœ… Ready to run evolution!\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Configure Evolution Parameters\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "OPENEVOLVE_ROOT = Path.cwd().parent\n",
    "TUTORIAL_DIR = OPENEVOLVE_ROOT / \"tutorial\"\n",
    "\n",
    "# Configuration parameters - EASILY ADJUSTABLE\n",
    "MAX_ITERATIONS = 10\n",
    "POPULATION_SIZE = 50\n",
    "NUM_ISLANDS = 4\n",
    "LOG_LEVEL = \"WARNING\"\n",
    "\n",
    "# Try multiple config templates\n",
    "CONFIG_TEMPLATES = [\n",
    "    OPENEVOLVE_ROOT / \"configs/default_config.yaml\",\n",
    "    OPENEVOLVE_ROOT / \"examples/tb/configs/demo_config.yaml\",\n",
    "]\n",
    "\n",
    "CONFIG_FILE = TUTORIAL_DIR / \"tutorial_config.yaml\"\n",
    "\n",
    "# Find first available template\n",
    "template_found = None\n",
    "for template in CONFIG_TEMPLATES:\n",
    "    if template.exists():\n",
    "        template_found = template\n",
    "        print(f\"âœ… Found config template: {template.relative_to(OPENEVOLVE_ROOT)}\")\n",
    "        break\n",
    "\n",
    "if template_found:\n",
    "    with open(template_found, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    config['max_iterations'] = MAX_ITERATIONS\n",
    "    config['log_level'] = LOG_LEVEL\n",
    "    \n",
    "    if 'database' not in config:\n",
    "        config['database'] = {}\n",
    "    config['database']['population_size'] = POPULATION_SIZE\n",
    "    config['database']['num_islands'] = NUM_ISLANDS\n",
    "    config['database']['log_prompts'] = True\n",
    "    \n",
    "    # CRITICAL: Fix db_path (can't be None)\n",
    "    if config['database'].get('db_path') is None:\n",
    "        config['database']['db_path'] = 'program_database'\n",
    "    \n",
    "    if 'llm' not in config:\n",
    "        config['llm'] = {}\n",
    "    \n",
    "    # CRITICAL: Set sampling configuration\n",
    "    config['llm']['sampling'] = {'fn': 'random'}\n",
    "    \n",
    "    config['llm']['models'] = [{'name': 'claude-sonnet-4-5', 'weight': 1.0}]\n",
    "    config['llm']['evaluator_models'] = [{'name': 'claude-sonnet-4-5', 'weight': 1.0}]\n",
    "    config['llm']['api_base'] = 'https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5'\n",
    "    config['llm']['api_key'] = None\n",
    "    \n",
    "    if 'evaluator' not in config:\n",
    "        config['evaluator'] = {}\n",
    "    config['evaluator']['cascade_evaluation'] = False\n",
    "    config['evaluator']['verbose'] = False\n",
    "    \n",
    "    # Set prompt template directory for advanced prompts\n",
    "    if 'prompt' not in config:\n",
    "        config['prompt'] = {}\n",
    "    config['prompt']['template_dir'] = './prompts_tutorial'\n",
    "    # Remove inline prompts when using template_dir (they would override template files)\n",
    "    config['prompt'].pop('system_message', None)\n",
    "    config['prompt'].pop('evaluator_system_message', None)\n",
    "    \n",
    "    # Set LLM parameters for code generation\n",
    "    config['llm']['max_tokens'] = 10000\n",
    "    config['llm']['timeout'] = 200\n",
    "    \n",
    "    config['diff_based_evolution'] = True\n",
    "    config['max_code_length'] = 50000\n",
    "    config['evaluator']['use_llm_feedback'] = True\n",
    "    config['evaluator']['parallel_evaluations'] = 1\n",
    "    \n",
    "    # CRITICAL: Create evals directory for evaluator temp files\n",
    "    evals_dir = TUTORIAL_DIR / \"evals\"\n",
    "    evals_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    with open(CONFIG_FILE, 'w') as f:\n",
    "        yaml.dump(config, f, default_flow_style=False, sort_keys=False)\n",
    "    \n",
    "    print(f\"âœ… Configuration saved to: {CONFIG_FILE.name}\")\n",
    "    print(f\"\\nğŸ“ Evolution Parameters:\")\n",
    "    print(f\"  Max Iterations:  {MAX_ITERATIONS}\")\n",
    "    print(f\"  Population Size: {POPULATION_SIZE}\")\n",
    "    print(f\"  Num Islands:     {NUM_ISLANDS}\")\n",
    "    print(f\"  Log Level:       {LOG_LEVEL}\")\n",
    "    print(f\"  LLM Model:       {config['llm']['models'][0]['name']}\")\n",
    "    print(f\"  LLM API:         {config['llm']['api_base'].split('/')[-1]}\")\n",
    "    print(f\"  Max Tokens:      {config['llm'].get('max_tokens', 'NOT SET')}\")\n",
    "    print(f\"  Timeout:         {config['llm'].get('timeout', 'NOT SET')}s\")\n",
    "    print(f\"  LLM Sampling:    {config['llm']['sampling']['fn']}\")\n",
    "    print(f\"  Prompt Dir:      {config['prompt']['template_dir']}\")\n",
    "    print(f\"  Database Path:   {config['database']['db_path']}\")\n",
    "    print(f\"  LLM  Feedback:   {config['evaluator']['use_llm_feedback']}\")\n",
    "    print(f\"  Parallel  Evaluation:   {config['evaluator']['parallel_evaluations']}\")\n",
    "    \n",
    "    # Debug: Check prompt configuration\n",
    "    print(f\"\\nğŸ” Prompt Configuration Details:\")\n",
    "    if 'system_message' in config['prompt']:\n",
    "        print(f\"  âš ï¸  Inline system_message present (will override template!)\")\n",
    "    else:\n",
    "        print(f\"  âœ… No inline system_message (will load from template)\")\n",
    "    \n",
    "    if 'evaluator_system_message' in config['prompt']:\n",
    "        print(f\"  âš ï¸  Inline evaluator_system_message present (will override template!)\")\n",
    "    else:\n",
    "        print(f\"  âœ… No inline evaluator_system_message (will load from template)\")\n",
    "    \n",
    "    # Verify template files exist\n",
    "    template_dir_path = TUTORIAL_DIR / config['prompt']['template_dir'].lstrip('./')\n",
    "    sys_msg_file = template_dir_path / \"system_message.txt\"\n",
    "    eval_msg_file = template_dir_path / \"evaluator_system_message.txt\"\n",
    "    \n",
    "    print(f\"\\nğŸ“ Template Files:\")\n",
    "    print(f\"  {sys_msg_file.name}: {'âœ… EXISTS' if sys_msg_file.exists() else 'âŒ MISSING'}\")\n",
    "    print(f\"  {eval_msg_file.name}: {'âœ… EXISTS' if eval_msg_file.exists() else 'âŒ MISSING'}\")\n",
    "    \n",
    "    if sys_msg_file.exists():\n",
    "        with open(sys_msg_file, 'r') as f:\n",
    "            content = f.read()\n",
    "            print(f\"\\n  system_message.txt: {len(content)} chars\")\n",
    "            if \"ALGORITHMIC IMPROVEMENTS\" in content or \"OPERATOR FUSION\" in content:\n",
    "                print(f\"  âœ… Contains advanced prompt keywords!\")\n",
    "            else:\n",
    "                print(f\"  âŒ Does not contain expected keywords\")\n",
    "    \n",
    "    print(f\"\\nâœ… Ready to run evolution!\")\n",
    "else:\n",
    "    print(\"âŒ No config template found!\")\n",
    "    CONFIG_FILE = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed31fc70",
   "metadata": {},
   "source": [
    "### ğŸ“„ Step 6.5: Preview Prompts (Optional - for debugging)\n",
    "\n",
    "Run this cell to see what system messages will be sent to the LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ca656ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ” PROMPTS THAT WILL BE SENT TO LLM\n",
      "================================================================================\n",
      "\n",
      "Template directory: /home/sapmajum/neurips/geak-openevolve/tutorial/prompts_tutorial\n",
      "Directory exists: True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ“ SYSTEM MESSAGE (for code generation)\n",
      "--------------------------------------------------------------------------------\n",
      "âœ… File: system_message.txt\n",
      "âœ… Length: 14058 characters\n",
      "\n",
      "--- First 800 characters ---\n",
      "Role: GPU Kernel Optimization Expert - Focus on Algorithmic Improvements\n",
      "\n",
      "You are optimizing Triton GPU kernels for AMD ROCm. Your goal is to achieve 2-5x speedup through smart algorithmic changes.\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "CRITICAL TRITON SYNTAX RULES (Follow These to Avoid Errors!)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "ğŸ“˜ DTYPES (triton.language types)\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Available: tl.float16, tl.float32, tl.float64, tl.bfloat16\n",
      "           tl.int8, tl.int16, tl.int32, tl.int64\n",
      "           tl.uint8, tl.uint16, tl.uint32, tl.uint64\n",
      "           tl.float8e4b8, tl.float8e4nv, tl.float8e5, etc.\n",
      "\n",
      "âœ“ Dtypes are TYPE OBJECTS, NOT constructors!\n",
      "  âŒ WRONG: result = x * tl.float32(777.0)     \n",
      "\n",
      "... [full prompt will be sent to LLM]\n",
      "\n",
      "âœ… Contains: ALGORITHMIC optimization guidance\n",
      "âœ… Contains: OPERATOR FUSION technique\n",
      "âœ… Contains: tl.float32 syntax rules (prevents errors!)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ğŸ“ EVALUATOR SYSTEM MESSAGE (for feedback)\n",
      "--------------------------------------------------------------------------------\n",
      "âœ… File: evaluator_system_message.txt\n",
      "âœ… Length: 7482 characters\n",
      "\n",
      "--- First 500 characters ---\n",
      "Role: Kernel Optimization Evaluator - Provide Clear, Actionable Feedback\n",
      "\n",
      "Your job is to analyze optimization attempts and guide the next iteration with specific, actionable advice.\n",
      "\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "EVALUATION CRITERIA (In Priority Order)\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "1. CORRECTNESS (Pass/Fail - Must Pass!)\n",
      "   âœ“ Output matches baseline exactly?\n",
      "   âœ“ No syntax errors?\n",
      "   âœ“ No runtime\n",
      "\n",
      "... [full prompt will be sent to LLM]\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: Preview what prompts will be sent to the LLM\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add OpenEvolve to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "try:\n",
    "    from openevolve.prompt.templates import TemplateManager\n",
    "    import yaml\n",
    "    \n",
    "    TUTORIAL_DIR = Path.cwd()\n",
    "    \n",
    "    with open('tutorial_config.yaml', 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    template_dir = config['prompt'].get('template_dir')\n",
    "    \n",
    "    if template_dir:\n",
    "        print(\"=\"*80)\n",
    "        print(\"ğŸ” PROMPTS THAT WILL BE SENT TO LLM\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Resolve relative path\n",
    "        if template_dir.startswith('./'):\n",
    "            template_path = TUTORIAL_DIR / template_dir.lstrip('./')\n",
    "        else:\n",
    "            template_path = Path(template_dir)\n",
    "        \n",
    "        print(f\"\\nTemplate directory: {template_path}\")\n",
    "        print(f\"Directory exists: {template_path.exists()}\")\n",
    "        \n",
    "        if template_path.exists():\n",
    "            sys_msg_file = template_path / \"system_message.txt\"\n",
    "            eval_msg_file = template_path / \"evaluator_system_message.txt\"\n",
    "            \n",
    "            print(f\"\\n\" + \"-\"*80)\n",
    "            print(f\"ğŸ“ SYSTEM MESSAGE (for code generation)\")\n",
    "            print(f\"-\"*80)\n",
    "            \n",
    "            if sys_msg_file.exists():\n",
    "                with open(sys_msg_file, 'r') as f:\n",
    "                    sys_msg = f.read()\n",
    "                \n",
    "                print(f\"âœ… File: {sys_msg_file.name}\")\n",
    "                print(f\"âœ… Length: {len(sys_msg)} characters\")\n",
    "                print(f\"\\n--- First 800 characters ---\")\n",
    "                print(sys_msg[:800])\n",
    "                print(\"\\n... [full prompt will be sent to LLM]\")\n",
    "                \n",
    "                # Check for key content\n",
    "                if \"ALGORITHMIC\" in sys_msg:\n",
    "                    print(\"\\nâœ… Contains: ALGORITHMIC optimization guidance\")\n",
    "                if \"OPERATOR FUSION\" in sys_msg:\n",
    "                    print(\"âœ… Contains: OPERATOR FUSION technique\")\n",
    "                if \"tl.float32\" in sys_msg:\n",
    "                    print(\"âœ… Contains: tl.float32 syntax rules (prevents errors!)\")\n",
    "            else:\n",
    "                print(f\"âŒ File not found: {sys_msg_file}\")\n",
    "            \n",
    "            print(f\"\\n\" + \"-\"*80)\n",
    "            print(f\"ğŸ“ EVALUATOR SYSTEM MESSAGE (for feedback)\")\n",
    "            print(f\"-\"*80)\n",
    "            \n",
    "            if eval_msg_file.exists():\n",
    "                with open(eval_msg_file, 'r') as f:\n",
    "                    eval_msg = f.read()\n",
    "                \n",
    "                print(f\"âœ… File: {eval_msg_file.name}\")\n",
    "                print(f\"âœ… Length: {len(eval_msg)} characters\")\n",
    "                print(f\"\\n--- First 500 characters ---\")\n",
    "                print(eval_msg[:500])\n",
    "                print(\"\\n... [full prompt will be sent to LLM]\")\n",
    "            else:\n",
    "                print(f\"âŒ File not found: {eval_msg_file}\")\n",
    "    else:\n",
    "        print(\"âš ï¸  No template_dir configured - using inline prompts or defaults\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\")\n",
    "    print(f\"\\nâš ï¸  This is an optional debug cell - you can skip it if needed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "211b4d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Output directory: runs/tutorial_run_20251126_203644\n",
      "âœ… Evals directory: evals\n",
      "\n",
      "======================================================================\n",
      "ğŸ“‹ Pre-Flight Check\n",
      "======================================================================\n",
      "âœ… Kernel      : test_kernel_sub.py\n",
      "âœ… Evaluator   : rocm_evaluator.py\n",
      "âœ… Config      : tutorial_config.yaml\n",
      "======================================================================\n",
      "\n",
      "ğŸš€ All components ready! You can proceed to run evolution.\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Setup Output Directory and Validate\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "OPENEVOLVE_ROOT = Path.cwd().parent\n",
    "TUTORIAL_DIR = OPENEVOLVE_ROOT / \"tutorial\"\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "OUTPUT_DIR = TUTORIAL_DIR / \"runs\" / f\"tutorial_run_{timestamp}\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# CRITICAL: Ensure evals directory exists (needed by evaluator)\n",
    "EVALS_DIR = TUTORIAL_DIR / \"evals\"\n",
    "EVALS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"âœ… Output directory: {OUTPUT_DIR.relative_to(TUTORIAL_DIR)}\")\n",
    "print(f\"âœ… Evals directory: {EVALS_DIR.relative_to(TUTORIAL_DIR)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“‹ Pre-Flight Check\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    kernel_var = INITIAL_KERNEL\n",
    "    kernel_defined = True\n",
    "except NameError:\n",
    "    kernel_var = None\n",
    "    kernel_defined = False\n",
    "\n",
    "try:\n",
    "    evaluator_var = EVALUATOR_PATH\n",
    "    evaluator_defined = True\n",
    "except NameError:\n",
    "    evaluator_var = None\n",
    "    evaluator_defined = False\n",
    "\n",
    "try:\n",
    "    config_var = CONFIG_FILE\n",
    "    config_defined = True\n",
    "except NameError:\n",
    "    config_var = None\n",
    "    config_defined = False\n",
    "\n",
    "components = {\n",
    "    \"Kernel\": (kernel_var, kernel_defined),\n",
    "    \"Evaluator\": (evaluator_var, evaluator_defined),\n",
    "    \"Config\": (config_var, config_defined)\n",
    "}\n",
    "\n",
    "all_ready = True\n",
    "missing_cells = []\n",
    "\n",
    "for name, (path, is_defined) in components.items():\n",
    "    if not is_defined:\n",
    "        print(f\"âŒ {name:12s}: NOT DEFINED (run earlier cell)\")\n",
    "        all_ready = False\n",
    "        if name == \"Kernel\":\n",
    "            missing_cells.append(\"Cell 5\")\n",
    "        elif name == \"Evaluator\":\n",
    "            missing_cells.append(\"Cell 6\")\n",
    "        elif name == \"Config\":\n",
    "            missing_cells.append(\"Cell 7\")\n",
    "    elif path and Path(path).exists():\n",
    "        print(f\"âœ… {name:12s}: {Path(path).name}\")\n",
    "    else:\n",
    "        print(f\"âŒ {name:12s}: NOT FOUND\")\n",
    "        all_ready = False\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n",
    "if all_ready:\n",
    "    print(\"\\nğŸš€ All components ready! You can proceed to run evolution.\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  Some components are missing!\")\n",
    "    if missing_cells:\n",
    "        print(\"\\nğŸ“ Please run these cells first:\")\n",
    "        for cell in missing_cells:\n",
    "            print(f\"   â€¢ {cell}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0210101f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting OpenEvolve Evolution...\n",
      "======================================================================\n",
      "ğŸ“¦ Kernel:    test_kernel_sub.py\n",
      "âš™ï¸  Evaluator: rocm_evaluator.py\n",
      "ğŸ“‹ Config:    tutorial_config.yaml\n",
      "ğŸ“ Output:    runs/tutorial_run_20251126_203644\n",
      "ğŸ  Working Dir: /home/sapmajum/neurips/geak-openevolve/tutorial\n",
      "======================================================================\n",
      "\n",
      "$ cd /home/sapmajum/neurips/geak-openevolve/tutorial\n",
      "$ openevolve-run /home/sapmajum/neurips/geak-openevolve/GEAK-eval-OE/geak_eval/data/ROCm/data/ROCm_v1/test_kernel_sub.py /home/sapmajum/neurips/geak-openevolve/examples/tb/rocm_evaluator.py --config /home/sapmajum/neurips/geak-openevolve/tutorial/tutorial_config.yaml --output /home/sapmajum/neurips/geak-openevolve/tutorial/runs/tutorial_run_20251126_203644\n",
      "\n",
      "======================================================================\n",
      "âœ… Loaded template 'evaluator_system_message' from prompts_tutorial/evaluator_system_message.txt (7482 chars)\n",
      "âœ… Loaded template 'system_message' from prompts_tutorial/system_message.txt (14058 chars)\n",
      "âœ… Loaded template 'evaluator_system_message' from prompts_tutorial/evaluator_system_message.txt (7482 chars)\n",
      "âœ… Loaded template 'system_message' from prompts_tutorial/system_message.txt (14058 chars)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 20:36:46,396 - INFO - Adding initial program to database\n",
      "2025-11-26 20:37:14,584 - INFO - Time spent in evaluation: 28.19 seconds\n",
      "2025-11-26 20:37:14,584 - INFO - ğŸ¯ Using system_message from template override: evaluator_system_message (7482 chars)\n",
      "2025-11-26 20:37:29,626 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:37:29,680 - INFO - Time spent in LLM evaluation: 15.10 seconds\n",
      "2025-11-26 20:37:29,680 - INFO - Evaluated program 0b7d30a9-3edc-4b07-972e-ec152134c1b8 in 15.10s: success=1.0000, final_score=1.0147, performance_metrics=1.0147, correctness_score=1.0000, combined_score=1.0147, benchmark_results=['Performance report: Kernel parameters: N_val=1024; dtype_str=fp32; num_warps=1, achieved latency: 0.006800 ms, speedup: 1.0147x.'], baseline_comparison=Performance report: Kernel parameters: N_val=1024; dtype_str=fp32; num_warps=1, achieved latency: 0.006800 ms, speedup: 1.0147x. Speedup=1.0147x (baseline: 0.006900ms, current: 0.006800ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 1.0147x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None, llm_readability=0.0450, llm_maintainability=0.0350, llm_efficiency=0.0500\n",
      "2025-11-26 20:37:29,680 - INFO - Initial program evaluated in 43.28 seconds \n",
      "2025-11-26 20:37:29,680 - INFO - Starting evolution from iteration 0 for 10 iterations (total: 10)\n",
      "2025-11-26 20:37:29,680 - INFO - Using island-based evolution with 4 islands\n",
      "2025-11-26 20:37:29,680 - INFO - Island Status:\n",
      "2025-11-26 20:37:29,681 - INFO -  * Island 0: 1 programs, best=1.0147, avg=1.0147, diversity=0.00, gen=0\n",
      "2025-11-26 20:37:29,681 - INFO -    Island 1: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=0\n",
      "2025-11-26 20:37:29,681 - INFO -    Island 2: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=0\n",
      "2025-11-26 20:37:29,681 - INFO -    Island 3: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=0\n",
      "2025-11-26 20:37:29,681 - INFO - ğŸ¯ Using system_message from template: 'system_message' (14058 chars)\n",
      "2025-11-26 20:37:29,681 - INFO - Sampled model: claude-sonnet-4-5\n",
      "2025-11-26 20:37:29,681 - INFO - Sampled model: claude-sonnet-4-5\n",
      "2025-11-26 20:37:29,685 - INFO - Sampled model: claude-sonnet-4-5\n",
      "2025-11-26 20:37:29,688 - INFO - Sampled model: claude-sonnet-4-5\n",
      "2025-11-26 20:37:29,690 - INFO - Sampled model: claude-sonnet-4-5\n",
      "2025-11-26 20:37:29,692 - INFO - Sampled model: claude-sonnet-4-5\n",
      "2025-11-26 20:37:29,692 - INFO - Sampled model: claude-sonnet-4-5\n",
      "2025-11-26 20:37:29,695 - INFO - Sampled model: claude-sonnet-4-5\n",
      "2025-11-26 20:38:03,412 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:38:05,224 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:38:07,127 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:38:08,471 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:38:10,851 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:38:13,432 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:38:30,545 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:38:47,083 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:38:47,127 - INFO - LLM responses generated in 1.29 minutes\n",
      "2025-11-26 20:39:29,699 - INFO - Time spent in evaluation: 42.57 seconds\n",
      "2025-11-26 20:39:29,699 - INFO - ğŸ¯ Using system_message from template override: evaluator_system_message (7482 chars)\n",
      "2025-11-26 20:39:40,388 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:39:40,390 - INFO - Time spent in LLM evaluation: 10.69 seconds\n",
      "2025-11-26 20:39:40,390 - INFO - Evaluated program ecca2e01-1e67-43c5-8951-3178d69444b1 in 10.69s: success=1.0000, final_score=1.1500, performance_metrics=1.1500, correctness_score=1.0000, combined_score=1.1500, benchmark_results=['Performance report: Kernel parameters: N_val=1024; dtype_str=fp32; num_warps=1, achieved latency: 0.006000 ms, speedup: 1.1500x.'], baseline_comparison=Performance report: Kernel parameters: N_val=1024; dtype_str=fp32; num_warps=1, achieved latency: 0.006000 ms, speedup: 1.1500x. Speedup=1.1500x (baseline: 0.006900ms, current: 0.006000ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 1.1500x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None, llm_readability=0.0550, llm_maintainability=0.0450, llm_efficiency=0.0700\n",
      "2025-11-26 20:40:22,738 - INFO - Time spent in evaluation: 42.35 seconds\n",
      "2025-11-26 20:40:22,738 - INFO - ğŸ¯ Using system_message from template override: evaluator_system_message (7482 chars)\n",
      "2025-11-26 20:40:33,104 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:40:33,106 - INFO - Time spent in LLM evaluation: 10.37 seconds\n",
      "2025-11-26 20:40:33,106 - INFO - Evaluated program a115dccb-2a35-41ca-b571-c111467b4dfc in 10.37s: success=1.0000, final_score=1.1311, performance_metrics=1.1311, correctness_score=1.0000, combined_score=1.1311, benchmark_results=['Performance report: Kernel parameters: N_val=1024; dtype_str=fp32; num_warps=1, achieved latency: 0.006100 ms, speedup: 1.1311x.'], baseline_comparison=Performance report: Kernel parameters: N_val=1024; dtype_str=fp32; num_warps=1, achieved latency: 0.006100 ms, speedup: 1.1311x. Speedup=1.1311x (baseline: 0.006900ms, current: 0.006100ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 1.1311x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None, llm_readability=0.0550, llm_maintainability=0.0450, llm_efficiency=0.0700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ WARNING: Kernel evaluator path /home/sapmajum/neurips/geak-openevolve/GEAK-eval-OE/geak_eval/data/ROCm/data/ROCm_v1/evaluator.py does not exist, using default given path.\n",
      "ğŸ›¡ï¸ BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp6h2tyyvl/test_kernel_sub.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp6h2tyyvl/test_kernel_sub.py\n",
      "ğŸ“ Extracted kernel name from program_text: test_kernel_sub.py\n",
      "ğŸ“ Final kernel name for test merging: test_kernel_sub.py\n",
      "âœ… No @triton.autotune - using ROCm_v1 tests\n",
      "âœ… Merged kernel with test code from ROCm_v1\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp6h2tyyvl/test_kernel_sub.py -k not (test_performance or test_save)\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp6h2tyyvl/test_kernel_sub.py -k test_performance or test_save_performance_results\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 45 items / 2 deselected / 43 selected\n",
      "\n",
      "evals/tmp6h2tyyvl/test_kernel_sub.py::test_performance[1-fp32-1024] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp6h2tyyvl/perf\n",
      "Found 1 JSON files: ['kernel_sub_triton_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp6h2tyyvl/perf/kernel_sub_triton_perf.json (most recent)\n",
      "Performance data structure: ['params', 'ms', 'min_ms', 'max_ms', 'GB/s', 'TFLOPS']\n",
      "Performance: 0.0068ms (from key 'ms')\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Calculated speedup: 0.006900ms / 0.006800ms = 1.0147x\n",
      "ğŸ›¡ï¸ BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmplpghuwno/test_kernel_sub.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmplpghuwno/test_kernel_sub.py\n",
      "ğŸ“ Extracted kernel name from program_text: test_kernel_sub.py\n",
      "ğŸ“ Final kernel name for test merging: test_kernel_sub.py\n",
      "âœ… Detected @triton.autotune - using ROCm_v1_autotune tests\n",
      "âœ… Merged kernel with test code from ROCm_v1_autotune\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmplpghuwno/test_kernel_sub.py -k not (test_performance or test_save)\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmplpghuwno/test_kernel_sub.py -k test_performance or test_save_performance_results\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 45 items / 2 deselected / 43 selected\n",
      "\n",
      "evals/tmplpghuwno/test_kernel_sub.py::test_performance[1-fp32-1024] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmplpghuwno/perf\n",
      "Found 1 JSON files: ['kernel_sub_triton_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmplpghuwno/perf/kernel_sub_triton_perf.json (most recent)\n",
      "Performance data structure: ['params', 'ms', 'min_ms', 'max_ms', 'GB/s', 'TFLOPS']\n",
      "Performance: 0.006ms (from key 'ms')\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Calculated speedup: 0.006900ms / 0.006000ms = 1.1500x\n",
      "ğŸ›¡ï¸ BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpc1ij8o91/test_kernel_sub.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpc1ij8o91/test_kernel_sub.py\n",
      "ğŸ“ Extracted kernel name from program_text: test_kernel_sub.py\n",
      "ğŸ“ Final kernel name for test merging: test_kernel_sub.py\n",
      "âœ… Detected @triton.autotune - using ROCm_v1_autotune tests\n",
      "âœ… Merged kernel with test code from ROCm_v1_autotune\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpc1ij8o91/test_kernel_sub.py -k not (test_performance or test_save)\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpc1ij8o91/test_kernel_sub.py -k test_performance or test_save_performance_results\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 45 items / 2 deselected / 43 selected\n",
      "\n",
      "evals/tmpc1ij8o91/test_kernel_sub.py::test_performance[1-fp32-1024] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpc1ij8o91/perf\n",
      "Found 1 JSON files: ['kernel_sub_triton_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpc1ij8o91/perf/kernel_sub_triton_perf.json (most recent)\n",
      "Performance data structure: ['params', 'ms', 'min_ms', 'max_ms', 'GB/s', 'TFLOPS']\n",
      "Performance: 0.0061ms (from key 'ms')\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Calculated speedup: 0.006900ms / 0.006100ms = 1.1311x\n",
      "ğŸ›¡ï¸ BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmple8twwkm/test_kernel_sub.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmple8twwkm/test_kernel_sub.py\n",
      "ğŸ“ Extracted kernel name from program_text: test_kernel_sub.py\n",
      "ğŸ“ Final kernel name for test merging: test_kernel_sub.py\n",
      "âœ… Detected @triton.autotune - using ROCm_v1_autotune tests\n",
      "âœ… Merged kernel with test code from ROCm_v1_autotune\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmple8twwkm/test_kernel_sub.py -k not (test_performance or test_save)\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmple8twwkm/test_kernel_sub.py -k test_performance or test_save_performance_results\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 45 items / 2 deselected / 43 selected\n",
      "\n",
      "evals/tmple8twwkm/test_kernel_sub.py::test_performance[1-fp32-1024] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmple8twwkm/perf\n",
      "Found 1 JSON files: ['kernel_sub_triton_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmple8twwkm/perf/kernel_sub_triton_perf.json (most recent)\n",
      "Performance data structure: ['params', 'ms', 'min_ms', 'max_ms', 'GB/s', 'TFLOPS']\n",
      "Performance: 0.0061ms (from key 'ms')\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Calculated speedup: 0.006900ms / 0.006100ms = 1.1311x"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 20:41:15,798 - INFO - Time spent in evaluation: 42.69 seconds\n",
      "2025-11-26 20:41:15,798 - INFO - ğŸ¯ Using system_message from template override: evaluator_system_message (7482 chars)\n",
      "2025-11-26 20:41:23,891 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:41:23,893 - INFO - Time spent in LLM evaluation: 8.09 seconds\n",
      "2025-11-26 20:41:23,893 - INFO - Evaluated program a11d223a-61f8-4dd2-89ee-ef8d29989a97 in 8.09s: success=1.0000, final_score=1.1311, performance_metrics=1.1311, correctness_score=1.0000, combined_score=1.1311, benchmark_results=['Performance report: Kernel parameters: N_val=1024; dtype_str=fp32; num_warps=1, achieved latency: 0.006100 ms, speedup: 1.1311x.'], baseline_comparison=Performance report: Kernel parameters: N_val=1024; dtype_str=fp32; num_warps=1, achieved latency: 0.006100 ms, speedup: 1.1311x. Speedup=1.1311x (baseline: 0.006900ms, current: 0.006100ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 1.1311x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None, llm_readability=0.0450, llm_maintainability=0.0400, llm_efficiency=0.0700\n",
      "2025-11-26 20:42:06,455 - INFO - Time spent in evaluation: 42.56 seconds\n",
      "2025-11-26 20:42:06,455 - INFO - ğŸ¯ Using system_message from template override: evaluator_system_message (7482 chars)\n",
      "2025-11-26 20:42:17,104 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:42:17,106 - INFO - Time spent in LLM evaluation: 10.65 seconds\n",
      "2025-11-26 20:42:17,106 - INFO - Evaluated program a29dd797-1269-4498-b025-6415944fd0dc in 10.65s: success=1.0000, final_score=1.1129, performance_metrics=1.1129, correctness_score=1.0000, combined_score=1.1129, benchmark_results=['Performance report: Kernel parameters: N_val=1024; dtype_str=fp32; num_warps=1, achieved latency: 0.006200 ms, speedup: 1.1129x.'], baseline_comparison=Performance report: Kernel parameters: N_val=1024; dtype_str=fp32; num_warps=1, achieved latency: 0.006200 ms, speedup: 1.1129x. Speedup=1.1129x (baseline: 0.006900ms, current: 0.006200ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 1.1129x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None, llm_readability=0.0650, llm_maintainability=0.0550, llm_efficiency=0.0750\n",
      "2025-11-26 20:42:59,594 - INFO - Time spent in evaluation: 42.49 seconds\n",
      "2025-11-26 20:42:59,594 - INFO - ğŸ¯ Using system_message from template override: evaluator_system_message (7482 chars)\n",
      "2025-11-26 20:43:09,169 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:43:09,171 - INFO - Time spent in LLM evaluation: 9.58 seconds\n",
      "2025-11-26 20:43:09,171 - INFO - Evaluated program 1db96791-ecdb-420a-87ff-b9245783243b in 9.58s: success=1.0000, final_score=1.1500, performance_metrics=1.1500, correctness_score=1.0000, combined_score=1.1500, benchmark_results=['Performance report: Kernel parameters: N_val=1024; dtype_str=fp32; num_warps=1, achieved latency: 0.006000 ms, speedup: 1.1500x.'], baseline_comparison=Performance report: Kernel parameters: N_val=1024; dtype_str=fp32; num_warps=1, achieved latency: 0.006000 ms, speedup: 1.1500x. Speedup=1.1500x (baseline: 0.006900ms, current: 0.006000ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 1.1500x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None, llm_readability=0.0450, llm_maintainability=0.0350, llm_efficiency=0.0600\n",
      "2025-11-26 20:43:11,935 - INFO - Time spent in evaluation: 2.76 seconds\n",
      "2025-11-26 20:43:11,935 - INFO - ğŸ¯ Using system_message from template override: evaluator_system_message (7482 chars)\n",
      "2025-11-26 20:43:22,549 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:43:22,552 - INFO - Time spent in LLM evaluation: 10.62 seconds\n",
      "2025-11-26 20:43:22,553 - INFO - Evaluated program 9cffa93b-706a-4723-85ef-3fcdd558b084 in 10.62s: success=0.0000, final_score=0.0000, error=Correctness tests failed (exit 2):\n",
      "STDOUT: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 0 items / 1 error\n",
      "\n",
      "==================================== ERRORS ====================================\n",
      "\u001b[31m\u001b[1m________ ERROR collecting tutorial/evals/tmpfminkgg4/test_kernel_sub.py ________\u001b[0m\n",
      "\u001b[1m\u001b[31mevals/tmpfminkgg4/test_kernel_sub.py\u001b[0m:234: in <module>\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, KERNEL_SUB_SHAPES_FOR_PERF)\u001b[90m\u001b[39;49;00m\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE   NameError: name 'KERNEL_SUB_SHAPES_FOR_PERF' is not defined\u001b[0m\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mERROR\u001b[0m evals/tmpfminkgg4/test_kernel_sub.py - NameError: name 'KERNEL_SUB_SHAPES_FOR_PERF' is not defined\n",
      "\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n",
      "\u001b[31m=============================== \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 1.92s\u001b[0m\u001b[31m ===============================\u001b[0m\n",
      "\n",
      ", performance_metrics={}, combined_score=0.0000, correctness_score=0.0000, summary=Evaluation failed due to: Correctness tests failed (exit 2):\n",
      "STDOUT: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 0 items / 1 error\n",
      "\n",
      "==================================== ERRORS ====================================\n",
      "\u001b[31m\u001b[1m________ ERROR collecting tutorial/evals/tmpfminkgg4/test_kernel_sub.py ________\u001b[0m\n",
      "\u001b[1m\u001b[31mevals/tmpfminkgg4/test_kernel_sub.py\u001b[0m:234: in <module>\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, KERNEL_SUB_SHAPES_FOR_PERF)\u001b[90m\u001b[39;49;00m\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE   NameError: name 'KERNEL_SUB_SHAPES_FOR_PERF' is not defined\u001b[0m\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mERROR\u001b[0m evals/tmpfminkgg4/test_kernel_sub.py - NameError: name 'KERNEL_SUB_SHAPES_FOR_PERF' is not defined\n",
      "\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n",
      "\u001b[31m=============================== \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 1.92s\u001b[0m\u001b[31m ===============================\u001b[0m\n",
      "\n",
      ", safety_validation={'success': False, 'error': 'Correctness tests failed (exit 2):\\nSTDOUT: \\x1b[1m============================= test session starts ==============================\\x1b[0m\\nplatform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\\ncachedir: .pytest_cache\\nrootdir: /home/sapmajum/neurips/geak-openevolve\\nconfigfile: pyproject.toml\\nplugins: timeout-2.4.0, anyio-4.11.0\\n\\x1b[1mcollecting ... \\x1b[0mcollected 0 items / 1 error\\n\\n==================================== ERRORS ====================================\\n\\x1b[31m\\x1b[1m________ ERROR collecting tutorial/evals/tmpfminkgg4/test_kernel_sub.py ________\\x1b[0m\\n\\x1b[1m\\x1b[31mevals/tmpfminkgg4/test_kernel_sub.py\\x1b[0m:234: in <module>\\n    \\x1b[0m\\x1b[37m@pytest\\x1b[39;49;00m.mark.parametrize(\\x1b[33m\"\\x1b[39;49;00m\\x1b[33mshape\\x1b[39;49;00m\\x1b[33m\"\\x1b[39;49;00m, KERNEL_SUB_SHAPES_FOR_PERF)\\x1b[90m\\x1b[39;49;00m\\n                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\\x1b[90m\\x1b[39;49;00m\\n\\x1b[1m\\x1b[31mE   NameError: name \\'KERNEL_SUB_SHAPES_FOR_PERF\\' is not defined\\x1b[0m\\n\\x1b[36m\\x1b[1m=========================== short test summary info ============================\\x1b[0m\\n\\x1b[31mERROR\\x1b[0m evals/tmpfminkgg4/test_kernel_sub.py - NameError: name \\'KERNEL_SUB_SHAPES_FOR_PERF\\' is not defined\\n\\x1b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\\x1b[0m\\n!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\\n\\x1b[31m=============================== \\x1b[31m\\x1b[1m1 error\\x1b[0m\\x1b[31m in 1.92s\\x1b[0m\\x1b[31m ===============================\\x1b[0m\\n\\n'}, llm_readability=0.0000, llm_maintainability=0.0000, llm_efficiency=0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ›¡ï¸ BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpugt_q4dm/test_kernel_sub.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpugt_q4dm/test_kernel_sub.py\n",
      "ğŸ“ Extracted kernel name from program_text: test_kernel_sub.py\n",
      "ğŸ“ Final kernel name for test merging: test_kernel_sub.py\n",
      "âœ… Detected @triton.autotune - using ROCm_v1_autotune tests\n",
      "âœ… Merged kernel with test code from ROCm_v1_autotune\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpugt_q4dm/test_kernel_sub.py -k not (test_performance or test_save)\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpugt_q4dm/test_kernel_sub.py -k test_performance or test_save_performance_results\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 45 items / 2 deselected / 43 selected\n",
      "\n",
      "evals/tmpugt_q4dm/test_kernel_sub.py::test_performance[1-fp32-1024] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpugt_q4dm/perf\n",
      "Found 1 JSON files: ['kernel_sub_triton_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpugt_q4dm/perf/kernel_sub_triton_perf.json (most recent)\n",
      "Performance data structure: ['params', 'ms', 'min_ms', 'max_ms', 'GB/s', 'TFLOPS']\n",
      "Performance: 0.0062ms (from key 'ms')\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Calculated speedup: 0.006900ms / 0.006200ms = 1.1129x\n",
      "ğŸ›¡ï¸ BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpmz67x8df/test_kernel_sub.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpmz67x8df/test_kernel_sub.py\n",
      "ğŸ“ Extracted kernel name from program_text: test_kernel_sub.py\n",
      "ğŸ“ Final kernel name for test merging: test_kernel_sub.py\n",
      "âœ… Detected @triton.autotune - using ROCm_v1_autotune tests\n",
      "âœ… Merged kernel with test code from ROCm_v1_autotune\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpmz67x8df/test_kernel_sub.py -k not (test_performance or test_save)\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpmz67x8df/test_kernel_sub.py -k test_performance or test_save_performance_results\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 45 items / 2 deselected / 43 selected\n",
      "\n",
      "evals/tmpmz67x8df/test_kernel_sub.py::test_performance[1-fp32-1024] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpmz67x8df/perf\n",
      "Found 1 JSON files: ['kernel_sub_triton_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpmz67x8df/perf/kernel_sub_triton_perf.json (most recent)\n",
      "Performance data structure: ['params', 'ms', 'min_ms', 'max_ms', 'GB/s', 'TFLOPS']\n",
      "Performance: 0.006ms (from key 'ms')\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Calculated speedup: 0.006900ms / 0.006000ms = 1.1500x\n",
      "ğŸ›¡ï¸ BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpfminkgg4/test_kernel_sub.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpfminkgg4/test_kernel_sub.py\n",
      "ğŸ“ Extracted kernel name from program_text: test_kernel_sub.py\n",
      "ğŸ“ Final kernel name for test merging: test_kernel_sub.py\n",
      "âœ… Detected @triton.autotune - using ROCm_v1_autotune tests\n",
      "âœ… Merged kernel with test code from ROCm_v1_autotune\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpfminkgg4/test_kernel_sub.py -k not (test_performance or test_save)\n",
      "Correctness tests failed. Return code: 2\n",
      "STDOUT: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 0 items / 1 error\n",
      "\n",
      "==================================== ERRORS ====================================\n",
      "\u001b[31m\u001b[1m________ ERROR collecting tutorial/evals/tmpfminkgg4/test_kernel_sub.py ________\u001b[0m\n",
      "\u001b[1m\u001b[31mevals/tmpfminkgg4/test_kernel_sub.py\u001b[0m:234: in <module>\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m\"\u001b[39;49;00m\u001b[33mshape\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, KERNEL_SUB_SHAPES_FOR_PERF)\u001b[90m\u001b[39;49;00m\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE   NameError: name 'KERNEL_SUB_SHAPES_FOR_PERF' is not defined\u001b[0m\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mERROR\u001b[0m evals/tmpfminkgg4/test_kernel_sub.py - NameError: name 'KERNEL_SUB_SHAPES_FOR_PERF' is not defined\n",
      "\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n",
      "\u001b[31m=============================== \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 1.92s\u001b[0m\u001b[31m ===============================\u001b[0m\n",
      "\n",
      "STDERR: \n",
      "ğŸ›¡ï¸ BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpvnjjsam7/test_kernel_sub.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpvnjjsam7/test_kernel_sub.py\n",
      "ğŸ“ Extracted kernel name from program_text: test_kernel_sub.py\n",
      "ğŸ“ Final kernel name for test merging: test_kernel_sub.py\n",
      "âœ… Detected @triton.autotune - using ROCm_v1_autotune tests\n",
      "âœ… Merged kernel with test code from ROCm_v1_autotune\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpvnjjsam7/test_kernel_sub.py -k not (test_performance or test_save)\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpvnjjsam7/test_kernel_sub.py -k test_performance or test_save_performance_results\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 45 items / 2 deselected / 43 selected\n",
      "\n",
      "evals/tmpvnjjsam7/test_kernel_sub.py::test_performance[1-fp32-1024] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpvnjjsam7/perf\n",
      "Found 1 JSON files: ['kernel_sub_triton_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpvnjjsam7/perf/kernel_sub_triton_perf.json (most recent)\n",
      "Performance data structure: ['params', 'ms', 'min_ms', 'max_ms', 'GB/s', 'TFLOPS']\n",
      "Performance: 0.006ms (from key 'ms')\n",
      "Loaded baseline latency from file: 0.006900ms"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 20:44:05,043 - INFO - Time spent in evaluation: 42.49 seconds\n",
      "2025-11-26 20:44:05,043 - INFO - ğŸ¯ Using system_message from template override: evaluator_system_message (7482 chars)\n",
      "2025-11-26 20:44:14,811 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:44:14,813 - INFO - Time spent in LLM evaluation: 9.77 seconds\n",
      "2025-11-26 20:44:14,813 - INFO - Evaluated program cc9afe6d-826c-4634-9f6c-4854d5c14529 in 9.77s: success=1.0000, final_score=1.1500, performance_metrics=1.1500, correctness_score=1.0000, combined_score=1.1500, benchmark_results=['Performance report: Kernel parameters: N_val=1024; dtype_str=fp32; num_warps=1, achieved latency: 0.006000 ms, speedup: 1.1500x.'], baseline_comparison=Performance report: Kernel parameters: N_val=1024; dtype_str=fp32; num_warps=1, achieved latency: 0.006000 ms, speedup: 1.1500x. Speedup=1.1500x (baseline: 0.006900ms, current: 0.006000ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 1.1500x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None, llm_readability=0.0450, llm_maintainability=0.0400, llm_efficiency=0.0700\n",
      "2025-11-26 20:44:20,493 - INFO - Time spent in evaluation: 5.68 seconds\n",
      "2025-11-26 20:44:20,493 - INFO - ğŸ¯ Using system_message from template override: evaluator_system_message (7482 chars)\n",
      "2025-11-26 20:44:30,496 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:44:30,498 - INFO - Time spent in LLM evaluation: 10.01 seconds\n",
      "2025-11-26 20:44:30,498 - INFO - Evaluated program 7c2dc62b-51b0-4cef-83c3-12a3c7059506 in 10.01s: success=0.0000, final_score=0.0000, performance_metrics=0.0000, correctness_score=1.0000, combined_score=0.0000, benchmark_results=['Performance report: Achieved latency: 0.000000 ms, speedup: 0.0000x.'], baseline_comparison=The Triton kernel failed to benchmark, so no performance comparison can be made., individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel failed to benchmark., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None, llm_readability=0.0000, llm_maintainability=0.0000, llm_efficiency=0.0000\n",
      "2025-11-26 20:44:30,499 - INFO - Child programs evaluated in 5.72 minutes\n",
      "2025-11-26 20:44:30,499 - INFO - Updated sampling model 0 with reward 1.15\n",
      "2025-11-26 20:44:30,499 - INFO - New best program ecca2e01-1e67-43c5-8951-3178d69444b1 replaces 0b7d30a9-3edc-4b07-972e-ec152134c1b8 (combined_score: 1.0147 â†’ 1.1500, +0.1353)\n",
      "2025-11-26 20:44:30,500 - INFO - ğŸŒŸ New best solution found at iteration 1: ecca2e01-1e67-43c5-8951-3178d69444b1\n",
      "2025-11-26 20:44:30,500 - INFO - Metrics: success=1.0000, final_score=1.1500, performance_metrics=1.1500, correctness_score=1.0000, combined_score=1.1500, benchmark_results=['Performance report: Kernel parameters: N_val=1024; dtype_str=fp32; num_warps=1, achieved latency: 0.006000 ms, speedup: 1.1500x.'], baseline_comparison=Performance report: Kernel parameters: N_val=1024; dtype_str=fp32; num_warps=1, achieved latency: 0.006000 ms, speedup: 1.1500x. Speedup=1.1500x (baseline: 0.006900ms, current: 0.006000ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 1.1500x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None, llm_readability=0.0550, llm_maintainability=0.0450, llm_efficiency=0.0700\n",
      "2025-11-26 20:44:30,500 - INFO - Updated sampling model 0 with reward 1.1311475409836065\n",
      "2025-11-26 20:44:30,500 - INFO - Updated sampling model 0 with reward 1.1311475409836065\n",
      "2025-11-26 20:44:30,501 - INFO - Updated sampling model 0 with reward 1.1129032258064517\n",
      "2025-11-26 20:44:30,501 - INFO - Updated sampling model 0 with reward 1.15\n",
      "2025-11-26 20:44:30,502 - INFO - Updated sampling model 0 with reward 0.0\n",
      "2025-11-26 20:44:30,502 - INFO - Updated sampling model 0 with reward 1.15\n",
      "2025-11-26 20:44:30,503 - INFO - Updated sampling model 0 with reward 0.0\n",
      "2025-11-26 20:44:30,503 - INFO - Iteration 1: Child 7c2dc62b-51b0-4cef-83c3-12a3c7059506 from parent 0b7d30a9-3edc-4b07-972e-ec152134c1b8 in 420.82s. Metrics: success=0.0000, final_score=0.0000, performance_metrics=0.0000, correctness_score=1.0000, combined_score=0.0000, benchmark_results=['Performance report: Achieved latency: 0.000000 ms, speedup: 0.0000x.'], baseline_comparison=The Triton kernel failed to benchmark, so no performance comparison can be made., individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel failed to benchmark., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None, llm_readability=0.0000, llm_maintainability=0.0000, llm_efficiency=0.0000 (Î”: success=-1.0000, final_score=-1.0147, performance_metrics=-1.0147, correctness_score=+0.0000, combined_score=-1.0147, llm_readability=-0.0450, llm_maintainability=-0.0350, llm_efficiency=-0.0500)\n",
      "2025-11-26 20:44:30,504 - INFO - ğŸ¯ Using system_message from template: 'system_message' (14058 chars)\n",
      "2025-11-26 20:44:30,506 - INFO - Sampled model: claude-sonnet-4-5\n",
      "2025-11-26 20:44:30,507 - INFO - Sampled model: claude-sonnet-4-5\n",
      "2025-11-26 20:44:30,507 - INFO - Sampled model: claude-sonnet-4-5\n",
      "2025-11-26 20:44:30,507 - INFO - Sampled model: claude-sonnet-4-5\n",
      "2025-11-26 20:44:30,510 - INFO - Sampled model: claude-sonnet-4-5\n",
      "2025-11-26 20:44:30,510 - INFO - Sampled model: claude-sonnet-4-5\n",
      "2025-11-26 20:44:30,510 - INFO - Sampled model: claude-sonnet-4-5\n",
      "2025-11-26 20:44:30,522 - INFO - Sampled model: claude-sonnet-4-5\n",
      "2025-11-26 20:45:00,911 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:45:00,972 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:45:05,404 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:45:05,870 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:45:07,111 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:45:08,157 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:45:08,683 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:45:11,004 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:45:11,048 - INFO - LLM responses generated in 40.54 seconds\n",
      "2025-11-26 20:45:56,881 - INFO - Time spent in evaluation: 45.83 seconds\n",
      "2025-11-26 20:45:56,881 - INFO - ğŸ¯ Using system_message from template override: evaluator_system_message (7482 chars)\n",
      "2025-11-26 20:46:06,489 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:46:06,491 - INFO - Time spent in LLM evaluation: 9.61 seconds\n",
      "2025-11-26 20:46:06,491 - INFO - Evaluated program 8f535f86-6fac-4501-8cca-b3882af47aa6 in 9.61s: success=1.0000, final_score=1.1500, performance_metrics=1.1500, correctness_score=1.0000, combined_score=1.1500, benchmark_results=['Performance report: Kernel parameters: N_val=1024; dtype_str=fp32; num_warps=1, achieved latency: 0.006000 ms, speedup: 1.1500x.'], baseline_comparison=Performance report: Kernel parameters: N_val=1024; dtype_str=fp32; num_warps=1, achieved latency: 0.006000 ms, speedup: 1.1500x. Speedup=1.1500x (baseline: 0.006900ms, current: 0.006000ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 1.1500x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None, llm_readability=0.0650, llm_maintainability=0.0550, llm_efficiency=0.0750\n",
      "2025-11-26 20:46:59,693 - INFO - Time spent in evaluation: 53.20 seconds\n",
      "2025-11-26 20:46:59,693 - INFO - ğŸ¯ Using system_message from template override: evaluator_system_message (7482 chars)\n",
      "2025-11-26 20:47:08,141 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:47:08,143 - INFO - Time spent in LLM evaluation: 8.45 seconds\n",
      "2025-11-26 20:47:08,143 - INFO - Evaluated program f31e61dd-dde2-47eb-9b6a-740253e7859a in 8.45s: success=1.0000, final_score=1.1311, performance_metrics=1.1311, correctness_score=1.0000, combined_score=1.1311, benchmark_results=['Performance report: Kernel parameters: N_val=1024; dtype_str=fp32; num_warps=1, achieved latency: 0.006100 ms, speedup: 1.1311x.'], baseline_comparison=Performance report: Kernel parameters: N_val=1024; dtype_str=fp32; num_warps=1, achieved latency: 0.006100 ms, speedup: 1.1311x. Speedup=1.1311x (baseline: 0.006900ms, current: 0.006100ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 1.1311x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None, llm_readability=0.0450, llm_maintainability=0.0350, llm_efficiency=0.0700\n",
      "2025-11-26 20:47:54,116 - INFO - Time spent in evaluation: 45.97 seconds\n",
      "2025-11-26 20:47:54,116 - INFO - ğŸ¯ Using system_message from template override: evaluator_system_message (7482 chars)\n",
      "2025-11-26 20:48:01,633 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:48:01,635 - INFO - Time spent in LLM evaluation: 7.52 seconds\n",
      "2025-11-26 20:48:01,635 - INFO - Evaluated program 9155b44f-8925-4fab-b933-2d763dfe40ea in 7.52s: success=1.0000, final_score=1.1500, performance_metrics=1.1500, correctness_score=1.0000, combined_score=1.1500, benchmark_results=['Performance report: Kernel parameters: N_val=1024; dtype_str=fp32; num_warps=1, achieved latency: 0.006000 ms, speedup: 1.1500x.'], baseline_comparison=Performance report: Kernel parameters: N_val=1024; dtype_str=fp32; num_warps=1, achieved latency: 0.006000 ms, speedup: 1.1500x. Speedup=1.1500x (baseline: 0.006900ms, current: 0.006000ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 1.1500x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None, llm_readability=0.0550, llm_maintainability=0.0450, llm_efficiency=0.0700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculated speedup: 0.006900ms / 0.006000ms = 1.1500x\n",
      "ğŸ›¡ï¸ BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp8e2412h7/test_kernel_sub.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp8e2412h7/test_kernel_sub.py\n",
      "ğŸ“ Extracted kernel name from program_text: test_kernel_sub.py\n",
      "ğŸ“ Final kernel name for test merging: test_kernel_sub.py\n",
      "âœ… Detected @triton.autotune - using ROCm_v1_autotune tests\n",
      "âœ… Merged kernel with test code from ROCm_v1_autotune\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp8e2412h7/test_kernel_sub.py -k not (test_performance or test_save)\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp8e2412h7/test_kernel_sub.py -k test_performance or test_save_performance_results\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 45 items / 2 deselected / 43 selected\n",
      "\n",
      "evals/tmp8e2412h7/test_kernel_sub.py::test_performance[1-fp32-1024] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp8e2412h7/perf\n",
      "Found 1 JSON files: ['kernel_sub_triton_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp8e2412h7/perf/kernel_sub_triton_perf.json (most recent)\n",
      "Performance data structure: ['params', 'error']\n",
      "Available keys in perf data: dict_keys(['params', 'error'])\n",
      "Warning: No benchmark data available\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Warning: Invalid benchmark 0.0, setting speedup to 0.0\n",
      "ğŸ›¡ï¸ BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpppzzp3zu/test_kernel_sub.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpppzzp3zu/test_kernel_sub.py\n",
      "ğŸ“ Extracted kernel name from program_text: test_kernel_sub.py\n",
      "ğŸ“ Final kernel name for test merging: test_kernel_sub.py\n",
      "âœ… Detected @triton.autotune - using ROCm_v1_autotune tests\n",
      "âœ… Merged kernel with test code from ROCm_v1_autotune\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpppzzp3zu/test_kernel_sub.py -k not (test_performance or test_save)\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpppzzp3zu/test_kernel_sub.py -k test_performance or test_save_performance_results\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 45 items / 2 deselected / 43 selected\n",
      "\n",
      "evals/tmpppzzp3zu/test_kernel_sub.py::test_performance[1-fp32-1024] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpppzzp3zu/perf\n",
      "Found 1 JSON files: ['kernel_sub_triton_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpppzzp3zu/perf/kernel_sub_triton_perf.json (most recent)\n",
      "Performance data structure: ['params', 'ms', 'min_ms', 'max_ms', 'GB/s', 'TFLOPS']\n",
      "Performance: 0.006ms (from key 'ms')\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Calculated speedup: 0.006900ms / 0.006000ms = 1.1500x\n",
      "ğŸ›¡ï¸ BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpvbmh_zmq/test_kernel_sub.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpvbmh_zmq/test_kernel_sub.py\n",
      "ğŸ“ Extracted kernel name from program_text: test_kernel_sub.py\n",
      "ğŸ“ Final kernel name for test merging: test_kernel_sub.py\n",
      "âœ… Detected @triton.autotune - using ROCm_v1_autotune tests\n",
      "âœ… Merged kernel with test code from ROCm_v1_autotune\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpvbmh_zmq/test_kernel_sub.py -k not (test_performance or test_save)\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpvbmh_zmq/test_kernel_sub.py -k test_performance or test_save_performance_results\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 45 items / 2 deselected / 43 selected\n",
      "\n",
      "evals/tmpvbmh_zmq/test_kernel_sub.py::test_performance[1-fp32-1024] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpvbmh_zmq/perf\n",
      "Found 1 JSON files: ['kernel_sub_triton_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpvbmh_zmq/perf/kernel_sub_triton_perf.json (most recent)\n",
      "Performance data structure: ['params', 'ms', 'min_ms', 'max_ms', 'GB/s', 'TFLOPS']\n",
      "Performance: 0.0061ms (from key 'ms')\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Calculated speedup: 0.006900ms / 0.006100ms = 1.1311x\n",
      "ğŸ›¡ï¸ BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp5000jr1a/test_kernel_sub.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp5000jr1a/test_kernel_sub.py\n",
      "ğŸ“ Extracted kernel name from program_text: test_kernel_sub.py\n",
      "ğŸ“ Final kernel name for test merging: test_kernel_sub.py\n",
      "âœ… Detected @triton.autotune - using ROCm_v1_autotune tests\n",
      "âœ… Merged kernel with test code from ROCm_v1_autotune\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp5000jr1a/test_kernel_sub.py -k not (test_performance or test_save)\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp5000jr1a/test_kernel_sub.py -k test_performance or test_save_performance_results\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 45 items / 2 deselected / 43 selected\n",
      "\n",
      "evals/tmp5000jr1a/test_kernel_sub.py::test_performance[1-fp32-1024] \u001b[32mPASSED\u001b[0m\u001b[32m [  2%]\u001b[0m\n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp5000jr1a/perf\n",
      "Found 1 JSON files: ['kernel_sub_triton_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp5000jr1a/perf/kernel_sub_triton_perf.json (most recent)\n",
      "Performance data structure: ['params', 'ms', 'min_ms', 'max_ms', 'GB/s', 'TFLOPS']\n",
      "Performance: 0.006ms (from key 'ms')\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Calculated speedup: 0.006900ms / 0.006000ms = 1.1500x\n",
      "ğŸ›¡ï¸ BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 20:48:45,898 - INFO - Time spent in evaluation: 44.26 seconds\n",
      "2025-11-26 20:48:45,898 - INFO - ğŸ¯ Using system_message from template override: evaluator_system_message (7482 chars)\n",
      "2025-11-26 20:49:01,490 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4-5/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 20:49:01,540 - INFO - Time spent in LLM evaluation: 15.64 seconds\n",
      "2025-11-26 20:49:01,541 - INFO - Evaluated program 98bd611b-196a-4d08-8265-0dbf7e5bb54f in 15.64s: success=1.0000, final_score=1.1500, performance_metrics=1.1500, correctness_score=1.0000, combined_score=1.1500, benchmark_results=['Performance report: Kernel parameters: N_val=1024; dtype_str=fp32; num_warps=1, achieved latency: 0.006000 ms, speedup: 1.1500x.'], baseline_comparison=Performance report: Kernel parameters: N_val=1024; dtype_str=fp32; num_warps=1, achieved latency: 0.006000 ms, speedup: 1.1500x. Speedup=1.1500x (baseline: 0.006900ms, current: 0.006000ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 1.1500x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None, llm_readability=0.0450, llm_maintainability=0.0350, llm_efficiency=0.0700\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Run OpenEvolve Evolution\n",
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "if not (INITIAL_KERNEL and EVALUATOR_PATH and CONFIG_FILE):\n",
    "    print(\"âŒ Missing required components!\")\n",
    "    print(f\"   Kernel:    {INITIAL_KERNEL is not None and Path(INITIAL_KERNEL).exists()}\")\n",
    "    print(f\"   Evaluator: {EVALUATOR_PATH is not None and Path(EVALUATOR_PATH).exists()}\")\n",
    "    print(f\"   Config:    {CONFIG_FILE is not None and Path(CONFIG_FILE).exists()}\")\n",
    "else:\n",
    "    command = [\n",
    "        \"openevolve-run\",\n",
    "        str(INITIAL_KERNEL),\n",
    "        str(EVALUATOR_PATH),\n",
    "        \"--config\", str(CONFIG_FILE),\n",
    "        \"--output\", str(OUTPUT_DIR)\n",
    "    ]\n",
    "    \n",
    "    print(\"ğŸš€ Starting OpenEvolve Evolution...\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"ğŸ“¦ Kernel:    {Path(INITIAL_KERNEL).name}\")\n",
    "    print(f\"âš™ï¸  Evaluator: {Path(EVALUATOR_PATH).name}\")\n",
    "    print(f\"ğŸ“‹ Config:    {Path(CONFIG_FILE).name}\")\n",
    "    print(f\"ğŸ“ Output:    {OUTPUT_DIR.relative_to(TUTORIAL_DIR)}\")\n",
    "    print(f\"ğŸ  Working Dir: {TUTORIAL_DIR}\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n$ cd {TUTORIAL_DIR}\")\n",
    "    print(f\"$ {' '.join(command)}\\n\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # CRITICAL: Run from tutorial directory where evals/ exists\n",
    "    result = subprocess.run(\n",
    "        command, \n",
    "        capture_output=False, \n",
    "        text=True,\n",
    "        cwd=str(TUTORIAL_DIR)  # Run from tutorial directory\n",
    "    )\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    if result.returncode == 0:\n",
    "        print(\"\\nâœ… Evolution completed successfully!\")\n",
    "        print(f\"\\nğŸ“Š Results saved to: {OUTPUT_DIR.relative_to(TUTORIAL_DIR)}\")\n",
    "    else:\n",
    "        print(f\"\\nâŒ Evolution failed with exit code: {result.returncode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487e1254",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddc1001",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b0007e",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a8be79-9637-4e9c-bf43-e9872e50b9a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf742275-e759-4e11-887d-2f573f2083fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527971c4-63d1-4a2c-86c7-4fa4d7c98c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e5d4df-1c2a-482a-94da-de6e883c83c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384ffc37-2f70-4b62-8e5b-94e589a7632f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac8d614-556f-433f-9a45-21506efeb9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53797f37-0e5f-4396-8e88-b8c382224845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce1bdcc-bc55-45cb-bc09-0eeb1496be51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de000255-0623-41ff-9bab-02257539c1b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1a7767-94a7-4ebf-a54e-90353e993976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9a5018-645f-43f8-81c6-09dc22462d94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3d04a5-dfa1-4f63-84c1-a0eeabf77212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78998e50-8844-45b7-8e11-20b017b5c0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab590940-9012-4aea-b6e9-f38af1d8b41e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb26f7f4-6100-4edf-b40b-37760d4d0d46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
