{"instruction": "You are a expert in writing Triton operators for efficient GPU programming. Use triton language write a kernel and wrapper according following instruction.\n            The Triton-accelerated function embedding_kernel is specialized for extracting and storing embedding vectors from a weight matrix for a sequence of token IDs. It uses program IDs to determine processing offsets and handles iteration over sequences with BLOCK_N and BLOCK_NN stride sizes. For each sequence, it computes token IDs and uses masks to ensure only valid data is loaded and processed. The weight matrix is addressed using a combination of token IDs and dimension offsets, facilitated by the stride of the weight tensor. The processed vectors are then stored into the 'out' tensor using calculated strides and masks, ensuring each output sequence position receives the correct embedding vector. The wrapping function, embedding, configures and invokes the kernel with appropriate grid settings, aligning the number of warps and stages for optimal performance.\n            ", "label": "\nimport torch\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef embedding_kernel(\n    weight,\n    input_ids,\n    out,\n    vob_start_id,\n    vob_end_id,\n    stride_weight_seq,\n    stride_out_seq,\n    n_ctx,\n    hiden_size: tl.constexpr,\n    BLOCK_DMODEL: tl.constexpr,\n    BLOCK_N: tl.constexpr,\n    BLOCK_NN: tl.constexpr,\n):\n    start_n = tl.program_id(0) * BLOCK_N\n\n    offs_nn = start_n + tl.arange(0, BLOCK_NN)\n    offs_d = tl.arange(0, BLOCK_DMODEL)\n\n    for start_nn in range(0, BLOCK_N, BLOCK_NN):\n        start_nn = tl.multiple_of(start_nn, BLOCK_NN)\n        offs_seq = start_nn + offs_nn\n        n_ctx_mask = offs_seq < n_ctx\n        token_ids = tl.load(input_ids + offs_seq, mask=n_ctx_mask, other=vob_end_id)\n        id_mask = (token_ids >= vob_start_id) & (token_ids < vob_end_id)\n        token_ids = token_ids - vob_start_id\n        dim_mask = offs_d < hiden_size\n        load_mask = id_mask[:, None] & dim_mask[None, :]\n        store_mask = n_ctx_mask[:, None] & dim_mask[None, :]\n        vecs = tl.load(weight + token_ids[:, None] * stride_weight_seq + offs_d[None, :], mask=load_mask, other=0.0)\n        tl.store(out + offs_seq[:, None] * stride_out_seq + offs_d[None, :], vecs, mask=store_mask)\n\n@torch.no_grad()\ndef embedding(input_ids, weight: torch.Tensor, vob_start_id, vob_end_id, out: torch.Tensor):\n    BLOCK_N = 64\n    BLOCK_NN = 1\n    BLOCK_DMODEL = triton.next_power_of_2(weight.shape[1])\n    n_ctx = input_ids.shape[0]\n\n    grid = (triton.cdiv(n_ctx, BLOCK_N), 1, 1)\n\n    embedding_kernel[grid](\n        weight,\n        input_ids,\n        out,\n        vob_start_id,\n        vob_end_id,\n        weight.stride(0),\n        out.stride(0),\n        n_ctx=n_ctx,\n        hiden_size=weight.shape[1],\n        BLOCK_DMODEL=BLOCK_DMODEL,\n        BLOCK_N=BLOCK_N,\n        BLOCK_NN=BLOCK_NN,\n        num_warps=1,\n        num_stages=1,\n    )\n\n\n\n", "filename": "embedding_triton_kernel.py", "test_code": "import torch\n\ndef test_embedding():\n    # \u53c2\u6570\u5b9a\u4e49\n    vocab_size = 1000         # \u8bcd\u6c47\u8868\u5927\u5c0f\n    embedding_dim = 512       # \u5d4c\u5165\u7ef4\u5ea6\n    sequence_length = 128     # \u8f93\u5165\u5e8f\u5217\u957f\u5ea6\n    vob_start_id = 10         # \u8bcd\u6c47\u8868\u8d77\u59cb ID\n    vob_end_id = 1000         # \u8bcd\u6c47\u8868\u7ed3\u675f ID\n\n    # \u521b\u5efa\u6d4b\u8bd5\u8f93\u5165\u5f20\u91cf\n    input_ids = torch.randint(\n        vob_start_id, vob_end_id, (sequence_length,), dtype=torch.int32, device='cuda'\n    )\n    weight = torch.randn(\n        vocab_size, embedding_dim, dtype=torch.float32, device='cuda'\n    )\n    out = torch.zeros(\n        sequence_length, embedding_dim, dtype=torch.float32, device='cuda'\n    )\n\n    # \u8c03\u7528\u5d4c\u5165\u51fd\u6570\n    embedding(input_ids, weight, vob_start_id, vob_end_id, out)\n\n    # \u4fdd\u5b58\u7ed3\u679c\n    results = {}\n    results['test_case_1'] = out.clone()\n\n    # \u6d4b\u8bd5\u4e0d\u540c\u7684\u8f93\u5165\n    input_ids = torch.randint(\n        vob_start_id, vob_end_id, (sequence_length,), dtype=torch.int32, device='cuda'\n    )\n    embedding(input_ids, weight, vob_start_id, vob_end_id, out)\n    results['test_case_2'] = out.clone()\n\n    # \u6d4b\u8bd5\u4e0d\u540c\u7684\u8bcd\u6c47\u8868\u8303\u56f4\n    vob_start_id = 0\n    vob_end_id = 500\n    input_ids = torch.randint(\n        vob_start_id, vob_end_id, (sequence_length,), dtype=torch.int32, device='cuda'\n    )\n    embedding(input_ids, weight, vob_start_id, vob_end_id, out)\n    results['test_case_3'] = out.clone()\n\n    # \u6d4b\u8bd5\u4e0d\u540c\u7684\u5d4c\u5165\u7ef4\u5ea6\n    embedding_dim = 256\n    weight = torch.randn(\n        vocab_size, embedding_dim, dtype=torch.float32, device='cuda'\n    )\n    out = torch.zeros(\n        sequence_length, embedding_dim, dtype=torch.float32, device='cuda'\n    )\n    embedding(input_ids, weight, vob_start_id, vob_end_id, out)\n    results['test_case_4'] = out.clone()\n\n    return results\n\nresult_gold = test_embedding()", "predict": "import torch\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef embedding_kernel(\n    weight,\n    input_ids,\n    out,\n    vob_start_id,\n    vob_end_id,\n    stride_weight_seq,\n    stride_out_seq,\n    n_ctx,\n    hiden_size: tl.constexpr,\n    BLOCK_DMODEL: tl.constexpr,\n    BLOCK_N: tl.constexpr,\n    BLOCK_NN: tl.constexpr,\n):\n    # sequence dimension program id\n    pid_m = tl.program_id(0)\n    # hidden dimension program id\n    pid_k = tl.program_id(1)\n\n    # Determine loop bounds for this program ID\n    # We process BLOCK_N tokens per pid_m\n    offs_m = pid_m * BLOCK_N + tl.arange(0, BLOCK_N)\n    \n    # We process BLOCK_DMODEL hidden elements per pid_k\n    offs_k = pid_k * BLOCK_DMODEL + tl.arange(0, BLOCK_DMODEL)\n\n    # Create masks for boundary checks\n    mask_m = offs_m < n_ctx\n    mask_k = offs_k < hiden_size\n\n    # Load input IDs\n    # input_ids is 1D (flattened) or addressed as such\n    ids_ptr = input_ids + offs_m\n    ids = tl.load(ids_ptr, mask=mask_m, other=0)\n\n    # Check if the IDs are within the vocabulary range for this partition\n    valid_id_mask = (ids >= vob_start_id) & (ids < vob_end_id)\n    \n    # Combine valid ID mask with the sequence boundary mask\n    # We need to broadcast to match the [BLOCK_N, BLOCK_DMODEL] shape of the weight block\n    load_mask = mask_m[:, None] & mask_k[None, :] & valid_id_mask[:, None]\n\n    # Calculate offsets into the weight matrix\n    # The weight matrix row index is (id - vob_start_id)\n    # We use indirect addressing: weight_base + row_offset + col_offset\n    # Note: ids is [BLOCK_N], stride_weight_seq applies to the row dimension\n    current_ids = ids - vob_start_id\n    weight_ptr = weight + (current_ids[:, None] * stride_weight_seq) + offs_k[None, :]\n\n    # Load weights\n    # If the ID is invalid (out of range), we load 0.0\n    weight_vals = tl.load(weight_ptr, mask=load_mask, other=0.0)\n\n    # Store results to output\n    # Output layout is [N_CTX, Hidden]\n    out_ptr = out + (offs_m[:, None] * stride_out_seq) + offs_k[None, :]\n    \n    # We only store if we are within bounds of N_CTX and Hiden_Size\n    # Note: If the ID was invalid, we stored 0.0 into weight_vals, so we write 0.0 to out.\n    # This assumes 'out' is initialized or overwriting with 0 is desired for OOB tokens in this partition.\n    store_mask = mask_m[:, None] & mask_k[None, :]\n    tl.store(out_ptr, weight_vals, mask=store_mask)\n\n\ndef embedding(input_ids, weight: torch.Tensor, vob_start_id, vob_end_id, out: torch.Tensor):\n    # Flatten input_ids to simplify kernel logic (treat as 1D sequence of tokens)\n    n_ctx = input_ids.numel()\n    \n    # Dimensions\n    hiden_size = weight.shape[1]\n    \n    # Strides\n    stride_weight_seq = weight.stride(0)\n    stride_out_seq = out.stride(0)\n    \n    # Block configurations\n    # Heuristic: Tile over Sequence (N) and Hidden (DMODEL)\n    BLOCK_N = 64\n    BLOCK_NN = 64  # Matching BLOCK_N as requested signature parameter\n    \n    # Adjust BLOCK_DMODEL based on hidden size to maximize occupancy\n    # Must be a power of 2 for optimal performance\n    if hiden_size >= 256:\n        BLOCK_DMODEL = 128\n    elif hiden_size >= 128:\n        BLOCK_DMODEL = 128\n    else:\n        BLOCK_DMODEL = 64\n        \n    # Grid definition: (Sequence Blocks, Hidden Blocks)\n    grid = lambda META: (\n        triton.cdiv(n_ctx, META['BLOCK_N']),\n        triton.cdiv(hiden_size, META['BLOCK_DMODEL'])\n    )\n    \n    embedding_kernel[grid](\n        weight,\n        input_ids,\n        out,\n        vob_start_id,\n        vob_end_id,\n        stride_weight_seq,\n        stride_out_seq,\n        n_ctx,\n        hiden_size=hiden_size,\n        BLOCK_DMODEL=BLOCK_DMODEL,\n        BLOCK_N=BLOCK_N,\n        BLOCK_NN=BLOCK_NN,\n    )\n", "speedup": 3.6953}
