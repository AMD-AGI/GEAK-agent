{"instruction": "You are a expert in writing Triton operators for efficient GPU programming. Use triton language write a kernel and wrapper according following instruction.\n            The Triton-accelerated function embedding_kernel is specialized for extracting and storing embedding vectors from a weight matrix for a sequence of token IDs. It uses program IDs to determine processing offsets and handles iteration over sequences with BLOCK_N and BLOCK_NN stride sizes. For each sequence, it computes token IDs and uses masks to ensure only valid data is loaded and processed. The weight matrix is addressed using a combination of token IDs and dimension offsets, facilitated by the stride of the weight tensor. The processed vectors are then stored into the 'out' tensor using calculated strides and masks, ensuring each output sequence position receives the correct embedding vector. The wrapping function, embedding, configures and invokes the kernel with appropriate grid settings, aligning the number of warps and stages for optimal performance.\n            ", "label": "\nimport torch\nimport triton\nimport triton.language as tl\n\n@triton.jit\ndef embedding_kernel(\n    weight,\n    input_ids,\n    out,\n    vob_start_id,\n    vob_end_id,\n    stride_weight_seq,\n    stride_out_seq,\n    n_ctx,\n    hiden_size: tl.constexpr,\n    BLOCK_DMODEL: tl.constexpr,\n    BLOCK_N: tl.constexpr,\n    BLOCK_NN: tl.constexpr,\n):\n    start_n = tl.program_id(0) * BLOCK_N\n\n    offs_nn = start_n + tl.arange(0, BLOCK_NN)\n    offs_d = tl.arange(0, BLOCK_DMODEL)\n\n    for start_nn in range(0, BLOCK_N, BLOCK_NN):\n        start_nn = tl.multiple_of(start_nn, BLOCK_NN)\n        offs_seq = start_nn + offs_nn\n        n_ctx_mask = offs_seq < n_ctx\n        token_ids = tl.load(input_ids + offs_seq, mask=n_ctx_mask, other=vob_end_id)\n        id_mask = (token_ids >= vob_start_id) & (token_ids < vob_end_id)\n        token_ids = token_ids - vob_start_id\n        dim_mask = offs_d < hiden_size\n        load_mask = id_mask[:, None] & dim_mask[None, :]\n        store_mask = n_ctx_mask[:, None] & dim_mask[None, :]\n        vecs = tl.load(weight + token_ids[:, None] * stride_weight_seq + offs_d[None, :], mask=load_mask, other=0.0)\n        tl.store(out + offs_seq[:, None] * stride_out_seq + offs_d[None, :], vecs, mask=store_mask)\n\n@torch.no_grad()\ndef embedding(input_ids, weight: torch.Tensor, vob_start_id, vob_end_id, out: torch.Tensor):\n    BLOCK_N = 64\n    BLOCK_NN = 1\n    BLOCK_DMODEL = triton.next_power_of_2(weight.shape[1])\n    n_ctx = input_ids.shape[0]\n\n    grid = (triton.cdiv(n_ctx, BLOCK_N), 1, 1)\n\n    embedding_kernel[grid](\n        weight,\n        input_ids,\n        out,\n        vob_start_id,\n        vob_end_id,\n        weight.stride(0),\n        out.stride(0),\n        n_ctx=n_ctx,\n        hiden_size=weight.shape[1],\n        BLOCK_DMODEL=BLOCK_DMODEL,\n        BLOCK_N=BLOCK_N,\n        BLOCK_NN=BLOCK_NN,\n        num_warps=1,\n        num_stages=1,\n    )\n\n\n\n", "filename": "embedding_triton_kernel.py", "test_code": "import torch\n\ndef test_embedding():\n    # \u53c2\u6570\u5b9a\u4e49\n    vocab_size = 1000         # \u8bcd\u6c47\u8868\u5927\u5c0f\n    embedding_dim = 512       # \u5d4c\u5165\u7ef4\u5ea6\n    sequence_length = 128     # \u8f93\u5165\u5e8f\u5217\u957f\u5ea6\n    vob_start_id = 10         # \u8bcd\u6c47\u8868\u8d77\u59cb ID\n    vob_end_id = 1000         # \u8bcd\u6c47\u8868\u7ed3\u675f ID\n\n    # \u521b\u5efa\u6d4b\u8bd5\u8f93\u5165\u5f20\u91cf\n    input_ids = torch.randint(\n        vob_start_id, vob_end_id, (sequence_length,), dtype=torch.int32, device='cuda'\n    )\n    weight = torch.randn(\n        vocab_size, embedding_dim, dtype=torch.float32, device='cuda'\n    )\n    out = torch.zeros(\n        sequence_length, embedding_dim, dtype=torch.float32, device='cuda'\n    )\n\n    # \u8c03\u7528\u5d4c\u5165\u51fd\u6570\n    embedding(input_ids, weight, vob_start_id, vob_end_id, out)\n\n    # \u4fdd\u5b58\u7ed3\u679c\n    results = {}\n    results['test_case_1'] = out.clone()\n\n    # \u6d4b\u8bd5\u4e0d\u540c\u7684\u8f93\u5165\n    input_ids = torch.randint(\n        vob_start_id, vob_end_id, (sequence_length,), dtype=torch.int32, device='cuda'\n    )\n    embedding(input_ids, weight, vob_start_id, vob_end_id, out)\n    results['test_case_2'] = out.clone()\n\n    # \u6d4b\u8bd5\u4e0d\u540c\u7684\u8bcd\u6c47\u8868\u8303\u56f4\n    vob_start_id = 0\n    vob_end_id = 500\n    input_ids = torch.randint(\n        vob_start_id, vob_end_id, (sequence_length,), dtype=torch.int32, device='cuda'\n    )\n    embedding(input_ids, weight, vob_start_id, vob_end_id, out)\n    results['test_case_3'] = out.clone()\n\n    # \u6d4b\u8bd5\u4e0d\u540c\u7684\u5d4c\u5165\u7ef4\u5ea6\n    embedding_dim = 256\n    weight = torch.randn(\n        vocab_size, embedding_dim, dtype=torch.float32, device='cuda'\n    )\n    out = torch.zeros(\n        sequence_length, embedding_dim, dtype=torch.float32, device='cuda'\n    )\n    embedding(input_ids, weight, vob_start_id, vob_end_id, out)\n    results['test_case_4'] = out.clone()\n\n    return results\n\nresult_gold = test_embedding()", "predict": "import torch\nimport triton\nimport triton.language as tl\n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_DMODEL': 64, 'BLOCK_N': 64, 'BLOCK_NN': 64}, num_warps=4),\n        triton.Config({'BLOCK_DMODEL': 128, 'BLOCK_N': 64, 'BLOCK_NN': 64}, num_warps=4),\n        triton.Config({'BLOCK_DMODEL': 256, 'BLOCK_N': 64, 'BLOCK_NN': 64}, num_warps=8),\n        triton.Config({'BLOCK_DMODEL': 128, 'BLOCK_N': 64, 'BLOCK_NN': 64}, num_warps=8),\n        triton.Config({'BLOCK_DMODEL': 64, 'BLOCK_N': 64, 'BLOCK_NN': 64}, num_warps=8),\n    ],\n    key=['n_ctx', 'hiden_size'],\n)\n@triton.jit\ndef embedding_kernel(\n    weight,\n    input_ids,\n    out,\n    vob_start_id,\n    vob_end_id,\n    stride_weight_seq,\n    stride_out_seq,\n    n_ctx,\n    hiden_size: tl.constexpr,\n    BLOCK_DMODEL: tl.constexpr,\n    BLOCK_N: tl.constexpr,\n    BLOCK_NN: tl.constexpr,\n):\n    # 2D Grid: pid(0) handles Sequence, pid(1) handles Hidden Dimension\n    pid_m = tl.program_id(0)\n    pid_k = tl.program_id(1)\n\n    # 1. Sequence Dimension Offsets\n    # We process BLOCK_N tokens per program instance\n    offs_m = pid_m * BLOCK_N + tl.arange(0, BLOCK_N)\n    mask_m = offs_m < n_ctx\n\n    # 2. Hidden Dimension Offsets\n    # We process BLOCK_DMODEL hidden elements per program instance\n    offs_k = pid_k * BLOCK_DMODEL + tl.arange(0, BLOCK_DMODEL)\n    mask_k = offs_k < hiden_size\n\n    # 3. Load Input IDs\n    # input_ids is flattened; load BLOCK_N ids\n    input_ids_ptr = input_ids + offs_m\n    ids = tl.load(input_ids_ptr, mask=mask_m, other=0)\n\n    # 4. ID Validation\n    # Check if IDs are within the vocabulary shard range\n    valid_id_mask = (ids >= vob_start_id) & (ids < vob_end_id)\n    \n    # Combined mask: Valid Sequence Position AND Valid Vocabulary ID\n    token_mask = mask_m & valid_id_mask\n\n    # 5. Safe Pointer Arithmetic\n    # Clamp IDs to vob_start_id where invalid to ensure pointers are within valid memory regions\n    # independent of the mask. This prevents segfaults on OOB pointer calculation.\n    safe_ids = tl.where(valid_id_mask, ids, vob_start_id)\n    local_ids = safe_ids - vob_start_id\n\n    # 6. Address Calculation\n    # Weight address: base + (row * stride) + col\n    # Broadcast local_ids to [BLOCK_N, 1] and offs_k to [1, BLOCK_DMODEL]\n    weight_ptrs = weight + (local_ids[:, None] * stride_weight_seq) + offs_k[None, :]\n    \n    # Output address: base + (row * stride) + col\n    out_ptrs = out + (offs_m[:, None] * stride_out_seq) + offs_k[None, :]\n\n    # 7. Load and Store\n    # Load mask: Valid Token & Valid Hidden Dim\n    op_mask = token_mask[:, None] & mask_k[None, :]\n    \n    # Load embedding vectors. Invalid tokens/dims get 0.0.\n    weight_vals = tl.load(weight_ptrs, mask=op_mask, other=0.0)\n\n    # Store result.\n    # We write to output if valid sequence & valid hidden dim.\n    # Since we loaded 0.0 for invalid IDs, this effectively zeros out OOB embeddings.\n    store_mask = mask_m[:, None] & mask_k[None, :]\n    tl.store(out_ptrs, weight_vals, mask=store_mask)\n\n\ndef embedding(input_ids, weight: torch.Tensor, vob_start_id, vob_end_id, out: torch.Tensor):\n    # Ensure inputs are contiguous for correct pointer arithmetic\n    if not input_ids.is_contiguous():\n        input_ids = input_ids.contiguous()\n    \n    # Flatten input_ids to treat as a linear sequence\n    input_ids_flat = input_ids.view(-1)\n    \n    if not out.is_contiguous():\n        out = out.contiguous()\n\n    n_ctx = input_ids_flat.numel()\n    hiden_size = weight.shape[1]\n\n    # Calculate Strides\n    stride_weight_seq = weight.stride(0)\n    # Output stride relative to the sequence dimension (i.e., step to next token)\n    # out is [..., hidden], so stride(-2) is the stride for the token dimension\n    stride_out_seq = out.stride(-2)\n\n    # Grid Definition\n    # We use a lambda to allow autotuner to supply BLOCK_N and BLOCK_DMODEL\n    grid = lambda META: (\n        triton.cdiv(n_ctx, META['BLOCK_N']),\n        triton.cdiv(hiden_size, META['BLOCK_DMODEL'])\n    )\n\n    # Launch Kernel\n    # BLOCK_N, BLOCK_DMODEL, BLOCK_NN are handled by autotuner config\n    embedding_kernel[grid](\n        weight,\n        input_ids_flat,\n        out,\n        vob_start_id,\n        vob_end_id,\n        stride_weight_seq,\n        stride_out_seq,\n        n_ctx,\n        hiden_size=hiden_size,\n    )\n    \n    return out", "speedup": 3.7238}
