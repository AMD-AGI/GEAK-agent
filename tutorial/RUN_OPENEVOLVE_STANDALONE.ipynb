{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08ea7604",
   "metadata": {},
   "source": [
    "# OpenEvolve Standalone Tutorial\n",
    "\n",
    "This notebook demonstrates how to use **GEAK-OpenEvolve** for GPU kernel optimization using LLM-guided evolution.\n",
    "\n",
    "## Prerequisites\n",
    " **Environment Variables**: Set `OPENAI_API_KEY`\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- How to set up GEAK-OpenEvolve\n",
    "- How to prepare an initial kernel program\n",
    "- How to configure evolution parameters\n",
    "- How to run the evolution pipeline\n",
    "- How to analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24c9f27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenEvolve Root: /home/sapmajum/neurips/geak-openevolve\n",
      "\n",
      "‚úÖ OpenEvolve root: /home/sapmajum/neurips/geak-openevolve\n",
      "‚úÖ Python path updated\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Environment Setup\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get geak-openevolve root\n",
    "OPENEVOLVE_ROOT = Path.cwd().parent\n",
    "print(f\"OpenEvolve Root: {OPENEVOLVE_ROOT}\")\n",
    "\n",
    "# Add to Python path\n",
    "if str(OPENEVOLVE_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(OPENEVOLVE_ROOT))\n",
    "\n",
    "print(f\"\\n‚úÖ OpenEvolve root: {OPENEVOLVE_ROOT}\")\n",
    "print(f\"‚úÖ Python path updated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d39b24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GEAK-eval already exists at: /home/sapmajum/neurips/geak-openevolve/GEAK-eval-OE\n",
      "‚úÖ geak-eval command available: /home/sapmajum/miniconda3/bin/geak-eval\n"
     ]
    }
   ],
   "source": [
    "# Step 1.5: Clone and Install GEAK-eval (if not already done)\n",
    "import os\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "OPENEVOLVE_ROOT = Path.cwd().parent\n",
    "GEAK_EVAL_DIR = OPENEVOLVE_ROOT / \"GEAK-eval-OE\"\n",
    "\n",
    "if not GEAK_EVAL_DIR.exists():\n",
    "    print(\"üì• Cloning GEAK-eval...\")\n",
    "    os.chdir(OPENEVOLVE_ROOT)\n",
    "    \n",
    "    # Clone and checkout\n",
    "    subprocess.run([\"git\", \"clone\", \"git@github.com:AMD-AGI/GEAK-eval.git\", \"GEAK-eval-OE\"], check=True)\n",
    "    os.chdir(\"GEAK-eval-OE\")\n",
    "    subprocess.run([\"git\", \"checkout\", \"geak-oe\"], check=True)\n",
    "    \n",
    "    print(\"‚úÖ GEAK-eval cloned\")\n",
    "    \n",
    "    # Install\n",
    "    print(\"üì¶ Installing GEAK-eval...\")\n",
    "    subprocess.run([\"pip\", \"install\", \"-e\", \".\", \"--no-deps\"], check=True)\n",
    "    print(\"‚úÖ GEAK-eval installed\")\n",
    "else:\n",
    "    print(f\"‚úÖ GEAK-eval already exists at: {GEAK_EVAL_DIR}\")\n",
    "    \n",
    "    # Check if installed\n",
    "    try:\n",
    "        result = subprocess.run([\"which\", \"geak-eval\"], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"‚úÖ geak-eval command available: {result.stdout.strip()}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  geak-eval command not found, installing...\")\n",
    "            os.chdir(GEAK_EVAL_DIR)\n",
    "            subprocess.run([\"pip\", \"install\", \"-e\", \".\", \"--no-deps\"], check=True)\n",
    "            print(\"‚úÖ GEAK-eval installed\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Could not check geak-eval: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b9a1d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OPENAI_API_KEY set\n",
      "‚úÖ ROCM_GOLDEN_DATA_PATH = /home/sapmajum/neurips/geak-openevolve/GEAK-eval-OE/geak_eval/data/ROCm/data/performance/golden_results\n",
      "   Path exists: True\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Set Environment Variables\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set API key\n",
    "# os.environ['OPENAI_API_KEY'] = \"<your-api-key>\"\n",
    "\n",
    "# Set ROCM_GOLDEN_DATA_PATH\n",
    "OPENEVOLVE_ROOT = Path.cwd().parent\n",
    "GOLDEN_DATA_PATH = OPENEVOLVE_ROOT / \"GEAK-eval-OE/geak_eval/data/ROCm/data/performance/golden_results\"\n",
    "os.environ['ROCM_GOLDEN_DATA_PATH'] = str(GOLDEN_DATA_PATH)\n",
    "\n",
    "print(f\"‚úÖ OPENAI_API_KEY set\")\n",
    "print(f\"‚úÖ ROCM_GOLDEN_DATA_PATH = {GOLDEN_DATA_PATH}\")\n",
    "print(f\"   Path exists: {GOLDEN_DATA_PATH.exists()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e398dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.13.9\n",
      "PyTorch: 2.7.0.dev20250310+rocm6.2.4\n",
      "GPU: AMD Instinct MI325X\n",
      "Triton: 3.2.0\n",
      "OpenEvolve: 0.1.0\n",
      "\n",
      "‚úÖ Environment ready!\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Verify OpenEvolve Installation\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'N/A'}\")\n",
    "\n",
    "try:\n",
    "    import triton\n",
    "    print(f\"Triton: {triton.__version__}\")\n",
    "except:\n",
    "    print(\"‚ùå Triton not found\")\n",
    "\n",
    "try:\n",
    "    import openevolve\n",
    "    print(f\"OpenEvolve: {openevolve.__version__ if hasattr(openevolve, '__version__') else 'installed'}\")\n",
    "except:\n",
    "    print(\"‚ùå OpenEvolve not found - install with: pip install -e .\")\n",
    "\n",
    "print(\"\\n‚úÖ Environment ready!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9e193c",
   "metadata": {},
   "source": [
    "## Kernel Preparation\n",
    "\n",
    "OpenEvolve requires:\n",
    "1. **Initial Kernel**: The starting kernel code to optimize\n",
    "2. **Evaluator**: A function that evaluates kernel performance\n",
    "3. **Configuration**: Evolution parameters (iterations, population size, etc.)\n",
    "\n",
    "We'll use a validated ROCm Triton kernel as our example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25923f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Selected kernel: test_add_kernel.py\n",
      "   Path: GEAK-eval-OE/geak_eval/data/ROCm/data/ROCm_v1/test_add_kernel.py\n",
      "\n",
      "üìù Kernel Preview:\n",
      "   @triton.jit\n",
      "   def add_kernel(\n",
      "       x_ptr,\n",
      "       y_ptr,\n",
      "       output_ptr,\n",
      "       n_elements,\n",
      "       BLOCK_SIZE: tl.constexpr,\n",
      "   ):\n",
      "       pid = tl.program_id(axis=0)  # We use a 1D launch grid so axis is 0.\n",
      "       block_start = pid * BLOCK_SIZE\n",
      "       offsets = block_start + tl.arange(0, BLOCK_SIZE)\n",
      "       mask = offsets < n_elements\n",
      "   \n",
      "       x_block_ptr = tl.make_block_ptr(base=x_ptr, shape=(n_elements, ), strides=(1, ), offsets=(pid * BLOCK_SIZE, ),\n",
      "                                       block_shape=(BLOCK_SIZE, ), order=(0, ))\n",
      "   ... (5 more lines)\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Select Example Kernel\n",
    "from pathlib import Path\n",
    "\n",
    "OPENEVOLVE_ROOT = Path.cwd().parent\n",
    "TUTORIAL_DIR = OPENEVOLVE_ROOT / \"tutorial\"\n",
    "\n",
    "# Use kernel from GEAK-eval-OE (cloned GEAK-eval repository)\n",
    "INITIAL_KERNEL = OPENEVOLVE_ROOT / \"GEAK-eval-OE/geak_eval/data/ROCm/data/ROCm_v1/test_add_kernel.py\"\n",
    "\n",
    "if INITIAL_KERNEL.exists():\n",
    "    print(f\"‚úÖ Selected kernel: {INITIAL_KERNEL.name}\")\n",
    "    print(f\"   Path: {INITIAL_KERNEL.relative_to(OPENEVOLVE_ROOT)}\")\n",
    "    \n",
    "    # Quick peek at the kernel\n",
    "    with open(INITIAL_KERNEL, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Find the kernel function\n",
    "    in_kernel = False\n",
    "    kernel_lines = []\n",
    "    for line in lines:\n",
    "        if '@triton.jit' in line:\n",
    "            in_kernel = True\n",
    "        if in_kernel:\n",
    "            kernel_lines.append(line.rstrip())\n",
    "            if line.strip().startswith('tl.store') and 'output' in line:\n",
    "                break\n",
    "    \n",
    "    print(f\"\\nüìù Kernel Preview:\")\n",
    "    for line in kernel_lines[:15]:\n",
    "        print(f\"   {line}\")\n",
    "    if len(kernel_lines) > 15:\n",
    "        print(f\"   ... ({len(kernel_lines)-15} more lines)\")\n",
    "else:\n",
    "    print(f\"‚ùå Kernel not found at: {INITIAL_KERNEL}\")\n",
    "    INITIAL_KERNEL = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c269a124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using evaluator: rocm_evaluator.py\n",
      "   Path: examples/tb/rocm_evaluator.py\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Setup Evaluator\n",
    "from pathlib import Path\n",
    "\n",
    "OPENEVOLVE_ROOT = Path.cwd().parent\n",
    "\n",
    "# Use the ROCm evaluator from examples\n",
    "EVALUATOR_PATH = OPENEVOLVE_ROOT / \"examples/tb/rocm_evaluator.py\"\n",
    "\n",
    "if EVALUATOR_PATH.exists():\n",
    "    print(f\"‚úÖ Using evaluator: {EVALUATOR_PATH.name}\")\n",
    "    print(f\"   Path: {EVALUATOR_PATH.relative_to(OPENEVOLVE_ROOT)}\")\n",
    "else:\n",
    "    print(f\"‚ùå Evaluator not found at: {EVALUATOR_PATH}\")\n",
    "    EVALUATOR_PATH = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79472251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found config template: configs/default_config.yaml\n",
      "‚úÖ Configuration saved to: tutorial_config.yaml\n",
      "\n",
      "üìù Evolution Parameters:\n",
      "  Max Iterations:  3\n",
      "  Population Size: 50\n",
      "  Num Islands:     4\n",
      "  Log Level:       WARNING\n",
      "  LLM Model:       claude-sonnet-4\n",
      "  LLM Sampling:    random\n",
      "  Database Path:   program_database\n",
      "\n",
      "‚úÖ Ready to run evolution!\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Configure Evolution Parameters\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "OPENEVOLVE_ROOT = Path.cwd().parent\n",
    "TUTORIAL_DIR = OPENEVOLVE_ROOT / \"tutorial\"\n",
    "\n",
    "# Configuration parameters - EASILY ADJUSTABLE\n",
    "MAX_ITERATIONS = 3\n",
    "POPULATION_SIZE = 50\n",
    "NUM_ISLANDS = 4\n",
    "LOG_LEVEL = \"WARNING\"\n",
    "\n",
    "# Try multiple config templates\n",
    "CONFIG_TEMPLATES = [\n",
    "    OPENEVOLVE_ROOT / \"configs/default_config.yaml\",\n",
    "    OPENEVOLVE_ROOT / \"examples/tb/configs/demo_config.yaml\",\n",
    "]\n",
    "\n",
    "CONFIG_FILE = TUTORIAL_DIR / \"tutorial_config.yaml\"\n",
    "\n",
    "# Find first available template\n",
    "template_found = None\n",
    "for template in CONFIG_TEMPLATES:\n",
    "    if template.exists():\n",
    "        template_found = template\n",
    "        print(f\"‚úÖ Found config template: {template.relative_to(OPENEVOLVE_ROOT)}\")\n",
    "        break\n",
    "\n",
    "if template_found:\n",
    "    with open(template_found, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    config['max_iterations'] = MAX_ITERATIONS\n",
    "    config['log_level'] = LOG_LEVEL\n",
    "    \n",
    "    if 'database' not in config:\n",
    "        config['database'] = {}\n",
    "    config['database']['population_size'] = POPULATION_SIZE\n",
    "    config['database']['num_islands'] = NUM_ISLANDS\n",
    "    config['database']['log_prompts'] = True\n",
    "    \n",
    "    # CRITICAL: Fix db_path (can't be None)\n",
    "    if config['database'].get('db_path') is None:\n",
    "        config['database']['db_path'] = 'program_database'\n",
    "    \n",
    "    if 'llm' not in config:\n",
    "        config['llm'] = {}\n",
    "    \n",
    "    # CRITICAL: Set sampling configuration\n",
    "    config['llm']['sampling'] = {'fn': 'random'}\n",
    "    \n",
    "    config['llm']['models'] = [{'name': 'claude-sonnet-4', 'weight': 1.0}]\n",
    "    config['llm']['evaluator_models'] = [{'name': 'claude-sonnet-4', 'weight': 1.0}]\n",
    "    config['llm']['api_base'] = 'https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4'\n",
    "    config['llm']['api_key'] = None\n",
    "    \n",
    "    if 'evaluator' not in config:\n",
    "        config['evaluator'] = {}\n",
    "    config['evaluator']['cascade_evaluation'] = False\n",
    "    config['evaluator']['verbose'] = False\n",
    "    \n",
    "    config['diff_based_evolution'] = True\n",
    "    config['max_code_length'] = 50000\n",
    "    \n",
    "    # CRITICAL: Create evals directory for evaluator temp files\n",
    "    evals_dir = TUTORIAL_DIR / \"evals\"\n",
    "    evals_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    with open(CONFIG_FILE, 'w') as f:\n",
    "        yaml.dump(config, f, default_flow_style=False, sort_keys=False)\n",
    "    \n",
    "    print(f\"‚úÖ Configuration saved to: {CONFIG_FILE.name}\")\n",
    "    print(f\"\\nüìù Evolution Parameters:\")\n",
    "    print(f\"  Max Iterations:  {MAX_ITERATIONS}\")\n",
    "    print(f\"  Population Size: {POPULATION_SIZE}\")\n",
    "    print(f\"  Num Islands:     {NUM_ISLANDS}\")\n",
    "    print(f\"  Log Level:       {LOG_LEVEL}\")\n",
    "    print(f\"  LLM Model:       claude-sonnet-4\")\n",
    "    print(f\"  LLM Sampling:    random\")\n",
    "    print(f\"  Database Path:   {config['database']['db_path']}\")\n",
    "    print(f\"\\n‚úÖ Ready to run evolution!\")\n",
    "else:\n",
    "    print(\"‚ùå No config template found!\")\n",
    "    CONFIG_FILE = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "211b4d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Output directory: runs/tutorial_run_20251126_143929\n",
      "‚úÖ Evals directory: evals\n",
      "\n",
      "======================================================================\n",
      "üìã Pre-Flight Check\n",
      "======================================================================\n",
      "‚úÖ Kernel      : test_add_kernel.py\n",
      "‚úÖ Evaluator   : rocm_evaluator.py\n",
      "‚úÖ Config      : tutorial_config.yaml\n",
      "======================================================================\n",
      "\n",
      "üöÄ All components ready! You can proceed to run evolution.\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Setup Output Directory and Validate\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "OPENEVOLVE_ROOT = Path.cwd().parent\n",
    "TUTORIAL_DIR = OPENEVOLVE_ROOT / \"tutorial\"\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "OUTPUT_DIR = TUTORIAL_DIR / \"runs\" / f\"tutorial_run_{timestamp}\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# CRITICAL: Ensure evals directory exists (needed by evaluator)\n",
    "EVALS_DIR = TUTORIAL_DIR / \"evals\"\n",
    "EVALS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"‚úÖ Output directory: {OUTPUT_DIR.relative_to(TUTORIAL_DIR)}\")\n",
    "print(f\"‚úÖ Evals directory: {EVALS_DIR.relative_to(TUTORIAL_DIR)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìã Pre-Flight Check\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    kernel_var = INITIAL_KERNEL\n",
    "    kernel_defined = True\n",
    "except NameError:\n",
    "    kernel_var = None\n",
    "    kernel_defined = False\n",
    "\n",
    "try:\n",
    "    evaluator_var = EVALUATOR_PATH\n",
    "    evaluator_defined = True\n",
    "except NameError:\n",
    "    evaluator_var = None\n",
    "    evaluator_defined = False\n",
    "\n",
    "try:\n",
    "    config_var = CONFIG_FILE\n",
    "    config_defined = True\n",
    "except NameError:\n",
    "    config_var = None\n",
    "    config_defined = False\n",
    "\n",
    "components = {\n",
    "    \"Kernel\": (kernel_var, kernel_defined),\n",
    "    \"Evaluator\": (evaluator_var, evaluator_defined),\n",
    "    \"Config\": (config_var, config_defined)\n",
    "}\n",
    "\n",
    "all_ready = True\n",
    "missing_cells = []\n",
    "\n",
    "for name, (path, is_defined) in components.items():\n",
    "    if not is_defined:\n",
    "        print(f\"‚ùå {name:12s}: NOT DEFINED (run earlier cell)\")\n",
    "        all_ready = False\n",
    "        if name == \"Kernel\":\n",
    "            missing_cells.append(\"Cell 5\")\n",
    "        elif name == \"Evaluator\":\n",
    "            missing_cells.append(\"Cell 6\")\n",
    "        elif name == \"Config\":\n",
    "            missing_cells.append(\"Cell 7\")\n",
    "    elif path and Path(path).exists():\n",
    "        print(f\"‚úÖ {name:12s}: {Path(path).name}\")\n",
    "    else:\n",
    "        print(f\"‚ùå {name:12s}: NOT FOUND\")\n",
    "        all_ready = False\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n",
    "if all_ready:\n",
    "    print(\"\\nüöÄ All components ready! You can proceed to run evolution.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Some components are missing!\")\n",
    "    if missing_cells:\n",
    "        print(\"\\nüìù Please run these cells first:\")\n",
    "        for cell in missing_cells:\n",
    "            print(f\"   ‚Ä¢ {cell}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0210101f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting OpenEvolve Evolution...\n",
      "======================================================================\n",
      "üì¶ Kernel:    test_add_kernel.py\n",
      "‚öôÔ∏è  Evaluator: rocm_evaluator.py\n",
      "üìã Config:    tutorial_config.yaml\n",
      "üìÅ Output:    runs/tutorial_run_20251126_143929\n",
      "üè† Working Dir: /home/sapmajum/neurips/geak-openevolve/tutorial\n",
      "======================================================================\n",
      "\n",
      "$ cd /home/sapmajum/neurips/geak-openevolve/tutorial\n",
      "$ openevolve-run /home/sapmajum/neurips/geak-openevolve/GEAK-eval-OE/geak_eval/data/ROCm/data/ROCm_v1/test_add_kernel.py /home/sapmajum/neurips/geak-openevolve/examples/tb/rocm_evaluator.py --config /home/sapmajum/neurips/geak-openevolve/tutorial/tutorial_config.yaml --output /home/sapmajum/neurips/geak-openevolve/tutorial/runs/tutorial_run_20251126_143929\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 14:39:31,485 - INFO - Adding initial program to database\n",
      "2025-11-26 14:39:37,581 - INFO - Time spent in evaluation: 6.09 seconds\n",
      "2025-11-26 14:39:37,581 - INFO - Evaluated program 1847919d-3912-414e-a269-ebe918eb1bdb in 6.09s: success=1.0000, final_score=1.0000, performance_metrics=1.0000, correctness_score=1.0000, combined_score=1.0000, benchmark_results=['Performance report: Kernel parameters: SIZE=98432; BLOCK_SIZE_RUNTIME=1024; dtype_str=float16, achieved latency: 0.006900 ms, speedup: 1.0000x.'], baseline_comparison=Performance report: Kernel parameters: SIZE=98432; BLOCK_SIZE_RUNTIME=1024; dtype_str=float16, achieved latency: 0.006900 ms, speedup: 1.0000x. Speedup=1.0000x (baseline: 0.006900ms, current: 0.006900ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 1.0000x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None\n",
      "2025-11-26 14:39:37,581 - INFO - Initial program evaluated in 6.10 seconds \n",
      "2025-11-26 14:39:37,582 - INFO - Starting evolution from iteration 0 for 3 iterations (total: 3)\n",
      "2025-11-26 14:39:37,582 - INFO - Using island-based evolution with 4 islands\n",
      "2025-11-26 14:39:37,582 - INFO - Island Status:\n",
      "2025-11-26 14:39:37,582 - INFO -  * Island 0: 1 programs, best=1.0000, avg=1.0000, diversity=0.00, gen=0\n",
      "2025-11-26 14:39:37,582 - INFO -    Island 1: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=0\n",
      "2025-11-26 14:39:37,582 - INFO -    Island 2: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=0\n",
      "2025-11-26 14:39:37,582 - INFO -    Island 3: 0 programs, best=0.0000, avg=0.0000, diversity=0.00, gen=0\n",
      "2025-11-26 14:39:37,582 - INFO - Sampled model: claude-sonnet-4\n",
      "2025-11-26 14:39:37,582 - INFO - Sampled model: claude-sonnet-4\n",
      "2025-11-26 14:39:37,583 - INFO - Sampled model: claude-sonnet-4\n",
      "2025-11-26 14:39:37,584 - INFO - Sampled model: claude-sonnet-4\n",
      "2025-11-26 14:39:37,584 - INFO - Sampled model: claude-sonnet-4\n",
      "2025-11-26 14:39:37,584 - INFO - Sampled model: claude-sonnet-4\n",
      "2025-11-26 14:39:37,585 - INFO - Sampled model: claude-sonnet-4\n",
      "2025-11-26 14:39:37,586 - INFO - Sampled model: claude-sonnet-4\n",
      "2025-11-26 14:40:28,482 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 14:40:29,809 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 14:40:30,009 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 14:40:30,717 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 14:40:30,887 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 14:40:31,786 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 14:40:34,593 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 14:40:35,586 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 14:40:35,630 - INFO - LLM responses generated in 58.05 seconds\n",
      "2025-11-26 14:40:41,799 - INFO - Time spent in evaluation: 6.16 seconds\n",
      "2025-11-26 14:40:41,799 - INFO - Evaluated program f083120b-8dad-4cf8-82da-b7a3492d62da in 6.16s: success=0.0000, final_score=0.0000, performance_metrics=0.0000, correctness_score=1.0000, combined_score=0.0000, benchmark_results=['Performance report: Achieved latency: 0.000000 ms, speedup: 0.0000x.'], baseline_comparison=The Triton kernel failed to benchmark, so no performance comparison can be made., individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel failed to benchmark., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None\n",
      "2025-11-26 14:40:41,814 - INFO - Time spent in evaluation: 6.18 seconds\n",
      "2025-11-26 14:40:41,814 - INFO - Evaluated program 44fd71a0-ad4a-44a4-bd8a-f4aaec14a18d in 6.18s: success=0.0000, final_score=0.0000, performance_metrics=0.0000, correctness_score=1.0000, combined_score=0.0000, benchmark_results=['Performance report: Achieved latency: 0.000000 ms, speedup: 0.0000x.'], baseline_comparison=The Triton kernel failed to benchmark, so no performance comparison can be made., individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel failed to benchmark., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è WARNING: Kernel evaluator path /home/sapmajum/neurips/geak-openevolve/GEAK-eval-OE/geak_eval/data/ROCm/data/ROCm_v1/evaluator.py does not exist, using default given path.\n",
      "üõ°Ô∏è BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpcpsuceea/test_add_kernel.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpcpsuceea/test_add_kernel.py\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpcpsuceea/test_add_kernel.py -k not (test_performance or test_save)\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpcpsuceea/test_add_kernel.py -k test_performance or test_save_performance_results\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 8 items / 3 deselected / 5 selected\n",
      "\n",
      "evals/tmpcpsuceea/test_add_kernel.py::test_performance[98432-1024-float16] \u001b[32mPASSED\u001b[0m\u001b[32m [ 20%\n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpcpsuceea/perf\n",
      "Found 1 JSON files: ['add_kernel_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpcpsuceea/perf/add_kernel_perf.json\n",
      "Performance data structure: ['params', 'ms', 'min_ms', 'max_ms', 'GB/s', 'TFLOPS']\n",
      "Performance: 0.0069ms (from key 'ms')\n",
      "Establishing NEW baseline latency: 0.006900ms, speedup=1.0\n",
      "Saved baseline to: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/.baseline_latency.txt\n",
      "üõ°Ô∏è BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpgwztd1rt/test_add_kernel.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpgwztd1rt/test_add_kernel.py\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpgwztd1rt/test_add_kernel.py -k not (test_performance or test_save)\n",
      "üõ°Ô∏è BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmptfr96fz6/test_add_kernel.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmptfr96fz6/test_add_kernel.py\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmptfr96fz6/test_add_kernel.py -k not (test_performance or test_save)\n",
      "üõ°Ô∏è BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp_3aj3ybq/test_add_kernel.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp_3aj3ybq/test_add_kernel.py\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp_3aj3ybq/test_add_kernel.py -k not (test_performance or test_save)\n",
      "üõ°Ô∏è BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmprge3c1r9/test_add_kernel.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmprge3c1r9/test_add_kernel.py\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmprge3c1r9/test_add_kernel.py -k not (test_performance or test_save)\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp_3aj3ybq/test_add_kernel.py -k test_performance or test_save_performance_results\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpgwztd1rt/test_add_kernel.py -k test_performance or test_save_performance_results\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmptfr96fz6/test_add_kernel.py -k test_performance or test_save_performance_results\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmprge3c1r9/test_add_kernel.py -k test_performance or test_save_performance_results\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 16 items / 11 deselected / 5 selected\n",
      "\n",
      "evals/tmprge3c1r9/test_add_kernel.py::test_performance[98432-1024-float16] \u001b[32mPASSED\u001b[0m\u001b[32m [ 2\n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmprge3c1r9/perf\n",
      "Found 1 JSON files: ['add_kernel_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmprge3c1r9/perf/add_kernel_perf.json\n",
      "Performance data structure: ['params', 'error']\n",
      "Available keys in perf data: dict_keys(['params', 'error'])\n",
      "Warning: No benchmark data available\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Warning: Invalid benchmark 0.0, setting speedup to 0.0\n",
      "üõ°Ô∏è BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp0i5b5c9l/test_add_kernel.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp0i5b5c9l/test_add_kernel.py\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp0i5b5c9l/test_add_kernel.py -k not (test_performance or test_save)\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 16 items / 11 deselected / 5 selected\n",
      "\n",
      "evals/tmptfr96fz6/test_add_kernel.py::test_performance[98432-1024-float16] \u001b[32mPASSED\u001b[0m\u001b[32m [ 2\n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmptfr96fz6/perf\n",
      "Found 1 JSON files: ['add_kernel_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmptfr96fz6/perf/add_kernel_perf.json\n",
      "Performance data structure: ['params', 'error']\n",
      "Available keys in perf data: dict_keys(['params', 'error'])\n",
      "Warning: No benchmark data available\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Warning: Invalid benchmark 0.0, setting speedup to 0.0\n",
      "üõ°Ô∏è BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp4c1y__m6/test_add_kernel.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp4c1y__m6/test_add_kernel.py\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp4c1y__m6/test_add_kernel.py -k not (test_performance or test_save)\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 47 items / 42 deselected / 5 selected\n",
      "\n",
      "evals/tmpgwztd1rt/test_add_kernel.py::test_performance[98432-1024-float16] \u001b[32mPASSED\u001b[0m\u001b[32m [ 2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 14:40:42,353 - INFO - Time spent in evaluation: 6.72 seconds\n",
      "2025-11-26 14:40:42,353 - INFO - Evaluated program de87a355-acd9-45db-823b-9dcd13cf2339 in 6.72s: success=1.0000, final_score=0.4631, performance_metrics=0.4631, correctness_score=1.0000, combined_score=0.4631, benchmark_results=['Performance report: Kernel parameters: SIZE=98432; BLOCK_SIZE_RUNTIME=1024; dtype_str=float16, achieved latency: 0.014900 ms, speedup: 0.4631x.'], baseline_comparison=Performance report: Kernel parameters: SIZE=98432; BLOCK_SIZE_RUNTIME=1024; dtype_str=float16, achieved latency: 0.014900 ms, speedup: 0.4631x. Speedup=0.4631x (baseline: 0.006900ms, current: 0.014900ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 0.4631x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None\n",
      "2025-11-26 14:40:50,494 - INFO - Time spent in evaluation: 8.69 seconds\n",
      "2025-11-26 14:40:50,494 - INFO - Evaluated program abff79cd-96ea-4d15-8c0b-5c09551bcf23 in 8.69s: success=1.0000, final_score=0.0787, performance_metrics=0.0787, correctness_score=1.0000, combined_score=0.0787, benchmark_results=['Performance report: Kernel parameters: SIZE=8192; M=64; N=128; BLOCK_SIZE_RUNTIME=64; dtype_str=float16, achieved latency: 0.087700 ms, speedup: 0.0787x.'], baseline_comparison=Performance report: Kernel parameters: SIZE=8192; M=64; N=128; BLOCK_SIZE_RUNTIME=64; dtype_str=float16, achieved latency: 0.087700 ms, speedup: 0.0787x. Speedup=0.0787x (baseline: 0.006900ms, current: 0.087700ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 0.0787x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None\n",
      "2025-11-26 14:40:52,059 - INFO - Time spent in evaluation: 9.70 seconds\n",
      "2025-11-26 14:40:52,059 - INFO - Evaluated program 40361994-d8e9-4f85-8ad8-d3b4861496c1 in 9.70s: success=1.0000, final_score=0.1016, performance_metrics=0.1016, correctness_score=1.0000, combined_score=0.1016, benchmark_results=['Performance report: Kernel parameters: SIZE=8192; M=64; N=128; BLOCK_SIZE_M=32; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.067900 ms, speedup: 0.1016x.'], baseline_comparison=Performance report: Kernel parameters: SIZE=8192; M=64; N=128; BLOCK_SIZE_M=32; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.067900 ms, speedup: 0.1016x. Speedup=0.1016x (baseline: 0.006900ms, current: 0.067900ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 0.1016x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None\n",
      "2025-11-26 14:40:53,227 - INFO - Time spent in evaluation: 2.73 seconds\n",
      "2025-11-26 14:40:53,227 - INFO - Evaluated program 8000f5c9-9d4c-4089-88a6-02422a6bded7 in 2.73s: success=0.0000, final_score=0.0000, error=Correctness tests failed (exit 1):\n",
      "STDOUT: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 144 items / 128 deselected / 16 selected\n",
      "\n",
      "evals/tmp4xytyw1u/test_add_kernel.py::test_add[64-128-float16] \u001b[31mFAILED\u001b[0m\u001b[31m    [  6%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m___________________________ test_add[64-128-float16] ___________________________\u001b[0m\n",
      "\n",
      "M = 64, N = 128, dtype_str = 'float16'\n",
      "request = <FixtureRequest for <Function test_add[64-128-float16]>>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m'\u001b[39;49;00m\u001b[33mM,N,dtype_str\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                             [(M, N, dtype_str) \u001b[94mfor\u001b[39;49;00m M, N \u001b[95min\u001b[39;49;00m test_shapes_2d[:\u001b[94m8\u001b[39;49;00m] \u001b[94mfor\u001b[39;49;00m dtype_str \u001b[95min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mfloat16\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]])  \u001b[90m# Start with subset for testing\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_add\u001b[39;49;00m(M, N, dtype_str, request):\u001b[90m\u001b[39;49;00m\n",
      "        set_seed()\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        dtype = dtype_mapping[dtype_str]\u001b[90m\u001b[39;49;00m\n",
      "        output = torch.empty((M, N), device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "        x = torch.randn((M, N), device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "        y = torch.randn((M, N), device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Get optimal block sizes for this shape\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       BLOCK_SIZE_M, BLOCK_SIZE_N = get_optimal_block_sizes(M, N)\u001b[90m\u001b[39;49;00m\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       ValueError: too many values to unpack (expected 2)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mevals/tmp4xytyw1u/test_add_kernel.py\u001b[0m:167: ValueError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m evals/tmp4xytyw1u/test_add_kernel.py::\u001b[1mtest_add[64-128-float16]\u001b[0m - ValueError: too many values to unpack (expected 2)\n",
      "\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "\u001b[31m====================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m128 deselected\u001b[0m\u001b[31m in 2.01s\u001b[0m\u001b[31m =======================\u001b[0m\n",
      "\n",
      ", performance_metrics={}, combined_score=0.0000, correctness_score=0.0000, summary=Evaluation failed due to: Correctness tests failed (exit 1):\n",
      "STDOUT: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 144 items / 128 deselected / 16 selected\n",
      "\n",
      "evals/tmp4xytyw1u/test_add_kernel.py::test_add[64-128-float16] \u001b[31mFAILED\u001b[0m\u001b[31m    [  6%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m___________________________ test_add[64-128-float16] ___________________________\u001b[0m\n",
      "\n",
      "M = 64, N = 128, dtype_str = 'float16'\n",
      "request = <FixtureRequest for <Function test_add[64-128-float16]>>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m'\u001b[39;49;00m\u001b[33mM,N,dtype_str\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                             [(M, N, dtype_str) \u001b[94mfor\u001b[39;49;00m M, N \u001b[95min\u001b[39;49;00m test_shapes_2d[:\u001b[94m8\u001b[39;49;00m] \u001b[94mfor\u001b[39;49;00m dtype_str \u001b[95min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mfloat16\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]])  \u001b[90m# Start with subset for testing\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_add\u001b[39;49;00m(M, N, dtype_str, request):\u001b[90m\u001b[39;49;00m\n",
      "        set_seed()\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        dtype = dtype_mapping[dtype_str]\u001b[90m\u001b[39;49;00m\n",
      "        output = torch.empty((M, N), device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "        x = torch.randn((M, N), device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "        y = torch.randn((M, N), device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Get optimal block sizes for this shape\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       BLOCK_SIZE_M, BLOCK_SIZE_N = get_optimal_block_sizes(M, N)\u001b[90m\u001b[39;49;00m\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       ValueError: too many values to unpack (expected 2)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mevals/tmp4xytyw1u/test_add_kernel.py\u001b[0m:167: ValueError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m evals/tmp4xytyw1u/test_add_kernel.py::\u001b[1mtest_add[64-128-float16]\u001b[0m - ValueError: too many values to unpack (expected 2)\n",
      "\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "\u001b[31m====================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m128 deselected\u001b[0m\u001b[31m in 2.01s\u001b[0m\u001b[31m =======================\u001b[0m\n",
      "\n",
      ", safety_validation={'success': False, 'error': \"Correctness tests failed (exit 1):\\nSTDOUT: \\x1b[1m============================= test session starts ==============================\\x1b[0m\\nplatform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\\ncachedir: .pytest_cache\\nrootdir: /home/sapmajum/neurips/geak-openevolve\\nconfigfile: pyproject.toml\\nplugins: timeout-2.4.0, anyio-4.11.0\\n\\x1b[1mcollecting ... \\x1b[0mcollected 144 items / 128 deselected / 16 selected\\n\\nevals/tmp4xytyw1u/test_add_kernel.py::test_add[64-128-float16] \\x1b[31mFAILED\\x1b[0m\\x1b[31m    [  6%]\\x1b[0m\\n\\n=================================== FAILURES ===================================\\n\\x1b[31m\\x1b[1m___________________________ test_add[64-128-float16] ___________________________\\x1b[0m\\n\\nM = 64, N = 128, dtype_str = 'float16'\\nrequest = <FixtureRequest for <Function test_add[64-128-float16]>>\\n\\n    \\x1b[0m\\x1b[37m@pytest\\x1b[39;49;00m.mark.parametrize(\\x1b[33m'\\x1b[39;49;00m\\x1b[33mM,N,dtype_str\\x1b[39;49;00m\\x1b[33m'\\x1b[39;49;00m,\\x1b[90m\\x1b[39;49;00m\\n                             [(M, N, dtype_str) \\x1b[94mfor\\x1b[39;49;00m M, N \\x1b[95min\\x1b[39;49;00m test_shapes_2d[:\\x1b[94m8\\x1b[39;49;00m] \\x1b[94mfor\\x1b[39;49;00m dtype_str \\x1b[95min\\x1b[39;49;00m [\\x1b[33m'\\x1b[39;49;00m\\x1b[33mfloat16\\x1b[39;49;00m\\x1b[33m'\\x1b[39;49;00m, \\x1b[33m'\\x1b[39;49;00m\\x1b[33mfloat32\\x1b[39;49;00m\\x1b[33m'\\x1b[39;49;00m]])  \\x1b[90m# Start with subset for testing\\x1b[39;49;00m\\x1b[90m\\x1b[39;49;00m\\n    \\x1b[94mdef\\x1b[39;49;00m\\x1b[90m \\x1b[39;49;00m\\x1b[92mtest_add\\x1b[39;49;00m(M, N, dtype_str, request):\\x1b[90m\\x1b[39;49;00m\\n        set_seed()\\x1b[90m\\x1b[39;49;00m\\n    \\x1b[90m\\x1b[39;49;00m\\n        dtype = dtype_mapping[dtype_str]\\x1b[90m\\x1b[39;49;00m\\n        output = torch.empty((M, N), device=\\x1b[33m'\\x1b[39;49;00m\\x1b[33mcuda\\x1b[39;49;00m\\x1b[33m'\\x1b[39;49;00m, dtype=dtype)\\x1b[90m\\x1b[39;49;00m\\n        x = torch.randn((M, N), device=\\x1b[33m'\\x1b[39;49;00m\\x1b[33mcuda\\x1b[39;49;00m\\x1b[33m'\\x1b[39;49;00m, dtype=dtype)\\x1b[90m\\x1b[39;49;00m\\n        y = torch.randn((M, N), device=\\x1b[33m'\\x1b[39;49;00m\\x1b[33mcuda\\x1b[39;49;00m\\x1b[33m'\\x1b[39;49;00m, dtype=dtype)\\x1b[90m\\x1b[39;49;00m\\n    \\x1b[90m\\x1b[39;49;00m\\n        \\x1b[90m# Get optimal block sizes for this shape\\x1b[39;49;00m\\x1b[90m\\x1b[39;49;00m\\n>       BLOCK_SIZE_M, BLOCK_SIZE_N = get_optimal_block_sizes(M, N)\\x1b[90m\\x1b[39;49;00m\\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^\\x1b[90m\\x1b[39;49;00m\\n\\x1b[1m\\x1b[31mE       ValueError: too many values to unpack (expected 2)\\x1b[0m\\n\\n\\x1b[1m\\x1b[31mevals/tmp4xytyw1u/test_add_kernel.py\\x1b[0m:167: ValueError\\n\\x1b[36m\\x1b[1m=========================== short test summary info ============================\\x1b[0m\\n\\x1b[31mFAILED\\x1b[0m evals/tmp4xytyw1u/test_add_kernel.py::\\x1b[1mtest_add[64-128-float16]\\x1b[0m - ValueError: too many values to unpack (expected 2)\\n\\x1b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\\x1b[0m\\n\\x1b[31m====================== \\x1b[31m\\x1b[1m1 failed\\x1b[0m, \\x1b[33m128 deselected\\x1b[0m\\x1b[31m in 2.01s\\x1b[0m\\x1b[31m =======================\\x1b[0m\\n\\n\"}\n",
      "2025-11-26 14:40:59,667 - INFO - Time spent in evaluation: 24.03 seconds\n",
      "2025-11-26 14:40:59,667 - INFO - Evaluated program 8b9ede44-16b5-4e76-bbd5-6671ecc2e757 in 24.03s: success=1.0000, final_score=1.0000, performance_metrics=1.0000, correctness_score=1.0000, combined_score=1.0000, benchmark_results=['Performance report: Kernel parameters: SIZE=8192; BLOCK_SIZE_RUNTIME=256; dtype_str=float16, achieved latency: 0.006900 ms, speedup: 1.0000x.'], baseline_comparison=Performance report: Kernel parameters: SIZE=8192; BLOCK_SIZE_RUNTIME=256; dtype_str=float16, achieved latency: 0.006900 ms, speedup: 1.0000x. Speedup=1.0000x (baseline: 0.006900ms, current: 0.006900ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 1.0000x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpgwztd1rt/perf\n",
      "Found 1 JSON files: ['add_kernel_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpgwztd1rt/perf/add_kernel_perf.json\n",
      "Performance data structure: ['params', 'ms', 'min_ms', 'max_ms', 'GB/s', 'TFLOPS']\n",
      "Performance: 0.0149ms (from key 'ms')\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Calculated speedup: 0.006900ms / 0.014900ms = 0.4631x\n",
      "üõ°Ô∏è BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmppt6h6pk1/test_add_kernel.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmppt6h6pk1/test_add_kernel.py\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmppt6h6pk1/test_add_kernel.py -k not (test_performance or test_save)\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp4c1y__m6/test_add_kernel.py -k test_performance or test_save_performance_results\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp0i5b5c9l/test_add_kernel.py -k test_performance or test_save_performance_results\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmppt6h6pk1/test_add_kernel.py -k test_performance or test_save_performance_results\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 26 items / 9 deselected / 17 selected\n",
      "\n",
      "evals/tmp0i5b5c9l/test_add_kernel.py::test_performance[64-128-32-64-float16] \u001b[32mPASSED\u001b[0m\u001b[32m [\n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp0i5b5c9l/perf\n",
      "Found 1 JSON files: ['add_kernel_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp0i5b5c9l/perf/add_kernel_perf.json\n",
      "Performance data structure: ['params', 'ms', 'min_ms', 'max_ms', 'GB/s', 'TFLOPS']\n",
      "Performance: 0.0877ms (from key 'ms')\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Calculated speedup: 0.006900ms / 0.087700ms = 0.0787x\n",
      "üõ°Ô∏è BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp4xytyw1u/test_add_kernel.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp4xytyw1u/test_add_kernel.py\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp4xytyw1u/test_add_kernel.py -k not (test_performance or test_save)\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 32 items / 7 deselected / 25 selected\n",
      "\n",
      "evals/tmppt6h6pk1/test_add_kernel.py::test_performance[64-128-float16] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b\n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmppt6h6pk1/perf\n",
      "Found 1 JSON files: ['add_kernel_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmppt6h6pk1/perf/add_kernel_perf.json\n",
      "Performance data structure: ['params', 'ms', 'min_ms', 'max_ms', 'GB/s', 'TFLOPS']\n",
      "Performance: 0.0679ms (from key 'ms')\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Calculated speedup: 0.006900ms / 0.067900ms = 0.1016x\n",
      "Correctness tests failed. Return code: 1\n",
      "STDOUT: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 144 items / 128 deselected / 16 selected\n",
      "\n",
      "evals/tmp4xytyw1u/test_add_kernel.py::test_add[64-128-float16] \u001b[31mFAILED\u001b[0m\u001b[31m    [  6%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m___________________________ test_add[64-128-float16] ___________________________\u001b[0m\n",
      "\n",
      "M = 64, N = 128, dtype_str = 'float16'\n",
      "request = <FixtureRequest for <Function test_add[64-128-float16]>>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m'\u001b[39;49;00m\u001b[33mM,N,dtype_str\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                             [(M, N, dtype_str) \u001b[94mfor\u001b[39;49;00m M, N \u001b[95min\u001b[39;49;00m test_shapes_2d[:\u001b[94m8\u001b[39;49;00m] \u001b[94mfor\u001b[39;49;00m dtype_str \u001b[95min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mfloat16\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]])  \u001b[90m# Start with subset for testing\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_add\u001b[39;49;00m(M, N, dtype_str, request):\u001b[90m\u001b[39;49;00m\n",
      "        set_seed()\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        dtype = dtype_mapping[dtype_str]\u001b[90m\u001b[39;49;00m\n",
      "        output = torch.empty((M, N), device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "        x = torch.randn((M, N), device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "        y = torch.randn((M, N), device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Get optimal block sizes for this shape\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       BLOCK_SIZE_M, BLOCK_SIZE_N = get_optimal_block_sizes(M, N)\u001b[90m\u001b[39;49;00m\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       ValueError: too many values to unpack (expected 2)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mevals/tmp4xytyw1u/test_add_kernel.py\u001b[0m:167: ValueError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m evals/tmp4xytyw1u/test_add_kernel.py::\u001b[1mtest_add[64-128-float16]\u001b[0m - ValueError: too many values to unpack (expected 2)\n",
      "\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "\u001b[31m====================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m128 deselected\u001b[0m\u001b[31m in 2.01s\u001b[0m\u001b[31m =======================\u001b[0m\n",
      "\n",
      "STDERR: \n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 134 items / 3 deselected / 131 selected\n",
      "\n",
      "evals/tmp_3aj3ybq/test_add_kernel.py::test_performance[8192-256-float16_0] \u001b[32mPASSED\u001b[0m\u001b[32m [\n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp_3aj3ybq/perf\n",
      "Found 1 JSON files: ['add_kernel_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp_3aj3ybq/perf/add_kernel_perf.json\n",
      "Performance data structure: ['params', 'ms', 'min_ms', 'max_ms', 'GB/s', 'TFLOPS']\n",
      "Performance: 0.0069ms (from key 'ms')\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Calculated speedup: 0.006900ms / 0.006900ms = 1.0000x\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 136 items / 7 deselected / 129 selected\n",
      "\n",
      "evals/tmp4c1y__m6/test_add_kernel.py::test_performance[64-64-64-64-float16] \u001b[32mPASSED\u001b[0m\u001b[32m "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 14:41:04,138 - INFO - Time spent in evaluation: 22.32 seconds\n",
      "2025-11-26 14:41:04,138 - INFO - Evaluated program 1de88931-60a8-4b72-adad-e728f58f9e0e in 22.32s: success=1.0000, final_score=1.0299, performance_metrics=1.0299, correctness_score=1.0000, combined_score=1.0299, benchmark_results=['Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.006700 ms, speedup: 1.0299x.'], baseline_comparison=Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.006700 ms, speedup: 1.0299x. Speedup=1.0299x (baseline: 0.006900ms, current: 0.006700ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 1.0299x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None\n",
      "2025-11-26 14:41:04,138 - INFO - Child programs evaluated in 28.50 seconds\n",
      "2025-11-26 14:41:04,138 - INFO - Updated sampling model 0 with reward 0.46308724832214765\n",
      "2025-11-26 14:41:04,139 - INFO - Updated sampling model 0 with reward 0.0\n",
      "2025-11-26 14:41:04,139 - INFO - Updated sampling model 0 with reward 1.0\n",
      "2025-11-26 14:41:04,139 - INFO - Updated sampling model 0 with reward 0.0\n",
      "2025-11-26 14:41:04,140 - INFO - Updated sampling model 0 with reward 0.07867730900798175\n",
      "2025-11-26 14:41:04,140 - INFO - Updated sampling model 0 with reward 1.0298507462686566\n",
      "2025-11-26 14:41:04,140 - INFO - New best program 1de88931-60a8-4b72-adad-e728f58f9e0e replaces 1847919d-3912-414e-a269-ebe918eb1bdb (combined_score: 1.0000 ‚Üí 1.0299, +0.0299)\n",
      "2025-11-26 14:41:04,140 - INFO - üåü New best solution found at iteration 1: 1de88931-60a8-4b72-adad-e728f58f9e0e\n",
      "2025-11-26 14:41:04,140 - INFO - Metrics: success=1.0000, final_score=1.0299, performance_metrics=1.0299, correctness_score=1.0000, combined_score=1.0299, benchmark_results=['Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.006700 ms, speedup: 1.0299x.'], baseline_comparison=Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.006700 ms, speedup: 1.0299x. Speedup=1.0299x (baseline: 0.006900ms, current: 0.006700ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 1.0299x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None\n",
      "2025-11-26 14:41:04,140 - INFO - Updated sampling model 0 with reward 0.101620029455081\n",
      "2025-11-26 14:41:04,140 - INFO - Updated sampling model 0 with reward 0.0\n",
      "2025-11-26 14:41:04,140 - INFO - Iteration 1: Child 8000f5c9-9d4c-4089-88a6-02422a6bded7 from parent 1847919d-3912-414e-a269-ebe918eb1bdb in 86.56s. Metrics: success=0.0000, final_score=0.0000, error=Correctness tests failed (exit 1):\n",
      "STDOUT: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 144 items / 128 deselected / 16 selected\n",
      "\n",
      "evals/tmp4xytyw1u/test_add_kernel.py::test_add[64-128-float16] \u001b[31mFAILED\u001b[0m\u001b[31m    [  6%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m___________________________ test_add[64-128-float16] ___________________________\u001b[0m\n",
      "\n",
      "M = 64, N = 128, dtype_str = 'float16'\n",
      "request = <FixtureRequest for <Function test_add[64-128-float16]>>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m'\u001b[39;49;00m\u001b[33mM,N,dtype_str\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                             [(M, N, dtype_str) \u001b[94mfor\u001b[39;49;00m M, N \u001b[95min\u001b[39;49;00m test_shapes_2d[:\u001b[94m8\u001b[39;49;00m] \u001b[94mfor\u001b[39;49;00m dtype_str \u001b[95min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mfloat16\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]])  \u001b[90m# Start with subset for testing\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_add\u001b[39;49;00m(M, N, dtype_str, request):\u001b[90m\u001b[39;49;00m\n",
      "        set_seed()\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        dtype = dtype_mapping[dtype_str]\u001b[90m\u001b[39;49;00m\n",
      "        output = torch.empty((M, N), device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "        x = torch.randn((M, N), device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "        y = torch.randn((M, N), device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Get optimal block sizes for this shape\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       BLOCK_SIZE_M, BLOCK_SIZE_N = get_optimal_block_sizes(M, N)\u001b[90m\u001b[39;49;00m\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       ValueError: too many values to unpack (expected 2)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mevals/tmp4xytyw1u/test_add_kernel.py\u001b[0m:167: ValueError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m evals/tmp4xytyw1u/test_add_kernel.py::\u001b[1mtest_add[64-128-float16]\u001b[0m - ValueError: too many values to unpack (expected 2)\n",
      "\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "\u001b[31m====================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m128 deselected\u001b[0m\u001b[31m in 2.01s\u001b[0m\u001b[31m =======================\u001b[0m\n",
      "\n",
      ", performance_metrics={}, combined_score=0.0000, correctness_score=0.0000, summary=Evaluation failed due to: Correctness tests failed (exit 1):\n",
      "STDOUT: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 144 items / 128 deselected / 16 selected\n",
      "\n",
      "evals/tmp4xytyw1u/test_add_kernel.py::test_add[64-128-float16] \u001b[31mFAILED\u001b[0m\u001b[31m    [  6%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m___________________________ test_add[64-128-float16] ___________________________\u001b[0m\n",
      "\n",
      "M = 64, N = 128, dtype_str = 'float16'\n",
      "request = <FixtureRequest for <Function test_add[64-128-float16]>>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m'\u001b[39;49;00m\u001b[33mM,N,dtype_str\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                             [(M, N, dtype_str) \u001b[94mfor\u001b[39;49;00m M, N \u001b[95min\u001b[39;49;00m test_shapes_2d[:\u001b[94m8\u001b[39;49;00m] \u001b[94mfor\u001b[39;49;00m dtype_str \u001b[95min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mfloat16\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]])  \u001b[90m# Start with subset for testing\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_add\u001b[39;49;00m(M, N, dtype_str, request):\u001b[90m\u001b[39;49;00m\n",
      "        set_seed()\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        dtype = dtype_mapping[dtype_str]\u001b[90m\u001b[39;49;00m\n",
      "        output = torch.empty((M, N), device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "        x = torch.randn((M, N), device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "        y = torch.randn((M, N), device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[90m# Get optimal block sizes for this shape\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       BLOCK_SIZE_M, BLOCK_SIZE_N = get_optimal_block_sizes(M, N)\u001b[90m\u001b[39;49;00m\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       ValueError: too many values to unpack (expected 2)\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mevals/tmp4xytyw1u/test_add_kernel.py\u001b[0m:167: ValueError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m evals/tmp4xytyw1u/test_add_kernel.py::\u001b[1mtest_add[64-128-float16]\u001b[0m - ValueError: too many values to unpack (expected 2)\n",
      "\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "\u001b[31m====================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m128 deselected\u001b[0m\u001b[31m in 2.01s\u001b[0m\u001b[31m =======================\u001b[0m\n",
      "\n",
      ", safety_validation={'success': False, 'error': \"Correctness tests failed (exit 1):\\nSTDOUT: \\x1b[1m============================= test session starts ==============================\\x1b[0m\\nplatform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\\ncachedir: .pytest_cache\\nrootdir: /home/sapmajum/neurips/geak-openevolve\\nconfigfile: pyproject.toml\\nplugins: timeout-2.4.0, anyio-4.11.0\\n\\x1b[1mcollecting ... \\x1b[0mcollected 144 items / 128 deselected / 16 selected\\n\\nevals/tmp4xytyw1u/test_add_kernel.py::test_add[64-128-float16] \\x1b[31mFAILED\\x1b[0m\\x1b[31m    [  6%]\\x1b[0m\\n\\n=================================== FAILURES ===================================\\n\\x1b[31m\\x1b[1m___________________________ test_add[64-128-float16] ___________________________\\x1b[0m\\n\\nM = 64, N = 128, dtype_str = 'float16'\\nrequest = <FixtureRequest for <Function test_add[64-128-float16]>>\\n\\n    \\x1b[0m\\x1b[37m@pytest\\x1b[39;49;00m.mark.parametrize(\\x1b[33m'\\x1b[39;49;00m\\x1b[33mM,N,dtype_str\\x1b[39;49;00m\\x1b[33m'\\x1b[39;49;00m,\\x1b[90m\\x1b[39;49;00m\\n                             [(M, N, dtype_str) \\x1b[94mfor\\x1b[39;49;00m M, N \\x1b[95min\\x1b[39;49;00m test_shapes_2d[:\\x1b[94m8\\x1b[39;49;00m] \\x1b[94mfor\\x1b[39;49;00m dtype_str \\x1b[95min\\x1b[39;49;00m [\\x1b[33m'\\x1b[39;49;00m\\x1b[33mfloat16\\x1b[39;49;00m\\x1b[33m'\\x1b[39;49;00m, \\x1b[33m'\\x1b[39;49;00m\\x1b[33mfloat32\\x1b[39;49;00m\\x1b[33m'\\x1b[39;49;00m]])  \\x1b[90m# Start with subset for testing\\x1b[39;49;00m\\x1b[90m\\x1b[39;49;00m\\n    \\x1b[94mdef\\x1b[39;49;00m\\x1b[90m \\x1b[39;49;00m\\x1b[92mtest_add\\x1b[39;49;00m(M, N, dtype_str, request):\\x1b[90m\\x1b[39;49;00m\\n        set_seed()\\x1b[90m\\x1b[39;49;00m\\n    \\x1b[90m\\x1b[39;49;00m\\n        dtype = dtype_mapping[dtype_str]\\x1b[90m\\x1b[39;49;00m\\n        output = torch.empty((M, N), device=\\x1b[33m'\\x1b[39;49;00m\\x1b[33mcuda\\x1b[39;49;00m\\x1b[33m'\\x1b[39;49;00m, dtype=dtype)\\x1b[90m\\x1b[39;49;00m\\n        x = torch.randn((M, N), device=\\x1b[33m'\\x1b[39;49;00m\\x1b[33mcuda\\x1b[39;49;00m\\x1b[33m'\\x1b[39;49;00m, dtype=dtype)\\x1b[90m\\x1b[39;49;00m\\n        y = torch.randn((M, N), device=\\x1b[33m'\\x1b[39;49;00m\\x1b[33mcuda\\x1b[39;49;00m\\x1b[33m'\\x1b[39;49;00m, dtype=dtype)\\x1b[90m\\x1b[39;49;00m\\n    \\x1b[90m\\x1b[39;49;00m\\n        \\x1b[90m# Get optimal block sizes for this shape\\x1b[39;49;00m\\x1b[90m\\x1b[39;49;00m\\n>       BLOCK_SIZE_M, BLOCK_SIZE_N = get_optimal_block_sizes(M, N)\\x1b[90m\\x1b[39;49;00m\\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^\\x1b[90m\\x1b[39;49;00m\\n\\x1b[1m\\x1b[31mE       ValueError: too many values to unpack (expected 2)\\x1b[0m\\n\\n\\x1b[1m\\x1b[31mevals/tmp4xytyw1u/test_add_kernel.py\\x1b[0m:167: ValueError\\n\\x1b[36m\\x1b[1m=========================== short test summary info ============================\\x1b[0m\\n\\x1b[31mFAILED\\x1b[0m evals/tmp4xytyw1u/test_add_kernel.py::\\x1b[1mtest_add[64-128-float16]\\x1b[0m - ValueError: too many values to unpack (expected 2)\\n\\x1b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\\x1b[0m\\n\\x1b[31m====================== \\x1b[31m\\x1b[1m1 failed\\x1b[0m, \\x1b[33m128 deselected\\x1b[0m\\x1b[31m in 2.01s\\x1b[0m\\x1b[31m =======================\\x1b[0m\\n\\n\"} (Œî: success=-1.0000, final_score=-1.0000, combined_score=-1.0000, correctness_score=-1.0000)\n",
      "2025-11-26 14:41:04,141 - INFO - Sampled model: claude-sonnet-4\n",
      "2025-11-26 14:41:04,141 - INFO - Sampled model: claude-sonnet-4\n",
      "2025-11-26 14:41:04,141 - INFO - Sampled model: claude-sonnet-4\n",
      "2025-11-26 14:41:04,141 - INFO - Sampled model: claude-sonnet-4\n",
      "2025-11-26 14:41:04,141 - INFO - Sampled model: claude-sonnet-4\n",
      "2025-11-26 14:41:04,141 - INFO - Sampled model: claude-sonnet-4\n",
      "2025-11-26 14:41:04,142 - INFO - Sampled model: claude-sonnet-4\n",
      "2025-11-26 14:41:04,142 - INFO - Sampled model: claude-sonnet-4\n",
      "2025-11-26 14:41:34,134 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 14:41:38,553 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 14:41:39,918 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 14:41:39,919 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 14:41:45,697 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 14:41:46,556 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 14:41:48,048 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 14:41:55,910 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 14:41:55,956 - INFO - LLM responses generated in 51.81 seconds\n",
      "2025-11-26 14:41:58,717 - INFO - Time spent in evaluation: 2.76 seconds\n",
      "2025-11-26 14:41:58,717 - INFO - Evaluated program e2a7a688-3291-49f0-9302-48a48a4396ce in 2.76s: success=0.0000, final_score=0.0000, error=Correctness tests failed (exit 2):\n",
      "STDOUT: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 0 items / 1 error\n",
      "\n",
      "==================================== ERRORS ====================================\n",
      "\u001b[31m\u001b[1m________ ERROR collecting tutorial/evals/tmpu24ljk50/test_add_kernel.py ________\u001b[0m\n",
      "\u001b[1m\u001b[31mevals/tmpu24ljk50/test_add_kernel.py\u001b[0m:144: in <module>\n",
      "    \u001b[0mblock_m, block_n = get_optimal_block_sizes(M, N)\u001b[90m\u001b[39;49;00m\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE   NameError: name 'get_optimal_block_sizes' is not defined\u001b[0m\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mERROR\u001b[0m evals/tmpu24ljk50/test_add_kernel.py - NameError: name 'get_optimal_block_sizes' is not defined\n",
      "\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n",
      "\u001b[31m=============================== \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 2.09s\u001b[0m\u001b[31m ===============================\u001b[0m\n",
      "\n",
      ", performance_metrics={}, combined_score=0.0000, correctness_score=0.0000, summary=Evaluation failed due to: Correctness tests failed (exit 2):\n",
      "STDOUT: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 0 items / 1 error\n",
      "\n",
      "==================================== ERRORS ====================================\n",
      "\u001b[31m\u001b[1m________ ERROR collecting tutorial/evals/tmpu24ljk50/test_add_kernel.py ________\u001b[0m\n",
      "\u001b[1m\u001b[31mevals/tmpu24ljk50/test_add_kernel.py\u001b[0m:144: in <module>\n",
      "    \u001b[0mblock_m, block_n = get_optimal_block_sizes(M, N)\u001b[90m\u001b[39;49;00m\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE   NameError: name 'get_optimal_block_sizes' is not defined\u001b[0m\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mERROR\u001b[0m evals/tmpu24ljk50/test_add_kernel.py - NameError: name 'get_optimal_block_sizes' is not defined\n",
      "\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n",
      "\u001b[31m=============================== \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 2.09s\u001b[0m\u001b[31m ===============================\u001b[0m\n",
      "\n",
      ", safety_validation={'success': False, 'error': \"Correctness tests failed (exit 2):\\nSTDOUT: \\x1b[1m============================= test session starts ==============================\\x1b[0m\\nplatform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\\ncachedir: .pytest_cache\\nrootdir: /home/sapmajum/neurips/geak-openevolve\\nconfigfile: pyproject.toml\\nplugins: timeout-2.4.0, anyio-4.11.0\\n\\x1b[1mcollecting ... \\x1b[0mcollected 0 items / 1 error\\n\\n==================================== ERRORS ====================================\\n\\x1b[31m\\x1b[1m________ ERROR collecting tutorial/evals/tmpu24ljk50/test_add_kernel.py ________\\x1b[0m\\n\\x1b[1m\\x1b[31mevals/tmpu24ljk50/test_add_kernel.py\\x1b[0m:144: in <module>\\n    \\x1b[0mblock_m, block_n = get_optimal_block_sizes(M, N)\\x1b[90m\\x1b[39;49;00m\\n                       ^^^^^^^^^^^^^^^^^^^^^^^\\x1b[90m\\x1b[39;49;00m\\n\\x1b[1m\\x1b[31mE   NameError: name 'get_optimal_block_sizes' is not defined\\x1b[0m\\n\\x1b[36m\\x1b[1m=========================== short test summary info ============================\\x1b[0m\\n\\x1b[31mERROR\\x1b[0m evals/tmpu24ljk50/test_add_kernel.py - NameError: name 'get_optimal_block_sizes' is not defined\\n\\x1b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\\x1b[0m\\n!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\\n\\x1b[31m=============================== \\x1b[31m\\x1b[1m1 error\\x1b[0m\\x1b[31m in 2.09s\\x1b[0m\\x1b[31m ===============================\\x1b[0m\\n\\n\"}\n",
      "2025-11-26 14:41:58,731 - INFO - Time spent in evaluation: 2.77 seconds\n",
      "2025-11-26 14:41:58,731 - INFO - Evaluated program 8fbd701a-2977-461f-92d5-afe3bdbdf740 in 2.77s: success=0.0000, final_score=0.0000, error=Correctness tests failed (exit 2):\n",
      "STDOUT: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 0 items / 1 error\n",
      "\n",
      "==================================== ERRORS ====================================\n",
      "\u001b[31m\u001b[1m________ ERROR collecting tutorial/evals/tmpso7ehkrr/test_add_kernel.py ________\u001b[0m\n",
      "\u001b[1m\u001b[31mevals/tmpso7ehkrr/test_add_kernel.py\u001b[0m:140: in <module>\n",
      "    \u001b[0mblock_m, block_n = get_optimal_block_sizes(M, N)\u001b[90m\u001b[39;49;00m\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE   NameError: name 'get_optimal_block_sizes' is not defined\u001b[0m\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mERROR\u001b[0m evals/tmpso7ehkrr/test_add_kernel.py - NameError: name 'get_optimal_block_sizes' is not defined\n",
      "\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n",
      "\u001b[31m=============================== \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 2.09s\u001b[0m\u001b[31m ===============================\u001b[0m\n",
      "\n",
      ", performance_metrics={}, combined_score=0.0000, correctness_score=0.0000, summary=Evaluation failed due to: Correctness tests failed (exit 2):\n",
      "STDOUT: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 0 items / 1 error\n",
      "\n",
      "==================================== ERRORS ====================================\n",
      "\u001b[31m\u001b[1m________ ERROR collecting tutorial/evals/tmpso7ehkrr/test_add_kernel.py ________\u001b[0m\n",
      "\u001b[1m\u001b[31mevals/tmpso7ehkrr/test_add_kernel.py\u001b[0m:140: in <module>\n",
      "    \u001b[0mblock_m, block_n = get_optimal_block_sizes(M, N)\u001b[90m\u001b[39;49;00m\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE   NameError: name 'get_optimal_block_sizes' is not defined\u001b[0m\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mERROR\u001b[0m evals/tmpso7ehkrr/test_add_kernel.py - NameError: name 'get_optimal_block_sizes' is not defined\n",
      "\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n",
      "\u001b[31m=============================== \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 2.09s\u001b[0m\u001b[31m ===============================\u001b[0m\n",
      "\n",
      ", safety_validation={'success': False, 'error': \"Correctness tests failed (exit 2):\\nSTDOUT: \\x1b[1m============================= test session starts ==============================\\x1b[0m\\nplatform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\\ncachedir: .pytest_cache\\nrootdir: /home/sapmajum/neurips/geak-openevolve\\nconfigfile: pyproject.toml\\nplugins: timeout-2.4.0, anyio-4.11.0\\n\\x1b[1mcollecting ... \\x1b[0mcollected 0 items / 1 error\\n\\n==================================== ERRORS ====================================\\n\\x1b[31m\\x1b[1m________ ERROR collecting tutorial/evals/tmpso7ehkrr/test_add_kernel.py ________\\x1b[0m\\n\\x1b[1m\\x1b[31mevals/tmpso7ehkrr/test_add_kernel.py\\x1b[0m:140: in <module>\\n    \\x1b[0mblock_m, block_n = get_optimal_block_sizes(M, N)\\x1b[90m\\x1b[39;49;00m\\n                       ^^^^^^^^^^^^^^^^^^^^^^^\\x1b[90m\\x1b[39;49;00m\\n\\x1b[1m\\x1b[31mE   NameError: name 'get_optimal_block_sizes' is not defined\\x1b[0m\\n\\x1b[36m\\x1b[1m=========================== short test summary info ============================\\x1b[0m\\n\\x1b[31mERROR\\x1b[0m evals/tmpso7ehkrr/test_add_kernel.py - NameError: name 'get_optimal_block_sizes' is not defined\\n\\x1b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\\x1b[0m\\n!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\\n\\x1b[31m=============================== \\x1b[31m\\x1b[1m1 error\\x1b[0m\\x1b[31m in 2.09s\\x1b[0m\\x1b[31m ===============================\\x1b[0m\\n\\n\"}\n",
      "2025-11-26 14:42:01,436 - INFO - Time spent in evaluation: 2.70 seconds\n",
      "2025-11-26 14:42:01,436 - INFO - Evaluated program dc880533-ec0c-4525-9bd1-c069d43f766b in 2.70s: success=0.0000, final_score=0.0000, error=Correctness tests failed (exit 2):\n",
      "STDOUT: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 0 items / 1 error\n",
      "\n",
      "==================================== ERRORS ====================================\n",
      "\u001b[31m\u001b[1m________ ERROR collecting tutorial/evals/tmp0rr5lwej/test_add_kernel.py ________\u001b[0m\n",
      "\u001b[1m\u001b[31mevals/tmp0rr5lwej/test_add_kernel.py\u001b[0m:139: in <module>\n",
      "    \u001b[0mblock_m, block_n = get_optimal_block_sizes(M, N)\u001b[90m\u001b[39;49;00m\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE   NameError: name 'get_optimal_block_sizes' is not defined\u001b[0m\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mERROR\u001b[0m evals/tmp0rr5lwej/test_add_kernel.py - NameError: name 'get_optimal_block_sizes' is not defined\n",
      "\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n",
      "\u001b[31m=============================== \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 2.01s\u001b[0m\u001b[31m ===============================\u001b[0m\n",
      "\n",
      ", performance_metrics={}, combined_score=0.0000, correctness_score=0.0000, summary=Evaluation failed due to: Correctness tests failed (exit 2):\n",
      "STDOUT: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 0 items / 1 error\n",
      "\n",
      "==================================== ERRORS ====================================\n",
      "\u001b[31m\u001b[1m________ ERROR collecting tutorial/evals/tmp0rr5lwej/test_add_kernel.py ________\u001b[0m\n",
      "\u001b[1m\u001b[31mevals/tmp0rr5lwej/test_add_kernel.py\u001b[0m:139: in <module>\n",
      "    \u001b[0mblock_m, block_n = get_optimal_block_sizes(M, N)\u001b[90m\u001b[39;49;00m\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE   NameError: name 'get_optimal_block_sizes' is not defined\u001b[0m\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mERROR\u001b[0m evals/tmp0rr5lwej/test_add_kernel.py - NameError: name 'get_optimal_block_sizes' is not defined\n",
      "\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n",
      "\u001b[31m=============================== \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 2.01s\u001b[0m\u001b[31m ===============================\u001b[0m\n",
      "\n",
      ", safety_validation={'success': False, 'error': \"Correctness tests failed (exit 2):\\nSTDOUT: \\x1b[1m============================= test session starts ==============================\\x1b[0m\\nplatform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\\ncachedir: .pytest_cache\\nrootdir: /home/sapmajum/neurips/geak-openevolve\\nconfigfile: pyproject.toml\\nplugins: timeout-2.4.0, anyio-4.11.0\\n\\x1b[1mcollecting ... \\x1b[0mcollected 0 items / 1 error\\n\\n==================================== ERRORS ====================================\\n\\x1b[31m\\x1b[1m________ ERROR collecting tutorial/evals/tmp0rr5lwej/test_add_kernel.py ________\\x1b[0m\\n\\x1b[1m\\x1b[31mevals/tmp0rr5lwej/test_add_kernel.py\\x1b[0m:139: in <module>\\n    \\x1b[0mblock_m, block_n = get_optimal_block_sizes(M, N)\\x1b[90m\\x1b[39;49;00m\\n                       ^^^^^^^^^^^^^^^^^^^^^^^\\x1b[90m\\x1b[39;49;00m\\n\\x1b[1m\\x1b[31mE   NameError: name 'get_optimal_block_sizes' is not defined\\x1b[0m\\n\\x1b[36m\\x1b[1m=========================== short test summary info ============================\\x1b[0m\\n\\x1b[31mERROR\\x1b[0m evals/tmp0rr5lwej/test_add_kernel.py - NameError: name 'get_optimal_block_sizes' is not defined\\n\\x1b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\\x1b[0m\\n!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\\n\\x1b[31m=============================== \\x1b[31m\\x1b[1m1 error\\x1b[0m\\x1b[31m in 2.01s\\x1b[0m\\x1b[31m ===============================\\x1b[0m\\n\\n\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp4c1y__m6/perf\n",
      "Found 1 JSON files: ['add_kernel_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp4c1y__m6/perf/add_kernel_perf.json\n",
      "Performance data structure: ['params', 'ms', 'min_ms', 'max_ms', 'GB/s', 'TFLOPS']\n",
      "Performance: 0.0067ms (from key 'ms')\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Calculated speedup: 0.006900ms / 0.006700ms = 1.0299x\n",
      "üõ°Ô∏è BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpu24ljk50/test_add_kernel.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpu24ljk50/test_add_kernel.py\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpu24ljk50/test_add_kernel.py -k not (test_performance or test_save)\n",
      "üõ°Ô∏è BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpso7ehkrr/test_add_kernel.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpso7ehkrr/test_add_kernel.py\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpso7ehkrr/test_add_kernel.py -k not (test_performance or test_save)\n",
      "üõ°Ô∏è BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp2eeq7vbq/test_add_kernel.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp2eeq7vbq/test_add_kernel.py\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp2eeq7vbq/test_add_kernel.py -k not (test_performance or test_save)\n",
      "üõ°Ô∏è BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp2h076s1y/test_add_kernel.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp2h076s1y/test_add_kernel.py\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp2h076s1y/test_add_kernel.py -k not (test_performance or test_save)\n",
      "Correctness tests failed. Return code: 2\n",
      "STDOUT: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 0 items / 1 error\n",
      "\n",
      "==================================== ERRORS ====================================\n",
      "\u001b[31m\u001b[1m________ ERROR collecting tutorial/evals/tmpu24ljk50/test_add_kernel.py ________\u001b[0m\n",
      "\u001b[1m\u001b[31mevals/tmpu24ljk50/test_add_kernel.py\u001b[0m:144: in <module>\n",
      "    \u001b[0mblock_m, block_n = get_optimal_block_sizes(M, N)\u001b[90m\u001b[39;49;00m\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE   NameError: name 'get_optimal_block_sizes' is not defined\u001b[0m\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mERROR\u001b[0m evals/tmpu24ljk50/test_add_kernel.py - NameError: name 'get_optimal_block_sizes' is not defined\n",
      "\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n",
      "\u001b[31m=============================== \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 2.09s\u001b[0m\u001b[31m ===============================\u001b[0m\n",
      "\n",
      "STDERR: \n",
      "üõ°Ô∏è BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpt_c42a9b/test_add_kernel.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpt_c42a9b/test_add_kernel.py\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpt_c42a9b/test_add_kernel.py -k not (test_performance or test_save)\n",
      "Correctness tests failed. Return code: 2\n",
      "STDOUT: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 0 items / 1 error\n",
      "\n",
      "==================================== ERRORS ====================================\n",
      "\u001b[31m\u001b[1m________ ERROR collecting tutorial/evals/tmpso7ehkrr/test_add_kernel.py ________\u001b[0m\n",
      "\u001b[1m\u001b[31mevals/tmpso7ehkrr/test_add_kernel.py\u001b[0m:140: in <module>\n",
      "    \u001b[0mblock_m, block_n = get_optimal_block_sizes(M, N)\u001b[90m\u001b[39;49;00m\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE   NameError: name 'get_optimal_block_sizes' is not defined\u001b[0m\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mERROR\u001b[0m evals/tmpso7ehkrr/test_add_kernel.py - NameError: name 'get_optimal_block_sizes' is not defined\n",
      "\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n",
      "\u001b[31m=============================== \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 2.09s\u001b[0m\u001b[31m ===============================\u001b[0m\n",
      "\n",
      "STDERR: \n",
      "üõ°Ô∏è BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp0rr5lwej/test_add_kernel.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp0rr5lwej/test_add_kernel.py\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp0rr5lwej/test_add_kernel.py -k not (test_performance or test_save)\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp2eeq7vbq/test_add_kernel.py -k test_performance or test_save_performance_results\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp2h076s1y/test_add_kernel.py -k test_performance or test_save_performance_results\n",
      "Correctness tests failed. Return code: 2\n",
      "STDOUT: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 0 items / 1 error\n",
      "\n",
      "==================================== ERRORS ====================================\n",
      "\u001b[31m\u001b[1m________ ERROR collecting tutorial/evals/tmp0rr5lwej/test_add_kernel.py ________\u001b[0m\n",
      "\u001b[1m\u001b[31mevals/tmp0rr5lwej/test_add_kernel.py\u001b[0m:139: in <module>\n",
      "    \u001b[0mblock_m, block_n = get_optimal_block_sizes(M, N)\u001b[90m\u001b[39;49;00m\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE   NameError: name 'get_optimal_block_sizes' is not defined\u001b[0m\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mERROR\u001b[0m evals/tmp0rr5lwej/test_add_kernel.py - NameError: name 'get_optimal_block_sizes' is not defined\n",
      "\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!\n",
      "\u001b[31m=============================== \u001b[31m\u001b[1m1 error\u001b[0m\u001b[31m in 2.01s\u001b[0m\u001b[31m ===============================\u001b[0m\n",
      "\n",
      "STDERR: \n",
      "üõ°Ô∏è BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmph7r_9s8c/test_add_kernel.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmph7r_9s8c/test_add_kernel.py"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 14:42:22,521 - INFO - Time spent in evaluation: 26.56 seconds\n",
      "2025-11-26 14:42:22,521 - INFO - Evaluated program cb4a9e19-d31e-42a4-95ec-dca3d855a04f in 26.56s: success=1.0000, final_score=1.0147, performance_metrics=1.0147, correctness_score=1.0000, combined_score=1.0147, benchmark_results=['Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16; memory_bound=False, achieved latency: 0.006800 ms, speedup: 1.0147x.'], baseline_comparison=Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16; memory_bound=False, achieved latency: 0.006800 ms, speedup: 1.0147x. Speedup=1.0147x (baseline: 0.006900ms, current: 0.006800ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 1.0147x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None\n",
      "2025-11-26 14:42:24,097 - INFO - Time spent in evaluation: 28.13 seconds\n",
      "2025-11-26 14:42:24,097 - INFO - Evaluated program 9a1d3509-87c8-454b-ab5d-deb369175545 in 28.13s: success=1.0000, final_score=0.4694, performance_metrics=0.4694, correctness_score=1.0000, combined_score=0.4694, benchmark_results=['Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.014700 ms, speedup: 0.4694x.'], baseline_comparison=Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.014700 ms, speedup: 0.4694x. Speedup=0.4694x (baseline: 0.006900ms, current: 0.014700ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 0.4694x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None\n",
      "2025-11-26 14:42:24,999 - INFO - Time spent in evaluation: 26.28 seconds\n",
      "2025-11-26 14:42:24,999 - INFO - Evaluated program 6ee48874-45ac-4325-b938-dfb8404f5456 in 26.28s: success=1.0000, final_score=0.5188, performance_metrics=0.5188, correctness_score=1.0000, combined_score=0.5188, benchmark_results=['Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.013300 ms, speedup: 0.5188x.'], baseline_comparison=Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.013300 ms, speedup: 0.5188x. Speedup=0.5188x (baseline: 0.006900ms, current: 0.013300ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 0.5188x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None\n",
      "2025-11-26 14:42:25,743 - INFO - Time spent in evaluation: 24.31 seconds\n",
      "2025-11-26 14:42:25,743 - INFO - Evaluated program e3c14305-38bf-4c27-8fb7-2a64f281bb75 in 24.31s: success=1.0000, final_score=0.1108, performance_metrics=0.1108, correctness_score=1.0000, combined_score=0.1108, benchmark_results=['Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.062300 ms, speedup: 0.1108x.'], baseline_comparison=Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.062300 ms, speedup: 0.1108x. Speedup=0.1108x (baseline: 0.006900ms, current: 0.062300ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 0.1108x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None\n",
      "2025-11-26 14:42:45,348 - INFO - Time spent in evaluation: 22.83 seconds\n",
      "2025-11-26 14:42:45,349 - INFO - Evaluated program 159e5e3b-715a-416f-9387-03a5e2013031 in 22.83s: success=1.0000, final_score=1.0000, performance_metrics=1.0000, correctness_score=1.0000, combined_score=1.0000, benchmark_results=['Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.006900 ms, speedup: 1.0000x.'], baseline_comparison=Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.006900 ms, speedup: 1.0000x. Speedup=1.0000x (baseline: 0.006900ms, current: 0.006900ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 1.0000x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None\n",
      "2025-11-26 14:42:45,349 - INFO - Child programs evaluated in 49.39 seconds\n",
      "2025-11-26 14:42:45,349 - INFO - Updated sampling model 0 with reward 0.0\n",
      "2025-11-26 14:42:45,349 - INFO - Updated sampling model 0 with reward 0.0\n",
      "2025-11-26 14:42:45,350 - INFO - Updated sampling model 0 with reward 1.0147058823529411\n",
      "2025-11-26 14:42:45,350 - INFO - Updated sampling model 0 with reward 0.46938775510204084\n",
      "2025-11-26 14:42:45,350 - INFO - Updated sampling model 0 with reward 0.518796992481203\n",
      "2025-11-26 14:42:45,350 - INFO - Updated sampling model 0 with reward 0.0\n",
      "2025-11-26 14:42:45,351 - INFO - Updated sampling model 0 with reward 0.11075441412520064\n",
      "2025-11-26 14:42:45,351 - INFO - Updated sampling model 0 with reward 1.0\n",
      "2025-11-26 14:42:45,351 - INFO - Iteration 2: Child 159e5e3b-715a-416f-9387-03a5e2013031 from parent 1de88931-60a8-4b72-adad-e728f58f9e0e in 101.21s. Metrics: success=1.0000, final_score=1.0000, performance_metrics=1.0000, correctness_score=1.0000, combined_score=1.0000, benchmark_results=['Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.006900 ms, speedup: 1.0000x.'], baseline_comparison=Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.006900 ms, speedup: 1.0000x. Speedup=1.0000x (baseline: 0.006900ms, current: 0.006900ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 1.0000x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None (Œî: success=+0.0000, final_score=-0.0299, performance_metrics=-0.0299, correctness_score=+0.0000, combined_score=-0.0299)\n",
      "2025-11-26 14:42:45,352 - INFO - Sampled model: claude-sonnet-4\n",
      "2025-11-26 14:42:45,352 - INFO - Sampled model: claude-sonnet-4\n",
      "2025-11-26 14:42:45,352 - INFO - Sampled model: claude-sonnet-4\n",
      "2025-11-26 14:42:45,352 - INFO - Sampled model: claude-sonnet-4\n",
      "2025-11-26 14:42:45,352 - INFO - Sampled model: claude-sonnet-4\n",
      "2025-11-26 14:42:45,352 - INFO - Sampled model: claude-sonnet-4\n",
      "2025-11-26 14:42:45,352 - INFO - Sampled model: claude-sonnet-4\n",
      "2025-11-26 14:42:45,354 - INFO - Sampled model: claude-sonnet-4\n",
      "2025-11-26 14:43:18,703 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 14:43:19,192 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 14:43:20,331 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 14:43:21,028 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 14:43:22,094 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 14:43:22,857 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 14:43:25,495 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 14:43:28,431 - INFO - HTTP Request: POST https://llm-api.amd.com/AnthropicVertex/deployments/claude-sonnet-4/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-11-26 14:43:28,516 - INFO - LLM responses generated in 43.16 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmph7r_9s8c/test_add_kernel.py -k not (test_performance or test_save)\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpt_c42a9b/test_add_kernel.py -k test_performance or test_save_performance_results\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmph7r_9s8c/test_add_kernel.py -k test_performance or test_save_performance_results\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 136 items / 7 deselected / 129 selected\n",
      "\n",
      "evals/tmp2eeq7vbq/test_add_kernel.py::test_performance[64-64-64-64-float16] \u001b[32mPASSED\u001b[0m\u001b[32m \n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp2eeq7vbq/perf\n",
      "Found 1 JSON files: ['add_kernel_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp2eeq7vbq/perf/add_kernel_perf.json\n",
      "Performance data structure: ['params', 'ms', 'min_ms', 'max_ms', 'GB/s', 'TFLOPS']\n",
      "Performance: 0.0068ms (from key 'ms')\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Calculated speedup: 0.006900ms / 0.006800ms = 1.0147x\n",
      "üõ°Ô∏è BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp_mm22tsm/test_add_kernel.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp_mm22tsm/test_add_kernel.py\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp_mm22tsm/test_add_kernel.py -k not (test_performance or test_save)\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 136 items / 7 deselected / 129 selected\n",
      "\n",
      "evals/tmp2h076s1y/test_add_kernel.py::test_performance[64-64-64-64-float16] \u001b[32mPASSED\u001b[0m\u001b[32m \n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp2h076s1y/perf\n",
      "Found 1 JSON files: ['add_kernel_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp2h076s1y/perf/add_kernel_perf.json\n",
      "Performance data structure: ['params', 'ms', 'min_ms', 'max_ms', 'GB/s', 'TFLOPS']\n",
      "Performance: 0.0147ms (from key 'ms')\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Calculated speedup: 0.006900ms / 0.014700ms = 0.4694x\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 136 items / 7 deselected / 129 selected\n",
      "\n",
      "evals/tmpt_c42a9b/test_add_kernel.py::test_performance[64-64-64-64-float16] \u001b[32mPASSED\u001b[0m\u001b[32m \n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpt_c42a9b/perf\n",
      "Found 1 JSON files: ['add_kernel_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpt_c42a9b/perf/add_kernel_perf.json\n",
      "Performance data structure: ['params', 'ms', 'min_ms', 'max_ms', 'GB/s', 'TFLOPS']\n",
      "Performance: 0.0133ms (from key 'ms')\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Calculated speedup: 0.006900ms / 0.013300ms = 0.5188x\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp_mm22tsm/test_add_kernel.py -k test_performance or test_save_performance_results\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 136 items / 7 deselected / 129 selected\n",
      "\n",
      "evals/tmph7r_9s8c/test_add_kernel.py::test_performance[64-64-64-64-float16] \u001b[32mPASSED\u001b[0m\u001b[32m \n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmph7r_9s8c/perf\n",
      "Found 1 JSON files: ['add_kernel_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmph7r_9s8c/perf/add_kernel_perf.json\n",
      "Performance data structure: ['params', 'ms', 'min_ms', 'max_ms', 'GB/s', 'TFLOPS']\n",
      "Performance: 0.0623ms (from key 'ms')\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Calculated speedup: 0.006900ms / 0.062300ms = 0.1108x\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 136 items / 7 deselected / 129 selected\n",
      "\n",
      "evals/tmp_mm22tsm/test_add_kernel.py::test_performance[64-64-64-64-float16] \u001b[32mPASSED\u001b[0m\u001b[32m \n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp_mm22tsm/perf\n",
      "Found 1 JSON files: ['add_kernel_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp_mm22tsm/perf/add_kernel_perf.json\n",
      "Performance data structure: ['params', 'ms', 'min_ms', 'max_ms', 'GB/s', 'TFLOPS']\n",
      "Performance: 0.0069ms (from key 'ms')\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Calculated speedup: 0.006900ms / 0.006900ms = 1.0000x\n",
      "üõ°Ô∏è BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp0guovkxi/test_add_kernel.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp0guovkxi/test_add_kernel.py\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp0guovkxi/test_add_kernel.py -k not (test_performance or test_save)\n",
      "üõ°Ô∏è BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpvs36697q/test_add_kernel.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpvs36697q/test_add_kernel.py\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpvs36697q/test_add_kernel.py -k not (test_performance or test_save)\n",
      "üõ°Ô∏è BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpyddatjy0/test_add_kernel.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpyddatjy0/test_add_kernel.py\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpyddatjy0/test_add_kernel.py -k not (test_performance or test_save)\n",
      "üõ°Ô∏è BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp1olrtcz1/test_add_kernel.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp1olrtcz1/test_add_kernel.py\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp1olrtcz1/test_add_kernel.py -k not (test_performance or test_save)\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp0guovkxi/test_add_kernel.py -k test_performance or test_save_performance_results\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpvs36697q/test_add_kernel.py -k test_performance or test_save_performance_results\n",
      "Correctness tests failed. Return code: 1\n",
      "STDOUT: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 136 items / 130 deselected / 6 selected\n",
      "\n",
      "evals/tmpyddatjy0/test_add_kernel.py::test_add[64-128-64-128-float16] \u001b[31mFAILED\u001b[0m\u001b[31m [ 16%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_______________________ test_add[64-128-64-128-float16] ________________________\u001b[0m\n",
      "\n",
      "args = (constexpr[64], constexpr[8])\n",
      "kwargs = {'_builder': <triton._C.libtriton.ir.builder object at 0x712c559062d0>}\n",
      "\n",
      "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(fn)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mwrapper\u001b[39;49;00m(*args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33m_builder\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m kwargs \u001b[95mor\u001b[39;49;00m kwargs[\u001b[33m\"\u001b[39;49;00m\u001b[33m_builder\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(kwargs)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mDid you forget to add @triton.jit ? \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                             \u001b[33m\"\u001b[39;49;00m\u001b[33m(`_builder` argument must be provided outside of JIT functions.)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m fn(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "               ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/language/core.py\u001b[0m:35: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/language/core.py\u001b[0m:2213: in multiple_of\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m semantic.multiple_of(\u001b[96minput\u001b[39;49;00m, values)\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "x = constexpr[64], values = [8]\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmultiple_of\u001b[39;49;00m(x: tl.tensor, values: List[\u001b[96mint\u001b[39;49;00m]) -> tl.tensor:\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mif\u001b[39;49;00m \u001b[96mmax\u001b[39;49;00m(\u001b[94m1\u001b[39;49;00m, \u001b[96mlen\u001b[39;49;00m(x.shape)) != \u001b[96mlen\u001b[39;49;00m(values):\u001b[90m\u001b[39;49;00m\n",
      "                      ^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AttributeError: 'constexpr' object has no attribute 'shape'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/language/semantic.py\u001b[0m:1673: AttributeError\n",
      "\n",
      "\u001b[33mThe above exception was the direct cause of the following exception:\u001b[0m\n",
      "\n",
      "M = 64, N = 128, BLOCK_SIZE_M = 64, BLOCK_SIZE_N = 128, dtype_str = 'float16'\n",
      "request = <FixtureRequest for <Function test_add[64-128-64-128-float16]>>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m'\u001b[39;49;00m\u001b[33mM,N,BLOCK_SIZE_M,BLOCK_SIZE_N,dtype_str\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                             [(\u001b[94m64\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m64\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, dtype_str) \u001b[94mfor\u001b[39;49;00m dtype_str \u001b[95min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mfloat16\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]] +\u001b[90m\u001b[39;49;00m\n",
      "                             [(\u001b[94m128\u001b[39;49;00m, \u001b[94m256\u001b[39;49;00m, \u001b[94m64\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, dtype_str) \u001b[94mfor\u001b[39;49;00m dtype_str \u001b[95min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mfloat16\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]] +\u001b[90m\u001b[39;49;00m\n",
      "                             [(\u001b[94m256\u001b[39;49;00m, \u001b[94m512\u001b[39;49;00m, \u001b[94m64\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, dtype_str) \u001b[94mfor\u001b[39;49;00m dtype_str \u001b[95min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mfloat16\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_add\u001b[39;49;00m(M, N, BLOCK_SIZE_M, BLOCK_SIZE_N, dtype_str, request):\u001b[90m\u001b[39;49;00m\n",
      "        set_seed()\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        dtype = dtype_mapping[dtype_str]\u001b[90m\u001b[39;49;00m\n",
      "        x = torch.randn(M, N, device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "        y = torch.randn(M, N, device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "        output = torch.empty(M, N, device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mgrid\u001b[39;49;00m(meta):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m (triton.cdiv(M, meta[\u001b[33m'\u001b[39;49;00m\u001b[33mBLOCK_SIZE_M\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]), triton.cdiv(N, meta[\u001b[33m'\u001b[39;49;00m\u001b[33mBLOCK_SIZE_N\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       add_kernel[grid](\u001b[90m\u001b[39;49;00m\n",
      "            x, y, output, M, N,\u001b[90m\u001b[39;49;00m\n",
      "            x.stride(\u001b[94m0\u001b[39;49;00m), x.stride(\u001b[94m1\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            y.stride(\u001b[94m0\u001b[39;49;00m), y.stride(\u001b[94m1\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            output.stride(\u001b[94m0\u001b[39;49;00m), output.stride(\u001b[94m1\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            BLOCK_SIZE_M=BLOCK_SIZE_M, BLOCK_SIZE_N=BLOCK_SIZE_N\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mevals/tmpyddatjy0/test_add_kernel.py\u001b[0m:176: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/runtime/jit.py\u001b[0m:330: in <lambda>\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mlambda\u001b[39;49;00m *args, **kwargs: \u001b[96mself\u001b[39;49;00m.run(grid=grid, warmup=\u001b[94mFalse\u001b[39;49;00m, *args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/runtime/jit.py\u001b[0m:623: in run\n",
      "    \u001b[0mkernel = \u001b[96mself\u001b[39;49;00m.compile(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/compiler/compiler.py\u001b[0m:273: in compile\n",
      "    \u001b[0mmodule = src.make_ir(options, codegen_fns, module_map, context)\u001b[90m\u001b[39;49;00m\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <triton.compiler.compiler.ASTSource object at 0x712c55e4b770>\n",
      "options = HIPOptions(num_warps=4, waves_per_eu=1, num_stages=2, num_ctas=1, num_buffers_warp_spec=0, num_consumer_groups=0, reg_...=1, allow_flush_denorm=False, max_num_imprecise_acc_default=0, backend_name='hip', instruction_sched_variant='default')\n",
      "codegen_fns = {'min_dot_size': <function min_dot_size.<locals>.<lambda> at 0x712c55d9a340>}\n",
      "module_map = {'triton.language.extra.libdevice': <module 'triton.language.extra.hip.libdevice' from '/home/sapmajum/miniconda3/lib/python3.13/site-packages/triton/language/extra/hip/libdevice.py'>}\n",
      "context = <triton._C.libtriton.ir.context object at 0x712c55d41af0>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake_ir\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, options, codegen_fns, module_map, context):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m ast_to_ttir(\u001b[96mself\u001b[39;49;00m.fn, \u001b[96mself\u001b[39;49;00m, context=context, options=options, codegen_fns=codegen_fns,\u001b[90m\u001b[39;49;00m\n",
      "                           module_map=module_map)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       triton.compiler.errors.CompilationError: at 13:4:\u001b[0m\n",
      "\u001b[1m\u001b[31mE           x_ptr,\u001b[0m\n",
      "\u001b[1m\u001b[31mE           y_ptr,\u001b[0m\n",
      "\u001b[1m\u001b[31mE           output_ptr,\u001b[0m\n",
      "\u001b[1m\u001b[31mE           M, N,  # Matrix dimensions\u001b[0m\n",
      "\u001b[1m\u001b[31mE           stride_xm, stride_xn,\u001b[0m\n",
      "\u001b[1m\u001b[31mE           stride_ym, stride_yn,\u001b[0m\n",
      "\u001b[1m\u001b[31mE           stride_om, stride_on,\u001b[0m\n",
      "\u001b[1m\u001b[31mE           BLOCK_SIZE_M: tl.constexpr,\u001b[0m\n",
      "\u001b[1m\u001b[31mE           BLOCK_SIZE_N: tl.constexpr,\u001b[0m\n",
      "\u001b[1m\u001b[31mE       ):\u001b[0m\n",
      "\u001b[1m\u001b[31mE           # Enable vectorization for better throughput\u001b[0m\n",
      "\u001b[1m\u001b[31mE           tl.multiple_of(BLOCK_SIZE_M, 8)\u001b[0m\n",
      "\u001b[1m\u001b[31mE           ^\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/compiler/compiler.py\u001b[0m:100: CompilationError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m evals/tmpyddatjy0/test_add_kernel.py::\u001b[1mtest_add[64-128-64-128-float16]\u001b[0m - triton.compiler.errors.CompilationError: at 13:4:\n",
      "\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "\u001b[31m====================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m130 deselected\u001b[0m\u001b[31m in 2.36s\u001b[0m\u001b[31m =======================\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 14:43:31,707 - INFO - Time spent in evaluation: 3.19 seconds\n",
      "2025-11-26 14:43:31,707 - INFO - Evaluated program 8c3f96a8-fff3-42aa-aa59-ed75fad6b4fb in 3.19s: success=0.0000, final_score=0.0000, error=Correctness tests failed (exit 1):\n",
      "STDOUT: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 136 items / 130 deselected / 6 selected\n",
      "\n",
      "evals/tmpyddatjy0/test_add_kernel.py::test_add[64-128-64-128-float16] \u001b[31mFAILED\u001b[0m\u001b[31m [ 16%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_______________________ test_add[64-128-64-128-float16] ________________________\u001b[0m\n",
      "\n",
      "args = (constexpr[64], constexpr[8])\n",
      "kwargs = {'_builder': <triton._C.libtriton.ir.builder object at 0x712c559062d0>}\n",
      "\n",
      "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(fn)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mwrapper\u001b[39;49;00m(*args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33m_builder\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m kwargs \u001b[95mor\u001b[39;49;00m kwargs[\u001b[33m\"\u001b[39;49;00m\u001b[33m_builder\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(kwargs)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mDid you forget to add @triton.jit ? \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                             \u001b[33m\"\u001b[39;49;00m\u001b[33m(`_builder` argument must be provided outside of JIT functions.)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m fn(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "               ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/language/core.py\u001b[0m:35: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/language/core.py\u001b[0m:2213: in multiple_of\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m semantic.multiple_of(\u001b[96minput\u001b[39;49;00m, values)\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "x = constexpr[64], values = [8]\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmultiple_of\u001b[39;49;00m(x: tl.tensor, values: List[\u001b[96mint\u001b[39;49;00m]) -> tl.tensor:\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mif\u001b[39;49;00m \u001b[96mmax\u001b[39;49;00m(\u001b[94m1\u001b[39;49;00m, \u001b[96mlen\u001b[39;49;00m(x.shape)) != \u001b[96mlen\u001b[39;49;00m(values):\u001b[90m\u001b[39;49;00m\n",
      "                      ^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AttributeError: 'constexpr' object has no attribute 'shape'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/language/semantic.py\u001b[0m:1673: AttributeError\n",
      "\n",
      "\u001b[33mThe above exception was the direct cause of the following exception:\u001b[0m\n",
      "\n",
      "M = 64, N = 128, BLOCK_SIZE_M = 64, BLOCK_SIZE_N = 128, dtype_str = 'float16'\n",
      "request = <FixtureRequest for <Function test_add[64-128-64-128-float16]>>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m'\u001b[39;49;00m\u001b[33mM,N,BLOCK_SIZE_M,BLOCK_SIZE_N,dtype_str\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                             [(\u001b[94m64\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m64\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, dtype_str) \u001b[94mfor\u001b[39;49;00m dtype_str \u001b[95min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mfloat16\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]] +\u001b[90m\u001b[39;49;00m\n",
      "                             [(\u001b[94m128\u001b[39;49;00m, \u001b[94m256\u001b[39;49;00m, \u001b[94m64\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, dtype_str) \u001b[94mfor\u001b[39;49;00m dtype_str \u001b[95min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mfloat16\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]] +\u001b[90m\u001b[39;49;00m\n",
      "                             [(\u001b[94m256\u001b[39;49;00m, \u001b[94m512\u001b[39;49;00m, \u001b[94m64\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, dtype_str) \u001b[94mfor\u001b[39;49;00m dtype_str \u001b[95min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mfloat16\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_add\u001b[39;49;00m(M, N, BLOCK_SIZE_M, BLOCK_SIZE_N, dtype_str, request):\u001b[90m\u001b[39;49;00m\n",
      "        set_seed()\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        dtype = dtype_mapping[dtype_str]\u001b[90m\u001b[39;49;00m\n",
      "        x = torch.randn(M, N, device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "        y = torch.randn(M, N, device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "        output = torch.empty(M, N, device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mgrid\u001b[39;49;00m(meta):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m (triton.cdiv(M, meta[\u001b[33m'\u001b[39;49;00m\u001b[33mBLOCK_SIZE_M\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]), triton.cdiv(N, meta[\u001b[33m'\u001b[39;49;00m\u001b[33mBLOCK_SIZE_N\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       add_kernel[grid](\u001b[90m\u001b[39;49;00m\n",
      "            x, y, output, M, N,\u001b[90m\u001b[39;49;00m\n",
      "            x.stride(\u001b[94m0\u001b[39;49;00m), x.stride(\u001b[94m1\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            y.stride(\u001b[94m0\u001b[39;49;00m), y.stride(\u001b[94m1\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            output.stride(\u001b[94m0\u001b[39;49;00m), output.stride(\u001b[94m1\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            BLOCK_SIZE_M=BLOCK_SIZE_M, BLOCK_SIZE_N=BLOCK_SIZE_N\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mevals/tmpyddatjy0/test_add_kernel.py\u001b[0m:176: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/runtime/jit.py\u001b[0m:330: in <lambda>\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mlambda\u001b[39;49;00m *args, **kwargs: \u001b[96mself\u001b[39;49;00m.run(grid=grid, warmup=\u001b[94mFalse\u001b[39;49;00m, *args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/runtime/jit.py\u001b[0m:623: in run\n",
      "    \u001b[0mkernel = \u001b[96mself\u001b[39;49;00m.compile(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/compiler/compiler.py\u001b[0m:273: in compile\n",
      "    \u001b[0mmodule = src.make_ir(options, codegen_fns, module_map, context)\u001b[90m\u001b[39;49;00m\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <triton.compiler.compiler.ASTSource object at 0x712c55e4b770>\n",
      "options = HIPOptions(num_warps=4, waves_per_eu=1, num_stages=2, num_ctas=1, num_buffers_warp_spec=0, num_consumer_groups=0, reg_...=1, allow_flush_denorm=False, max_num_imprecise_acc_default=0, backend_name='hip', instruction_sched_variant='default')\n",
      "codegen_fns = {'min_dot_size': <function min_dot_size.<locals>.<lambda> at 0x712c55d9a340>}\n",
      "module_map = {'triton.language.extra.libdevice': <module 'triton.language.extra.hip.libdevice' from '/home/sapmajum/miniconda3/lib/python3.13/site-packages/triton/language/extra/hip/libdevice.py'>}\n",
      "context = <triton._C.libtriton.ir.context object at 0x712c55d41af0>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake_ir\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, options, codegen_fns, module_map, context):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m ast_to_ttir(\u001b[96mself\u001b[39;49;00m.fn, \u001b[96mself\u001b[39;49;00m, context=context, options=options, codegen_fns=codegen_fns,\u001b[90m\u001b[39;49;00m\n",
      "                           module_map=module_map)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       triton.compiler.errors.CompilationError: at 13:4:\u001b[0m\n",
      "\u001b[1m\u001b[31mE           x_ptr,\u001b[0m\n",
      "\u001b[1m\u001b[31mE           y_ptr,\u001b[0m\n",
      "\u001b[1m\u001b[31mE           output_ptr,\u001b[0m\n",
      "\u001b[1m\u001b[31mE           M, N,  # Matrix dimensions\u001b[0m\n",
      "\u001b[1m\u001b[31mE           stride_xm, stride_xn,\u001b[0m\n",
      "\u001b[1m\u001b[31mE           stride_ym, stride_yn,\u001b[0m\n",
      "\u001b[1m\u001b[31mE           stride_om, stride_on,\u001b[0m\n",
      "\u001b[1m\u001b[31mE           BLOCK_SIZE_M: tl.constexpr,\u001b[0m\n",
      "\u001b[1m\u001b[31mE           BLOCK_SIZE_N: tl.constexpr,\u001b[0m\n",
      "\u001b[1m\u001b[31mE       ):\u001b[0m\n",
      "\u001b[1m\u001b[31mE           # Enable vectorization for better throughput\u001b[0m\n",
      "\u001b[1m\u001b[31mE           tl.multiple_of(BLOCK_SIZE_M, 8)\u001b[0m\n",
      "\u001b[1m\u001b[31mE           ^\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/compiler/compiler.py\u001b[0m:100: CompilationError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m evals/tmpyddatjy0/test_add_kernel.py::\u001b[1mtest_add[64-128-64-128-float16]\u001b[0m - triton.compiler.errors.CompilationError: at 13:4:\n",
      "\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "\u001b[31m====================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m130 deselected\u001b[0m\u001b[31m in 2.36s\u001b[0m\u001b[31m =======================\u001b[0m\n",
      "\n",
      ", performance_metrics={}, combined_score=0.0000, correctness_score=0.0000, summary=Evaluation failed due to: Correctness tests failed (exit 1):\n",
      "STDOUT: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 136 items / 130 deselected / 6 selected\n",
      "\n",
      "evals/tmpyddatjy0/test_add_kernel.py::test_add[64-128-64-128-float16] \u001b[31mFAILED\u001b[0m\u001b[31m [ 16%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_______________________ test_add[64-128-64-128-float16] ________________________\u001b[0m\n",
      "\n",
      "args = (constexpr[64], constexpr[8])\n",
      "kwargs = {'_builder': <triton._C.libtriton.ir.builder object at 0x712c559062d0>}\n",
      "\n",
      "    \u001b[0m\u001b[37m@wraps\u001b[39;49;00m(fn)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mwrapper\u001b[39;49;00m(*args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33m_builder\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[95mnot\u001b[39;49;00m \u001b[95min\u001b[39;49;00m kwargs \u001b[95mor\u001b[39;49;00m kwargs[\u001b[33m\"\u001b[39;49;00m\u001b[33m_builder\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[96mprint\u001b[39;49;00m(kwargs)\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mraise\u001b[39;49;00m \u001b[96mValueError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mDid you forget to add @triton.jit ? \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                             \u001b[33m\"\u001b[39;49;00m\u001b[33m(`_builder` argument must be provided outside of JIT functions.)\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m fn(*args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "               ^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/language/core.py\u001b[0m:35: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/language/core.py\u001b[0m:2213: in multiple_of\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m semantic.multiple_of(\u001b[96minput\u001b[39;49;00m, values)\u001b[90m\u001b[39;49;00m\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "x = constexpr[64], values = [8]\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmultiple_of\u001b[39;49;00m(x: tl.tensor, values: List[\u001b[96mint\u001b[39;49;00m]) -> tl.tensor:\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mif\u001b[39;49;00m \u001b[96mmax\u001b[39;49;00m(\u001b[94m1\u001b[39;49;00m, \u001b[96mlen\u001b[39;49;00m(x.shape)) != \u001b[96mlen\u001b[39;49;00m(values):\u001b[90m\u001b[39;49;00m\n",
      "                      ^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       AttributeError: 'constexpr' object has no attribute 'shape'\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/language/semantic.py\u001b[0m:1673: AttributeError\n",
      "\n",
      "\u001b[33mThe above exception was the direct cause of the following exception:\u001b[0m\n",
      "\n",
      "M = 64, N = 128, BLOCK_SIZE_M = 64, BLOCK_SIZE_N = 128, dtype_str = 'float16'\n",
      "request = <FixtureRequest for <Function test_add[64-128-64-128-float16]>>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m'\u001b[39;49;00m\u001b[33mM,N,BLOCK_SIZE_M,BLOCK_SIZE_N,dtype_str\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                             [(\u001b[94m64\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m64\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, dtype_str) \u001b[94mfor\u001b[39;49;00m dtype_str \u001b[95min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mfloat16\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]] +\u001b[90m\u001b[39;49;00m\n",
      "                             [(\u001b[94m128\u001b[39;49;00m, \u001b[94m256\u001b[39;49;00m, \u001b[94m64\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, dtype_str) \u001b[94mfor\u001b[39;49;00m dtype_str \u001b[95min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mfloat16\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]] +\u001b[90m\u001b[39;49;00m\n",
      "                             [(\u001b[94m256\u001b[39;49;00m, \u001b[94m512\u001b[39;49;00m, \u001b[94m64\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, dtype_str) \u001b[94mfor\u001b[39;49;00m dtype_str \u001b[95min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mfloat16\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_add\u001b[39;49;00m(M, N, BLOCK_SIZE_M, BLOCK_SIZE_N, dtype_str, request):\u001b[90m\u001b[39;49;00m\n",
      "        set_seed()\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        dtype = dtype_mapping[dtype_str]\u001b[90m\u001b[39;49;00m\n",
      "        x = torch.randn(M, N, device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "        y = torch.randn(M, N, device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "        output = torch.empty(M, N, device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mgrid\u001b[39;49;00m(meta):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m (triton.cdiv(M, meta[\u001b[33m'\u001b[39;49;00m\u001b[33mBLOCK_SIZE_M\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]), triton.cdiv(N, meta[\u001b[33m'\u001b[39;49;00m\u001b[33mBLOCK_SIZE_N\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       add_kernel[grid](\u001b[90m\u001b[39;49;00m\n",
      "            x, y, output, M, N,\u001b[90m\u001b[39;49;00m\n",
      "            x.stride(\u001b[94m0\u001b[39;49;00m), x.stride(\u001b[94m1\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            y.stride(\u001b[94m0\u001b[39;49;00m), y.stride(\u001b[94m1\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            output.stride(\u001b[94m0\u001b[39;49;00m), output.stride(\u001b[94m1\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            BLOCK_SIZE_M=BLOCK_SIZE_M, BLOCK_SIZE_N=BLOCK_SIZE_N\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mevals/tmpyddatjy0/test_add_kernel.py\u001b[0m:176: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/runtime/jit.py\u001b[0m:330: in <lambda>\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mlambda\u001b[39;49;00m *args, **kwargs: \u001b[96mself\u001b[39;49;00m.run(grid=grid, warmup=\u001b[94mFalse\u001b[39;49;00m, *args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/runtime/jit.py\u001b[0m:623: in run\n",
      "    \u001b[0mkernel = \u001b[96mself\u001b[39;49;00m.compile(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/compiler/compiler.py\u001b[0m:273: in compile\n",
      "    \u001b[0mmodule = src.make_ir(options, codegen_fns, module_map, context)\u001b[90m\u001b[39;49;00m\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <triton.compiler.compiler.ASTSource object at 0x712c55e4b770>\n",
      "options = HIPOptions(num_warps=4, waves_per_eu=1, num_stages=2, num_ctas=1, num_buffers_warp_spec=0, num_consumer_groups=0, reg_...=1, allow_flush_denorm=False, max_num_imprecise_acc_default=0, backend_name='hip', instruction_sched_variant='default')\n",
      "codegen_fns = {'min_dot_size': <function min_dot_size.<locals>.<lambda> at 0x712c55d9a340>}\n",
      "module_map = {'triton.language.extra.libdevice': <module 'triton.language.extra.hip.libdevice' from '/home/sapmajum/miniconda3/lib/python3.13/site-packages/triton/language/extra/hip/libdevice.py'>}\n",
      "context = <triton._C.libtriton.ir.context object at 0x712c55d41af0>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake_ir\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, options, codegen_fns, module_map, context):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m ast_to_ttir(\u001b[96mself\u001b[39;49;00m.fn, \u001b[96mself\u001b[39;49;00m, context=context, options=options, codegen_fns=codegen_fns,\u001b[90m\u001b[39;49;00m\n",
      "                           module_map=module_map)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       triton.compiler.errors.CompilationError: at 13:4:\u001b[0m\n",
      "\u001b[1m\u001b[31mE           x_ptr,\u001b[0m\n",
      "\u001b[1m\u001b[31mE           y_ptr,\u001b[0m\n",
      "\u001b[1m\u001b[31mE           output_ptr,\u001b[0m\n",
      "\u001b[1m\u001b[31mE           M, N,  # Matrix dimensions\u001b[0m\n",
      "\u001b[1m\u001b[31mE           stride_xm, stride_xn,\u001b[0m\n",
      "\u001b[1m\u001b[31mE           stride_ym, stride_yn,\u001b[0m\n",
      "\u001b[1m\u001b[31mE           stride_om, stride_on,\u001b[0m\n",
      "\u001b[1m\u001b[31mE           BLOCK_SIZE_M: tl.constexpr,\u001b[0m\n",
      "\u001b[1m\u001b[31mE           BLOCK_SIZE_N: tl.constexpr,\u001b[0m\n",
      "\u001b[1m\u001b[31mE       ):\u001b[0m\n",
      "\u001b[1m\u001b[31mE           # Enable vectorization for better throughput\u001b[0m\n",
      "\u001b[1m\u001b[31mE           tl.multiple_of(BLOCK_SIZE_M, 8)\u001b[0m\n",
      "\u001b[1m\u001b[31mE           ^\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/compiler/compiler.py\u001b[0m:100: CompilationError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m evals/tmpyddatjy0/test_add_kernel.py::\u001b[1mtest_add[64-128-64-128-float16]\u001b[0m - triton.compiler.errors.CompilationError: at 13:4:\n",
      "\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "\u001b[31m====================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m130 deselected\u001b[0m\u001b[31m in 2.36s\u001b[0m\u001b[31m =======================\u001b[0m\n",
      "\n",
      ", safety_validation={'success': False, 'error': 'Correctness tests failed (exit 1):\\nSTDOUT: \\x1b[1m============================= test session starts ==============================\\x1b[0m\\nplatform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\\ncachedir: .pytest_cache\\nrootdir: /home/sapmajum/neurips/geak-openevolve\\nconfigfile: pyproject.toml\\nplugins: timeout-2.4.0, anyio-4.11.0\\n\\x1b[1mcollecting ... \\x1b[0mcollected 136 items / 130 deselected / 6 selected\\n\\nevals/tmpyddatjy0/test_add_kernel.py::test_add[64-128-64-128-float16] \\x1b[31mFAILED\\x1b[0m\\x1b[31m [ 16%]\\x1b[0m\\n\\n=================================== FAILURES ===================================\\n\\x1b[31m\\x1b[1m_______________________ test_add[64-128-64-128-float16] ________________________\\x1b[0m\\n\\nargs = (constexpr[64], constexpr[8])\\nkwargs = {\\'_builder\\': <triton._C.libtriton.ir.builder object at 0x712c559062d0>}\\n\\n    \\x1b[0m\\x1b[37m@wraps\\x1b[39;49;00m(fn)\\x1b[90m\\x1b[39;49;00m\\n    \\x1b[94mdef\\x1b[39;49;00m\\x1b[90m \\x1b[39;49;00m\\x1b[92mwrapper\\x1b[39;49;00m(*args, **kwargs):\\x1b[90m\\x1b[39;49;00m\\n        \\x1b[94mif\\x1b[39;49;00m \\x1b[33m\"\\x1b[39;49;00m\\x1b[33m_builder\\x1b[39;49;00m\\x1b[33m\"\\x1b[39;49;00m \\x1b[95mnot\\x1b[39;49;00m \\x1b[95min\\x1b[39;49;00m kwargs \\x1b[95mor\\x1b[39;49;00m kwargs[\\x1b[33m\"\\x1b[39;49;00m\\x1b[33m_builder\\x1b[39;49;00m\\x1b[33m\"\\x1b[39;49;00m] \\x1b[95mis\\x1b[39;49;00m \\x1b[94mNone\\x1b[39;49;00m:\\x1b[90m\\x1b[39;49;00m\\n            \\x1b[96mprint\\x1b[39;49;00m(kwargs)\\x1b[90m\\x1b[39;49;00m\\n            \\x1b[94mraise\\x1b[39;49;00m \\x1b[96mValueError\\x1b[39;49;00m(\\x1b[33m\"\\x1b[39;49;00m\\x1b[33mDid you forget to add @triton.jit ? \\x1b[39;49;00m\\x1b[33m\"\\x1b[39;49;00m\\x1b[90m\\x1b[39;49;00m\\n                             \\x1b[33m\"\\x1b[39;49;00m\\x1b[33m(`_builder` argument must be provided outside of JIT functions.)\\x1b[39;49;00m\\x1b[33m\"\\x1b[39;49;00m)\\x1b[90m\\x1b[39;49;00m\\n>       \\x1b[94mreturn\\x1b[39;49;00m fn(*args, **kwargs)\\x1b[90m\\x1b[39;49;00m\\n               ^^^^^^^^^^^^^^^^^^^\\x1b[90m\\x1b[39;49;00m\\n\\n\\x1b[1m\\x1b[31m../../../miniconda3/lib/python3.13/site-packages/triton/language/core.py\\x1b[0m:35: \\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \\n\\x1b[1m\\x1b[31m../../../miniconda3/lib/python3.13/site-packages/triton/language/core.py\\x1b[0m:2213: in multiple_of\\n    \\x1b[0m\\x1b[94mreturn\\x1b[39;49;00m semantic.multiple_of(\\x1b[96minput\\x1b[39;49;00m, values)\\x1b[90m\\x1b[39;49;00m\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\x1b[90m\\x1b[39;49;00m\\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \\n\\nx = constexpr[64], values = [8]\\n\\n    \\x1b[0m\\x1b[94mdef\\x1b[39;49;00m\\x1b[90m \\x1b[39;49;00m\\x1b[92mmultiple_of\\x1b[39;49;00m(x: tl.tensor, values: List[\\x1b[96mint\\x1b[39;49;00m]) -> tl.tensor:\\x1b[90m\\x1b[39;49;00m\\n>       \\x1b[94mif\\x1b[39;49;00m \\x1b[96mmax\\x1b[39;49;00m(\\x1b[94m1\\x1b[39;49;00m, \\x1b[96mlen\\x1b[39;49;00m(x.shape)) != \\x1b[96mlen\\x1b[39;49;00m(values):\\x1b[90m\\x1b[39;49;00m\\n                      ^^^^^^^\\x1b[90m\\x1b[39;49;00m\\n\\x1b[1m\\x1b[31mE       AttributeError: \\'constexpr\\' object has no attribute \\'shape\\'\\x1b[0m\\n\\n\\x1b[1m\\x1b[31m../../../miniconda3/lib/python3.13/site-packages/triton/language/semantic.py\\x1b[0m:1673: AttributeError\\n\\n\\x1b[33mThe above exception was the direct cause of the following exception:\\x1b[0m\\n\\nM = 64, N = 128, BLOCK_SIZE_M = 64, BLOCK_SIZE_N = 128, dtype_str = \\'float16\\'\\nrequest = <FixtureRequest for <Function test_add[64-128-64-128-float16]>>\\n\\n    \\x1b[0m\\x1b[37m@pytest\\x1b[39;49;00m.mark.parametrize(\\x1b[33m\\'\\x1b[39;49;00m\\x1b[33mM,N,BLOCK_SIZE_M,BLOCK_SIZE_N,dtype_str\\x1b[39;49;00m\\x1b[33m\\'\\x1b[39;49;00m,\\x1b[90m\\x1b[39;49;00m\\n                             [(\\x1b[94m64\\x1b[39;49;00m, \\x1b[94m128\\x1b[39;49;00m, \\x1b[94m64\\x1b[39;49;00m, \\x1b[94m128\\x1b[39;49;00m, dtype_str) \\x1b[94mfor\\x1b[39;49;00m dtype_str \\x1b[95min\\x1b[39;49;00m [\\x1b[33m\\'\\x1b[39;49;00m\\x1b[33mfloat16\\x1b[39;49;00m\\x1b[33m\\'\\x1b[39;49;00m, \\x1b[33m\\'\\x1b[39;49;00m\\x1b[33mfloat32\\x1b[39;49;00m\\x1b[33m\\'\\x1b[39;49;00m]] +\\x1b[90m\\x1b[39;49;00m\\n                             [(\\x1b[94m128\\x1b[39;49;00m, \\x1b[94m256\\x1b[39;49;00m, \\x1b[94m64\\x1b[39;49;00m, \\x1b[94m128\\x1b[39;49;00m, dtype_str) \\x1b[94mfor\\x1b[39;49;00m dtype_str \\x1b[95min\\x1b[39;49;00m [\\x1b[33m\\'\\x1b[39;49;00m\\x1b[33mfloat16\\x1b[39;49;00m\\x1b[33m\\'\\x1b[39;49;00m, \\x1b[33m\\'\\x1b[39;49;00m\\x1b[33mfloat32\\x1b[39;49;00m\\x1b[33m\\'\\x1b[39;49;00m]] +\\x1b[90m\\x1b[39;49;00m\\n                             [(\\x1b[94m256\\x1b[39;49;00m, \\x1b[94m512\\x1b[39;49;00m, \\x1b[94m64\\x1b[39;49;00m, \\x1b[94m128\\x1b[39;49;00m, dtype_str) \\x1b[94mfor\\x1b[39;49;00m dtype_str \\x1b[95min\\x1b[39;49;00m [\\x1b[33m\\'\\x1b[39;49;00m\\x1b[33mfloat16\\x1b[39;49;00m\\x1b[33m\\'\\x1b[39;49;00m, \\x1b[33m\\'\\x1b[39;49;00m\\x1b[33mfloat32\\x1b[39;49;00m\\x1b[33m\\'\\x1b[39;49;00m]])\\x1b[90m\\x1b[39;49;00m\\n    \\x1b[94mdef\\x1b[39;49;00m\\x1b[90m \\x1b[39;49;00m\\x1b[92mtest_add\\x1b[39;49;00m(M, N, BLOCK_SIZE_M, BLOCK_SIZE_N, dtype_str, request):\\x1b[90m\\x1b[39;49;00m\\n        set_seed()\\x1b[90m\\x1b[39;49;00m\\n    \\x1b[90m\\x1b[39;49;00m\\n        dtype = dtype_mapping[dtype_str]\\x1b[90m\\x1b[39;49;00m\\n        x = torch.randn(M, N, device=\\x1b[33m\\'\\x1b[39;49;00m\\x1b[33mcuda\\x1b[39;49;00m\\x1b[33m\\'\\x1b[39;49;00m, dtype=dtype)\\x1b[90m\\x1b[39;49;00m\\n        y = torch.randn(M, N, device=\\x1b[33m\\'\\x1b[39;49;00m\\x1b[33mcuda\\x1b[39;49;00m\\x1b[33m\\'\\x1b[39;49;00m, dtype=dtype)\\x1b[90m\\x1b[39;49;00m\\n        output = torch.empty(M, N, device=\\x1b[33m\\'\\x1b[39;49;00m\\x1b[33mcuda\\x1b[39;49;00m\\x1b[33m\\'\\x1b[39;49;00m, dtype=dtype)\\x1b[90m\\x1b[39;49;00m\\n    \\x1b[90m\\x1b[39;49;00m\\n        \\x1b[94mdef\\x1b[39;49;00m\\x1b[90m \\x1b[39;49;00m\\x1b[92mgrid\\x1b[39;49;00m(meta):\\x1b[90m\\x1b[39;49;00m\\n            \\x1b[94mreturn\\x1b[39;49;00m (triton.cdiv(M, meta[\\x1b[33m\\'\\x1b[39;49;00m\\x1b[33mBLOCK_SIZE_M\\x1b[39;49;00m\\x1b[33m\\'\\x1b[39;49;00m]), triton.cdiv(N, meta[\\x1b[33m\\'\\x1b[39;49;00m\\x1b[33mBLOCK_SIZE_N\\x1b[39;49;00m\\x1b[33m\\'\\x1b[39;49;00m]))\\x1b[90m\\x1b[39;49;00m\\n    \\x1b[90m\\x1b[39;49;00m\\n>       add_kernel[grid](\\x1b[90m\\x1b[39;49;00m\\n            x, y, output, M, N,\\x1b[90m\\x1b[39;49;00m\\n            x.stride(\\x1b[94m0\\x1b[39;49;00m), x.stride(\\x1b[94m1\\x1b[39;49;00m),\\x1b[90m\\x1b[39;49;00m\\n            y.stride(\\x1b[94m0\\x1b[39;49;00m), y.stride(\\x1b[94m1\\x1b[39;49;00m),\\x1b[90m\\x1b[39;49;00m\\n            output.stride(\\x1b[94m0\\x1b[39;49;00m), output.stride(\\x1b[94m1\\x1b[39;49;00m),\\x1b[90m\\x1b[39;49;00m\\n            BLOCK_SIZE_M=BLOCK_SIZE_M, BLOCK_SIZE_N=BLOCK_SIZE_N\\x1b[90m\\x1b[39;49;00m\\n        )\\x1b[90m\\x1b[39;49;00m\\n\\n\\x1b[1m\\x1b[31mevals/tmpyddatjy0/test_add_kernel.py\\x1b[0m:176: \\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \\n\\x1b[1m\\x1b[31m../../../miniconda3/lib/python3.13/site-packages/triton/runtime/jit.py\\x1b[0m:330: in <lambda>\\n    \\x1b[0m\\x1b[94mreturn\\x1b[39;49;00m \\x1b[94mlambda\\x1b[39;49;00m *args, **kwargs: \\x1b[96mself\\x1b[39;49;00m.run(grid=grid, warmup=\\x1b[94mFalse\\x1b[39;49;00m, *args, **kwargs)\\x1b[90m\\x1b[39;49;00m\\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\x1b[90m\\x1b[39;49;00m\\n\\x1b[1m\\x1b[31m../../../miniconda3/lib/python3.13/site-packages/triton/runtime/jit.py\\x1b[0m:623: in run\\n    \\x1b[0mkernel = \\x1b[96mself\\x1b[39;49;00m.compile(\\x1b[90m\\x1b[39;49;00m\\n\\x1b[1m\\x1b[31m../../../miniconda3/lib/python3.13/site-packages/triton/compiler/compiler.py\\x1b[0m:273: in compile\\n    \\x1b[0mmodule = src.make_ir(options, codegen_fns, module_map, context)\\x1b[90m\\x1b[39;49;00m\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\x1b[90m\\x1b[39;49;00m\\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \\n\\nself = <triton.compiler.compiler.ASTSource object at 0x712c55e4b770>\\noptions = HIPOptions(num_warps=4, waves_per_eu=1, num_stages=2, num_ctas=1, num_buffers_warp_spec=0, num_consumer_groups=0, reg_...=1, allow_flush_denorm=False, max_num_imprecise_acc_default=0, backend_name=\\'hip\\', instruction_sched_variant=\\'default\\')\\ncodegen_fns = {\\'min_dot_size\\': <function min_dot_size.<locals>.<lambda> at 0x712c55d9a340>}\\nmodule_map = {\\'triton.language.extra.libdevice\\': <module \\'triton.language.extra.hip.libdevice\\' from \\'/home/sapmajum/miniconda3/lib/python3.13/site-packages/triton/language/extra/hip/libdevice.py\\'>}\\ncontext = <triton._C.libtriton.ir.context object at 0x712c55d41af0>\\n\\n    \\x1b[0m\\x1b[94mdef\\x1b[39;49;00m\\x1b[90m \\x1b[39;49;00m\\x1b[92mmake_ir\\x1b[39;49;00m(\\x1b[96mself\\x1b[39;49;00m, options, codegen_fns, module_map, context):\\x1b[90m\\x1b[39;49;00m\\n>       \\x1b[94mreturn\\x1b[39;49;00m ast_to_ttir(\\x1b[96mself\\x1b[39;49;00m.fn, \\x1b[96mself\\x1b[39;49;00m, context=context, options=options, codegen_fns=codegen_fns,\\x1b[90m\\x1b[39;49;00m\\n                           module_map=module_map)\\x1b[90m\\x1b[39;49;00m\\n\\x1b[1m\\x1b[31mE       triton.compiler.errors.CompilationError: at 13:4:\\x1b[0m\\n\\x1b[1m\\x1b[31mE           x_ptr,\\x1b[0m\\n\\x1b[1m\\x1b[31mE           y_ptr,\\x1b[0m\\n\\x1b[1m\\x1b[31mE           output_ptr,\\x1b[0m\\n\\x1b[1m\\x1b[31mE           M, N,  # Matrix dimensions\\x1b[0m\\n\\x1b[1m\\x1b[31mE           stride_xm, stride_xn,\\x1b[0m\\n\\x1b[1m\\x1b[31mE           stride_ym, stride_yn,\\x1b[0m\\n\\x1b[1m\\x1b[31mE           stride_om, stride_on,\\x1b[0m\\n\\x1b[1m\\x1b[31mE           BLOCK_SIZE_M: tl.constexpr,\\x1b[0m\\n\\x1b[1m\\x1b[31mE           BLOCK_SIZE_N: tl.constexpr,\\x1b[0m\\n\\x1b[1m\\x1b[31mE       ):\\x1b[0m\\n\\x1b[1m\\x1b[31mE           # Enable vectorization for better throughput\\x1b[0m\\n\\x1b[1m\\x1b[31mE           tl.multiple_of(BLOCK_SIZE_M, 8)\\x1b[0m\\n\\x1b[1m\\x1b[31mE           ^\\x1b[0m\\n\\n\\x1b[1m\\x1b[31m../../../miniconda3/lib/python3.13/site-packages/triton/compiler/compiler.py\\x1b[0m:100: CompilationError\\n\\x1b[36m\\x1b[1m=========================== short test summary info ============================\\x1b[0m\\n\\x1b[31mFAILED\\x1b[0m evals/tmpyddatjy0/test_add_kernel.py::\\x1b[1mtest_add[64-128-64-128-float16]\\x1b[0m - triton.compiler.errors.CompilationError: at 13:4:\\n\\x1b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\\x1b[0m\\n\\x1b[31m====================== \\x1b[31m\\x1b[1m1 failed\\x1b[0m, \\x1b[33m130 deselected\\x1b[0m\\x1b[31m in 2.36s\\x1b[0m\\x1b[31m =======================\\x1b[0m\\n\\n'}\n",
      "2025-11-26 14:43:54,088 - INFO - Time spent in evaluation: 25.57 seconds\n",
      "2025-11-26 14:43:54,088 - INFO - Evaluated program d0fb2772-8258-4ea4-92db-cf3253bbef14 in 25.57s: success=1.0000, final_score=1.0299, performance_metrics=1.0299, correctness_score=1.0000, combined_score=1.0299, benchmark_results=['Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.006700 ms, speedup: 1.0299x.'], baseline_comparison=Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.006700 ms, speedup: 1.0299x. Speedup=1.0299x (baseline: 0.006900ms, current: 0.006700ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 1.0299x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None\n",
      "2025-11-26 14:43:54,830 - INFO - Time spent in evaluation: 26.31 seconds\n",
      "2025-11-26 14:43:54,830 - INFO - Evaluated program 70edb0b5-b699-405c-9930-0a1ab6f98ae1 in 26.31s: success=1.0000, final_score=0.9583, performance_metrics=0.9583, correctness_score=1.0000, combined_score=0.9583, benchmark_results=['Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.007200 ms, speedup: 0.9583x.'], baseline_comparison=Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.007200 ms, speedup: 0.9583x. Speedup=0.9583x (baseline: 0.006900ms, current: 0.007200ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 0.9583x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None\n",
      "2025-11-26 14:43:55,840 - INFO - Time spent in evaluation: 27.32 seconds\n",
      "2025-11-26 14:43:55,840 - INFO - Evaluated program 8d405085-add8-44c3-a4ac-08613f201bed in 27.32s: success=1.0000, final_score=1.0147, performance_metrics=1.0147, correctness_score=1.0000, combined_score=1.0147, benchmark_results=['Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.006800 ms, speedup: 1.0147x.'], baseline_comparison=Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.006800 ms, speedup: 1.0147x. Speedup=1.0147x (baseline: 0.006900ms, current: 0.006800ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 1.0147x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None\n",
      "2025-11-26 14:43:56,904 - INFO - Time spent in evaluation: 25.19 seconds\n",
      "2025-11-26 14:43:56,904 - INFO - Evaluated program 5a3a076c-5810-43a5-9fe3-1badafc638f1 in 25.19s: success=1.0000, final_score=0.1053, performance_metrics=0.1053, correctness_score=1.0000, combined_score=0.1053, benchmark_results=['Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16; aspect_ratio=1.0; memory_bound=False, achieved latency: 0.065500 ms, speedup: 0.1053x.'], baseline_comparison=Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16; aspect_ratio=1.0; memory_bound=False, achieved latency: 0.065500 ms, speedup: 0.1053x. Speedup=0.1053x (baseline: 0.006900ms, current: 0.065500ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 0.1053x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None\n",
      "2025-11-26 14:43:57,026 - INFO - Time spent in evaluation: 2.94 seconds\n",
      "2025-11-26 14:43:57,026 - INFO - Evaluated program 92c4592a-f813-4aca-b9dc-7d9473979f19 in 2.94s: success=0.0000, final_score=0.0000, error=Correctness tests failed (exit 1):\n",
      "STDOUT: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 136 items / 130 deselected / 6 selected\n",
      "\n",
      "evals/tmpn_y4ccf3/test_add_kernel.py::test_add[64-128-64-128-float16] \u001b[31mFAILED\u001b[0m\u001b[31m [ 16%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_______________________ test_add[64-128-64-128-float16] ________________________\u001b[0m\n",
      "\n",
      "M = 64, N = 128, BLOCK_SIZE_M = 64, BLOCK_SIZE_N = 128, dtype_str = 'float16'\n",
      "request = <FixtureRequest for <Function test_add[64-128-64-128-float16]>>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m'\u001b[39;49;00m\u001b[33mM,N,BLOCK_SIZE_M,BLOCK_SIZE_N,dtype_str\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                             [(\u001b[94m64\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m64\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, dtype_str) \u001b[94mfor\u001b[39;49;00m dtype_str \u001b[95min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mfloat16\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]] +\u001b[90m\u001b[39;49;00m\n",
      "                             [(\u001b[94m128\u001b[39;49;00m, \u001b[94m256\u001b[39;49;00m, \u001b[94m64\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, dtype_str) \u001b[94mfor\u001b[39;49;00m dtype_str \u001b[95min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mfloat16\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]] +\u001b[90m\u001b[39;49;00m\n",
      "                             [(\u001b[94m256\u001b[39;49;00m, \u001b[94m512\u001b[39;49;00m, \u001b[94m64\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, dtype_str) \u001b[94mfor\u001b[39;49;00m dtype_str \u001b[95min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mfloat16\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_add\u001b[39;49;00m(M, N, BLOCK_SIZE_M, BLOCK_SIZE_N, dtype_str, request):\u001b[90m\u001b[39;49;00m\n",
      "        set_seed()\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        dtype = dtype_mapping[dtype_str]\u001b[90m\u001b[39;49;00m\n",
      "        x = torch.randn(M, N, device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "        y = torch.randn(M, N, device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "        output = torch.empty(M, N, device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mgrid\u001b[39;49;00m(meta):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m (triton.cdiv(M, meta[\u001b[33m'\u001b[39;49;00m\u001b[33mBLOCK_SIZE_M\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]), triton.cdiv(N, meta[\u001b[33m'\u001b[39;49;00m\u001b[33mBLOCK_SIZE_N\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       add_kernel[grid](\u001b[90m\u001b[39;49;00m\n",
      "            x, y, output, M, N,\u001b[90m\u001b[39;49;00m\n",
      "            x.stride(\u001b[94m0\u001b[39;49;00m), x.stride(\u001b[94m1\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            y.stride(\u001b[94m0\u001b[39;49;00m), y.stride(\u001b[94m1\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            output.stride(\u001b[94m0\u001b[39;49;00m), output.stride(\u001b[94m1\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            BLOCK_SIZE_M=BLOCK_SIZE_M, BLOCK_SIZE_N=BLOCK_SIZE_N\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mevals/tmpn_y4ccf3/test_add_kernel.py\u001b[0m:186: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/runtime/jit.py\u001b[0m:330: in <lambda>\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mlambda\u001b[39;49;00m *args, **kwargs: \u001b[96mself\u001b[39;49;00m.run(grid=grid, warmup=\u001b[94mFalse\u001b[39;49;00m, *args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/runtime/jit.py\u001b[0m:623: in run\n",
      "    \u001b[0mkernel = \u001b[96mself\u001b[39;49;00m.compile(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/compiler/compiler.py\u001b[0m:273: in compile\n",
      "    \u001b[0mmodule = src.make_ir(options, codegen_fns, module_map, context)\u001b[90m\u001b[39;49;00m\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <triton.compiler.compiler.ASTSource object at 0x7ea0c956f770>\n",
      "options = HIPOptions(num_warps=4, waves_per_eu=1, num_stages=2, num_ctas=1, num_buffers_warp_spec=0, num_consumer_groups=0, reg_...=1, allow_flush_denorm=False, max_num_imprecise_acc_default=0, backend_name='hip', instruction_sched_variant='default')\n",
      "codegen_fns = {'min_dot_size': <function min_dot_size.<locals>.<lambda> at 0x7ea0c94be340>}\n",
      "module_map = {'triton.language.extra.libdevice': <module 'triton.language.extra.hip.libdevice' from '/home/sapmajum/miniconda3/lib/python3.13/site-packages/triton/language/extra/hip/libdevice.py'>}\n",
      "context = <triton._C.libtriton.ir.context object at 0x7ea0ca01b3f0>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake_ir\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, options, codegen_fns, module_map, context):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m ast_to_ttir(\u001b[96mself\u001b[39;49;00m.fn, \u001b[96mself\u001b[39;49;00m, context=context, options=options, codegen_fns=codegen_fns,\u001b[90m\u001b[39;49;00m\n",
      "                           module_map=module_map)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       triton.compiler.errors.UnsupportedLanguageConstruct: at 33:7:\u001b[0m\n",
      "\u001b[1m\u001b[31mE           mask_n = offs_n < N\u001b[0m\n",
      "\u001b[1m\u001b[31mE           mask = mask_m[:, None] & mask_n[None, :]\u001b[0m\n",
      "\u001b[1m\u001b[31mE       \u001b[0m\n",
      "\u001b[1m\u001b[31mE           # Optimize pointer calculations for better memory coalescing\u001b[0m\n",
      "\u001b[1m\u001b[31mE           # Use more efficient broadcasting and stride calculations\u001b[0m\n",
      "\u001b[1m\u001b[31mE           x_ptrs = x_ptr + offs_m[:, None] * stride_xm + offs_n[None, :] * stride_xn\u001b[0m\n",
      "\u001b[1m\u001b[31mE           y_ptrs = y_ptr + offs_m[:, None] * stride_ym + offs_n[None, :] * stride_yn\u001b[0m\n",
      "\u001b[1m\u001b[31mE           output_ptrs = output_ptr + offs_m[:, None] * stride_om + offs_n[None, :] * stride_on\u001b[0m\n",
      "\u001b[1m\u001b[31mE       \u001b[0m\n",
      "\u001b[1m\u001b[31mE           # Optimize for contiguous memory access when possible\u001b[0m\n",
      "\u001b[1m\u001b[31mE           # For row-major matrices with unit stride in the inner dimension\u001b[0m\n",
      "\u001b[1m\u001b[31mE           if stride_xn == 1 and stride_yn == 1 and stride_on == 1:\u001b[0m\n",
      "\u001b[1m\u001b[31mE              ^\u001b[0m\n",
      "\u001b[1m\u001b[31mE       chained boolean operators (A or B or C) are not supported; use parentheses to split the chain.\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/compiler/compiler.py\u001b[0m:100: UnsupportedLanguageConstruct\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m evals/tmpn_y4ccf3/test_add_kernel.py::\u001b[1mtest_add[64-128-64-128-float16]\u001b[0m - triton.compiler.errors.UnsupportedLanguageConstruct: at 33:7:\n",
      "\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "\u001b[31m====================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m130 deselected\u001b[0m\u001b[31m in 2.23s\u001b[0m\u001b[31m =======================\u001b[0m\n",
      "\n",
      ", performance_metrics={}, combined_score=0.0000, correctness_score=0.0000, summary=Evaluation failed due to: Correctness tests failed (exit 1):\n",
      "STDOUT: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 136 items / 130 deselected / 6 selected\n",
      "\n",
      "evals/tmpn_y4ccf3/test_add_kernel.py::test_add[64-128-64-128-float16] \u001b[31mFAILED\u001b[0m\u001b[31m [ 16%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_______________________ test_add[64-128-64-128-float16] ________________________\u001b[0m\n",
      "\n",
      "M = 64, N = 128, BLOCK_SIZE_M = 64, BLOCK_SIZE_N = 128, dtype_str = 'float16'\n",
      "request = <FixtureRequest for <Function test_add[64-128-64-128-float16]>>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m'\u001b[39;49;00m\u001b[33mM,N,BLOCK_SIZE_M,BLOCK_SIZE_N,dtype_str\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                             [(\u001b[94m64\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m64\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, dtype_str) \u001b[94mfor\u001b[39;49;00m dtype_str \u001b[95min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mfloat16\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]] +\u001b[90m\u001b[39;49;00m\n",
      "                             [(\u001b[94m128\u001b[39;49;00m, \u001b[94m256\u001b[39;49;00m, \u001b[94m64\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, dtype_str) \u001b[94mfor\u001b[39;49;00m dtype_str \u001b[95min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mfloat16\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]] +\u001b[90m\u001b[39;49;00m\n",
      "                             [(\u001b[94m256\u001b[39;49;00m, \u001b[94m512\u001b[39;49;00m, \u001b[94m64\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, dtype_str) \u001b[94mfor\u001b[39;49;00m dtype_str \u001b[95min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mfloat16\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_add\u001b[39;49;00m(M, N, BLOCK_SIZE_M, BLOCK_SIZE_N, dtype_str, request):\u001b[90m\u001b[39;49;00m\n",
      "        set_seed()\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        dtype = dtype_mapping[dtype_str]\u001b[90m\u001b[39;49;00m\n",
      "        x = torch.randn(M, N, device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "        y = torch.randn(M, N, device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "        output = torch.empty(M, N, device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mgrid\u001b[39;49;00m(meta):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m (triton.cdiv(M, meta[\u001b[33m'\u001b[39;49;00m\u001b[33mBLOCK_SIZE_M\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]), triton.cdiv(N, meta[\u001b[33m'\u001b[39;49;00m\u001b[33mBLOCK_SIZE_N\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       add_kernel[grid](\u001b[90m\u001b[39;49;00m\n",
      "            x, y, output, M, N,\u001b[90m\u001b[39;49;00m\n",
      "            x.stride(\u001b[94m0\u001b[39;49;00m), x.stride(\u001b[94m1\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            y.stride(\u001b[94m0\u001b[39;49;00m), y.stride(\u001b[94m1\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            output.stride(\u001b[94m0\u001b[39;49;00m), output.stride(\u001b[94m1\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            BLOCK_SIZE_M=BLOCK_SIZE_M, BLOCK_SIZE_N=BLOCK_SIZE_N\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mevals/tmpn_y4ccf3/test_add_kernel.py\u001b[0m:186: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/runtime/jit.py\u001b[0m:330: in <lambda>\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mlambda\u001b[39;49;00m *args, **kwargs: \u001b[96mself\u001b[39;49;00m.run(grid=grid, warmup=\u001b[94mFalse\u001b[39;49;00m, *args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/runtime/jit.py\u001b[0m:623: in run\n",
      "    \u001b[0mkernel = \u001b[96mself\u001b[39;49;00m.compile(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/compiler/compiler.py\u001b[0m:273: in compile\n",
      "    \u001b[0mmodule = src.make_ir(options, codegen_fns, module_map, context)\u001b[90m\u001b[39;49;00m\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <triton.compiler.compiler.ASTSource object at 0x7ea0c956f770>\n",
      "options = HIPOptions(num_warps=4, waves_per_eu=1, num_stages=2, num_ctas=1, num_buffers_warp_spec=0, num_consumer_groups=0, reg_...=1, allow_flush_denorm=False, max_num_imprecise_acc_default=0, backend_name='hip', instruction_sched_variant='default')\n",
      "codegen_fns = {'min_dot_size': <function min_dot_size.<locals>.<lambda> at 0x7ea0c94be340>}\n",
      "module_map = {'triton.language.extra.libdevice': <module 'triton.language.extra.hip.libdevice' from '/home/sapmajum/miniconda3/lib/python3.13/site-packages/triton/language/extra/hip/libdevice.py'>}\n",
      "context = <triton._C.libtriton.ir.context object at 0x7ea0ca01b3f0>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake_ir\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, options, codegen_fns, module_map, context):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m ast_to_ttir(\u001b[96mself\u001b[39;49;00m.fn, \u001b[96mself\u001b[39;49;00m, context=context, options=options, codegen_fns=codegen_fns,\u001b[90m\u001b[39;49;00m\n",
      "                           module_map=module_map)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       triton.compiler.errors.UnsupportedLanguageConstruct: at 33:7:\u001b[0m\n",
      "\u001b[1m\u001b[31mE           mask_n = offs_n < N\u001b[0m\n",
      "\u001b[1m\u001b[31mE           mask = mask_m[:, None] & mask_n[None, :]\u001b[0m\n",
      "\u001b[1m\u001b[31mE       \u001b[0m\n",
      "\u001b[1m\u001b[31mE           # Optimize pointer calculations for better memory coalescing\u001b[0m\n",
      "\u001b[1m\u001b[31mE           # Use more efficient broadcasting and stride calculations\u001b[0m\n",
      "\u001b[1m\u001b[31mE           x_ptrs = x_ptr + offs_m[:, None] * stride_xm + offs_n[None, :] * stride_xn\u001b[0m\n",
      "\u001b[1m\u001b[31mE           y_ptrs = y_ptr + offs_m[:, None] * stride_ym + offs_n[None, :] * stride_yn\u001b[0m\n",
      "\u001b[1m\u001b[31mE           output_ptrs = output_ptr + offs_m[:, None] * stride_om + offs_n[None, :] * stride_on\u001b[0m\n",
      "\u001b[1m\u001b[31mE       \u001b[0m\n",
      "\u001b[1m\u001b[31mE           # Optimize for contiguous memory access when possible\u001b[0m\n",
      "\u001b[1m\u001b[31mE           # For row-major matrices with unit stride in the inner dimension\u001b[0m\n",
      "\u001b[1m\u001b[31mE           if stride_xn == 1 and stride_yn == 1 and stride_on == 1:\u001b[0m\n",
      "\u001b[1m\u001b[31mE              ^\u001b[0m\n",
      "\u001b[1m\u001b[31mE       chained boolean operators (A or B or C) are not supported; use parentheses to split the chain.\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/compiler/compiler.py\u001b[0m:100: UnsupportedLanguageConstruct\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m evals/tmpn_y4ccf3/test_add_kernel.py::\u001b[1mtest_add[64-128-64-128-float16]\u001b[0m - triton.compiler.errors.UnsupportedLanguageConstruct: at 33:7:\n",
      "\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "\u001b[31m====================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m130 deselected\u001b[0m\u001b[31m in 2.23s\u001b[0m\u001b[31m =======================\u001b[0m\n",
      "\n",
      ", safety_validation={'success': False, 'error': \"Correctness tests failed (exit 1):\\nSTDOUT: \\x1b[1m============================= test session starts ==============================\\x1b[0m\\nplatform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\\ncachedir: .pytest_cache\\nrootdir: /home/sapmajum/neurips/geak-openevolve\\nconfigfile: pyproject.toml\\nplugins: timeout-2.4.0, anyio-4.11.0\\n\\x1b[1mcollecting ... \\x1b[0mcollected 136 items / 130 deselected / 6 selected\\n\\nevals/tmpn_y4ccf3/test_add_kernel.py::test_add[64-128-64-128-float16] \\x1b[31mFAILED\\x1b[0m\\x1b[31m [ 16%]\\x1b[0m\\n\\n=================================== FAILURES ===================================\\n\\x1b[31m\\x1b[1m_______________________ test_add[64-128-64-128-float16] ________________________\\x1b[0m\\n\\nM = 64, N = 128, BLOCK_SIZE_M = 64, BLOCK_SIZE_N = 128, dtype_str = 'float16'\\nrequest = <FixtureRequest for <Function test_add[64-128-64-128-float16]>>\\n\\n    \\x1b[0m\\x1b[37m@pytest\\x1b[39;49;00m.mark.parametrize(\\x1b[33m'\\x1b[39;49;00m\\x1b[33mM,N,BLOCK_SIZE_M,BLOCK_SIZE_N,dtype_str\\x1b[39;49;00m\\x1b[33m'\\x1b[39;49;00m,\\x1b[90m\\x1b[39;49;00m\\n                             [(\\x1b[94m64\\x1b[39;49;00m, \\x1b[94m128\\x1b[39;49;00m, \\x1b[94m64\\x1b[39;49;00m, \\x1b[94m128\\x1b[39;49;00m, dtype_str) \\x1b[94mfor\\x1b[39;49;00m dtype_str \\x1b[95min\\x1b[39;49;00m [\\x1b[33m'\\x1b[39;49;00m\\x1b[33mfloat16\\x1b[39;49;00m\\x1b[33m'\\x1b[39;49;00m, \\x1b[33m'\\x1b[39;49;00m\\x1b[33mfloat32\\x1b[39;49;00m\\x1b[33m'\\x1b[39;49;00m]] +\\x1b[90m\\x1b[39;49;00m\\n                             [(\\x1b[94m128\\x1b[39;49;00m, \\x1b[94m256\\x1b[39;49;00m, \\x1b[94m64\\x1b[39;49;00m, \\x1b[94m128\\x1b[39;49;00m, dtype_str) \\x1b[94mfor\\x1b[39;49;00m dtype_str \\x1b[95min\\x1b[39;49;00m [\\x1b[33m'\\x1b[39;49;00m\\x1b[33mfloat16\\x1b[39;49;00m\\x1b[33m'\\x1b[39;49;00m, \\x1b[33m'\\x1b[39;49;00m\\x1b[33mfloat32\\x1b[39;49;00m\\x1b[33m'\\x1b[39;49;00m]] +\\x1b[90m\\x1b[39;49;00m\\n                             [(\\x1b[94m256\\x1b[39;49;00m, \\x1b[94m512\\x1b[39;49;00m, \\x1b[94m64\\x1b[39;49;00m, \\x1b[94m128\\x1b[39;49;00m, dtype_str) \\x1b[94mfor\\x1b[39;49;00m dtype_str \\x1b[95min\\x1b[39;49;00m [\\x1b[33m'\\x1b[39;49;00m\\x1b[33mfloat16\\x1b[39;49;00m\\x1b[33m'\\x1b[39;49;00m, \\x1b[33m'\\x1b[39;49;00m\\x1b[33mfloat32\\x1b[39;49;00m\\x1b[33m'\\x1b[39;49;00m]])\\x1b[90m\\x1b[39;49;00m\\n    \\x1b[94mdef\\x1b[39;49;00m\\x1b[90m \\x1b[39;49;00m\\x1b[92mtest_add\\x1b[39;49;00m(M, N, BLOCK_SIZE_M, BLOCK_SIZE_N, dtype_str, request):\\x1b[90m\\x1b[39;49;00m\\n        set_seed()\\x1b[90m\\x1b[39;49;00m\\n    \\x1b[90m\\x1b[39;49;00m\\n        dtype = dtype_mapping[dtype_str]\\x1b[90m\\x1b[39;49;00m\\n        x = torch.randn(M, N, device=\\x1b[33m'\\x1b[39;49;00m\\x1b[33mcuda\\x1b[39;49;00m\\x1b[33m'\\x1b[39;49;00m, dtype=dtype)\\x1b[90m\\x1b[39;49;00m\\n        y = torch.randn(M, N, device=\\x1b[33m'\\x1b[39;49;00m\\x1b[33mcuda\\x1b[39;49;00m\\x1b[33m'\\x1b[39;49;00m, dtype=dtype)\\x1b[90m\\x1b[39;49;00m\\n        output = torch.empty(M, N, device=\\x1b[33m'\\x1b[39;49;00m\\x1b[33mcuda\\x1b[39;49;00m\\x1b[33m'\\x1b[39;49;00m, dtype=dtype)\\x1b[90m\\x1b[39;49;00m\\n    \\x1b[90m\\x1b[39;49;00m\\n        \\x1b[94mdef\\x1b[39;49;00m\\x1b[90m \\x1b[39;49;00m\\x1b[92mgrid\\x1b[39;49;00m(meta):\\x1b[90m\\x1b[39;49;00m\\n            \\x1b[94mreturn\\x1b[39;49;00m (triton.cdiv(M, meta[\\x1b[33m'\\x1b[39;49;00m\\x1b[33mBLOCK_SIZE_M\\x1b[39;49;00m\\x1b[33m'\\x1b[39;49;00m]), triton.cdiv(N, meta[\\x1b[33m'\\x1b[39;49;00m\\x1b[33mBLOCK_SIZE_N\\x1b[39;49;00m\\x1b[33m'\\x1b[39;49;00m]))\\x1b[90m\\x1b[39;49;00m\\n    \\x1b[90m\\x1b[39;49;00m\\n>       add_kernel[grid](\\x1b[90m\\x1b[39;49;00m\\n            x, y, output, M, N,\\x1b[90m\\x1b[39;49;00m\\n            x.stride(\\x1b[94m0\\x1b[39;49;00m), x.stride(\\x1b[94m1\\x1b[39;49;00m),\\x1b[90m\\x1b[39;49;00m\\n            y.stride(\\x1b[94m0\\x1b[39;49;00m), y.stride(\\x1b[94m1\\x1b[39;49;00m),\\x1b[90m\\x1b[39;49;00m\\n            output.stride(\\x1b[94m0\\x1b[39;49;00m), output.stride(\\x1b[94m1\\x1b[39;49;00m),\\x1b[90m\\x1b[39;49;00m\\n            BLOCK_SIZE_M=BLOCK_SIZE_M, BLOCK_SIZE_N=BLOCK_SIZE_N\\x1b[90m\\x1b[39;49;00m\\n        )\\x1b[90m\\x1b[39;49;00m\\n\\n\\x1b[1m\\x1b[31mevals/tmpn_y4ccf3/test_add_kernel.py\\x1b[0m:186: \\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \\n\\x1b[1m\\x1b[31m../../../miniconda3/lib/python3.13/site-packages/triton/runtime/jit.py\\x1b[0m:330: in <lambda>\\n    \\x1b[0m\\x1b[94mreturn\\x1b[39;49;00m \\x1b[94mlambda\\x1b[39;49;00m *args, **kwargs: \\x1b[96mself\\x1b[39;49;00m.run(grid=grid, warmup=\\x1b[94mFalse\\x1b[39;49;00m, *args, **kwargs)\\x1b[90m\\x1b[39;49;00m\\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\x1b[90m\\x1b[39;49;00m\\n\\x1b[1m\\x1b[31m../../../miniconda3/lib/python3.13/site-packages/triton/runtime/jit.py\\x1b[0m:623: in run\\n    \\x1b[0mkernel = \\x1b[96mself\\x1b[39;49;00m.compile(\\x1b[90m\\x1b[39;49;00m\\n\\x1b[1m\\x1b[31m../../../miniconda3/lib/python3.13/site-packages/triton/compiler/compiler.py\\x1b[0m:273: in compile\\n    \\x1b[0mmodule = src.make_ir(options, codegen_fns, module_map, context)\\x1b[90m\\x1b[39;49;00m\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\x1b[90m\\x1b[39;49;00m\\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \\n\\nself = <triton.compiler.compiler.ASTSource object at 0x7ea0c956f770>\\noptions = HIPOptions(num_warps=4, waves_per_eu=1, num_stages=2, num_ctas=1, num_buffers_warp_spec=0, num_consumer_groups=0, reg_...=1, allow_flush_denorm=False, max_num_imprecise_acc_default=0, backend_name='hip', instruction_sched_variant='default')\\ncodegen_fns = {'min_dot_size': <function min_dot_size.<locals>.<lambda> at 0x7ea0c94be340>}\\nmodule_map = {'triton.language.extra.libdevice': <module 'triton.language.extra.hip.libdevice' from '/home/sapmajum/miniconda3/lib/python3.13/site-packages/triton/language/extra/hip/libdevice.py'>}\\ncontext = <triton._C.libtriton.ir.context object at 0x7ea0ca01b3f0>\\n\\n    \\x1b[0m\\x1b[94mdef\\x1b[39;49;00m\\x1b[90m \\x1b[39;49;00m\\x1b[92mmake_ir\\x1b[39;49;00m(\\x1b[96mself\\x1b[39;49;00m, options, codegen_fns, module_map, context):\\x1b[90m\\x1b[39;49;00m\\n>       \\x1b[94mreturn\\x1b[39;49;00m ast_to_ttir(\\x1b[96mself\\x1b[39;49;00m.fn, \\x1b[96mself\\x1b[39;49;00m, context=context, options=options, codegen_fns=codegen_fns,\\x1b[90m\\x1b[39;49;00m\\n                           module_map=module_map)\\x1b[90m\\x1b[39;49;00m\\n\\x1b[1m\\x1b[31mE       triton.compiler.errors.UnsupportedLanguageConstruct: at 33:7:\\x1b[0m\\n\\x1b[1m\\x1b[31mE           mask_n = offs_n < N\\x1b[0m\\n\\x1b[1m\\x1b[31mE           mask = mask_m[:, None] & mask_n[None, :]\\x1b[0m\\n\\x1b[1m\\x1b[31mE       \\x1b[0m\\n\\x1b[1m\\x1b[31mE           # Optimize pointer calculations for better memory coalescing\\x1b[0m\\n\\x1b[1m\\x1b[31mE           # Use more efficient broadcasting and stride calculations\\x1b[0m\\n\\x1b[1m\\x1b[31mE           x_ptrs = x_ptr + offs_m[:, None] * stride_xm + offs_n[None, :] * stride_xn\\x1b[0m\\n\\x1b[1m\\x1b[31mE           y_ptrs = y_ptr + offs_m[:, None] * stride_ym + offs_n[None, :] * stride_yn\\x1b[0m\\n\\x1b[1m\\x1b[31mE           output_ptrs = output_ptr + offs_m[:, None] * stride_om + offs_n[None, :] * stride_on\\x1b[0m\\n\\x1b[1m\\x1b[31mE       \\x1b[0m\\n\\x1b[1m\\x1b[31mE           # Optimize for contiguous memory access when possible\\x1b[0m\\n\\x1b[1m\\x1b[31mE           # For row-major matrices with unit stride in the inner dimension\\x1b[0m\\n\\x1b[1m\\x1b[31mE           if stride_xn == 1 and stride_yn == 1 and stride_on == 1:\\x1b[0m\\n\\x1b[1m\\x1b[31mE              ^\\x1b[0m\\n\\x1b[1m\\x1b[31mE       chained boolean operators (A or B or C) are not supported; use parentheses to split the chain.\\x1b[0m\\n\\n\\x1b[1m\\x1b[31m../../../miniconda3/lib/python3.13/site-packages/triton/compiler/compiler.py\\x1b[0m:100: UnsupportedLanguageConstruct\\n\\x1b[36m\\x1b[1m=========================== short test summary info ============================\\x1b[0m\\n\\x1b[31mFAILED\\x1b[0m evals/tmpn_y4ccf3/test_add_kernel.py::\\x1b[1mtest_add[64-128-64-128-float16]\\x1b[0m - triton.compiler.errors.UnsupportedLanguageConstruct: at 33:7:\\n\\x1b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\\x1b[0m\\n\\x1b[31m====================== \\x1b[31m\\x1b[1m1 failed\\x1b[0m, \\x1b[33m130 deselected\\x1b[0m\\x1b[31m in 2.23s\\x1b[0m\\x1b[31m =======================\\x1b[0m\\n\\n\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STDERR: \n",
      "üõ°Ô∏è BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpwumc3at2/test_add_kernel.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpwumc3at2/test_add_kernel.py\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpwumc3at2/test_add_kernel.py -k not (test_performance or test_save)\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp1olrtcz1/test_add_kernel.py -k test_performance or test_save_performance_results\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpwumc3at2/test_add_kernel.py -k test_performance or test_save_performance_results\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 136 items / 7 deselected / 129 selected\n",
      "\n",
      "evals/tmp0guovkxi/test_add_kernel.py::test_performance[64-64-64-64-float16] \u001b[32mPASSED\u001b[0m\u001b[32m \n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp0guovkxi/perf\n",
      "Found 1 JSON files: ['add_kernel_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp0guovkxi/perf/add_kernel_perf.json\n",
      "Performance data structure: ['params', 'ms', 'min_ms', 'max_ms', 'GB/s', 'TFLOPS']\n",
      "Performance: 0.0067ms (from key 'ms')\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Calculated speedup: 0.006900ms / 0.006700ms = 1.0299x\n",
      "üõ°Ô∏è BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpn_y4ccf3/test_add_kernel.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpn_y4ccf3/test_add_kernel.py\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpn_y4ccf3/test_add_kernel.py -k not (test_performance or test_save)\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 136 items / 7 deselected / 129 selected\n",
      "\n",
      "evals/tmpvs36697q/test_add_kernel.py::test_performance[64-64-64-64-float16] \u001b[32mPASSED\u001b[0m\u001b[32m \n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpvs36697q/perf\n",
      "Found 1 JSON files: ['add_kernel_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpvs36697q/perf/add_kernel_perf.json\n",
      "Performance data structure: ['params', 'ms', 'min_ms', 'max_ms', 'GB/s', 'TFLOPS']\n",
      "Performance: 0.0072ms (from key 'ms')\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Calculated speedup: 0.006900ms / 0.007200ms = 0.9583x\n",
      "üõ°Ô∏è BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpft66wgmd/test_add_kernel.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpft66wgmd/test_add_kernel.py\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpft66wgmd/test_add_kernel.py -k not (test_performance or test_save)\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 136 items / 7 deselected / 129 selected\n",
      "\n",
      "evals/tmp1olrtcz1/test_add_kernel.py::test_performance[64-64-64-64-float16] \u001b[32mPASSED\u001b[0m\u001b[32m \n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp1olrtcz1/perf\n",
      "Found 1 JSON files: ['add_kernel_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmp1olrtcz1/perf/add_kernel_perf.json\n",
      "Performance data structure: ['params', 'ms', 'min_ms', 'max_ms', 'GB/s', 'TFLOPS']\n",
      "Performance: 0.0068ms (from key 'ms')\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Calculated speedup: 0.006900ms / 0.006800ms = 1.0147x\n",
      "üõ°Ô∏è BULLETPROOF TRITON KERNEL EVALUATOR (AMD GPU) INITIALISED\n",
      "Using program text from file: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpqip8_or8/test_add_kernel.py\n",
      "Evaluating Triton kernel from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpqip8_or8/test_add_kernel.py\n",
      "Running correctness tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpqip8_or8/test_add_kernel.py -k not (test_performance or test_save)\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 136 items / 7 deselected / 129 selected\n",
      "\n",
      "evals/tmpwumc3at2/test_add_kernel.py::test_performance[64-64-64-64-float16] \u001b[32mPASSED\u001b[0m\u001b[32m \n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpwumc3at2/perf\n",
      "Found 1 JSON files: ['add_kernel_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpwumc3at2/perf/add_kernel_perf.json\n",
      "Performance data structure: ['params', 'ms', 'min_ms', 'max_ms', 'GB/s', 'TFLOPS']\n",
      "Performance: 0.0655ms (from key 'ms')\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Calculated speedup: 0.006900ms / 0.065500ms = 0.1053x\n",
      "Correctness tests failed. Return code: 1\n",
      "STDOUT: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 136 items / 130 deselected / 6 selected\n",
      "\n",
      "evals/tmpn_y4ccf3/test_add_kernel.py::test_add[64-128-64-128-float16] \u001b[31mFAILED\u001b[0m\u001b[31m [ 16%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_______________________ test_add[64-128-64-128-float16] ________________________\u001b[0m\n",
      "\n",
      "M = 64, N = 128, BLOCK_SIZE_M = 64, BLOCK_SIZE_N = 128, dtype_str = 'float16'\n",
      "request = <FixtureRequest for <Function test_add[64-128-64-128-float16]>>\n",
      "\n",
      "    \u001b[0m\u001b[37m@pytest\u001b[39;49;00m.mark.parametrize(\u001b[33m'\u001b[39;49;00m\u001b[33mM,N,BLOCK_SIZE_M,BLOCK_SIZE_N,dtype_str\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "                             [(\u001b[94m64\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, \u001b[94m64\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, dtype_str) \u001b[94mfor\u001b[39;49;00m dtype_str \u001b[95min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mfloat16\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]] +\u001b[90m\u001b[39;49;00m\n",
      "                             [(\u001b[94m128\u001b[39;49;00m, \u001b[94m256\u001b[39;49;00m, \u001b[94m64\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, dtype_str) \u001b[94mfor\u001b[39;49;00m dtype_str \u001b[95min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mfloat16\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]] +\u001b[90m\u001b[39;49;00m\n",
      "                             [(\u001b[94m256\u001b[39;49;00m, \u001b[94m512\u001b[39;49;00m, \u001b[94m64\u001b[39;49;00m, \u001b[94m128\u001b[39;49;00m, dtype_str) \u001b[94mfor\u001b[39;49;00m dtype_str \u001b[95min\u001b[39;49;00m [\u001b[33m'\u001b[39;49;00m\u001b[33mfloat16\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfloat32\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]])\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_add\u001b[39;49;00m(M, N, BLOCK_SIZE_M, BLOCK_SIZE_N, dtype_str, request):\u001b[90m\u001b[39;49;00m\n",
      "        set_seed()\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        dtype = dtype_mapping[dtype_str]\u001b[90m\u001b[39;49;00m\n",
      "        x = torch.randn(M, N, device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "        y = torch.randn(M, N, device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "        output = torch.empty(M, N, device=\u001b[33m'\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, dtype=dtype)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mgrid\u001b[39;49;00m(meta):\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m (triton.cdiv(M, meta[\u001b[33m'\u001b[39;49;00m\u001b[33mBLOCK_SIZE_M\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]), triton.cdiv(N, meta[\u001b[33m'\u001b[39;49;00m\u001b[33mBLOCK_SIZE_N\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      ">       add_kernel[grid](\u001b[90m\u001b[39;49;00m\n",
      "            x, y, output, M, N,\u001b[90m\u001b[39;49;00m\n",
      "            x.stride(\u001b[94m0\u001b[39;49;00m), x.stride(\u001b[94m1\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            y.stride(\u001b[94m0\u001b[39;49;00m), y.stride(\u001b[94m1\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            output.stride(\u001b[94m0\u001b[39;49;00m), output.stride(\u001b[94m1\u001b[39;49;00m),\u001b[90m\u001b[39;49;00m\n",
      "            BLOCK_SIZE_M=BLOCK_SIZE_M, BLOCK_SIZE_N=BLOCK_SIZE_N\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mevals/tmpn_y4ccf3/test_add_kernel.py\u001b[0m:186: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/runtime/jit.py\u001b[0m:330: in <lambda>\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[94mlambda\u001b[39;49;00m *args, **kwargs: \u001b[96mself\u001b[39;49;00m.run(grid=grid, warmup=\u001b[94mFalse\u001b[39;49;00m, *args, **kwargs)\u001b[90m\u001b[39;49;00m\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/runtime/jit.py\u001b[0m:623: in run\n",
      "    \u001b[0mkernel = \u001b[96mself\u001b[39;49;00m.compile(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/compiler/compiler.py\u001b[0m:273: in compile\n",
      "    \u001b[0mmodule = src.make_ir(options, codegen_fns, module_map, context)\u001b[90m\u001b[39;49;00m\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <triton.compiler.compiler.ASTSource object at 0x7ea0c956f770>\n",
      "options = HIPOptions(num_warps=4, waves_per_eu=1, num_stages=2, num_ctas=1, num_buffers_warp_spec=0, num_consumer_groups=0, reg_...=1, allow_flush_denorm=False, max_num_imprecise_acc_default=0, backend_name='hip', instruction_sched_variant='default')\n",
      "codegen_fns = {'min_dot_size': <function min_dot_size.<locals>.<lambda> at 0x7ea0c94be340>}\n",
      "module_map = {'triton.language.extra.libdevice': <module 'triton.language.extra.hip.libdevice' from '/home/sapmajum/miniconda3/lib/python3.13/site-packages/triton/language/extra/hip/libdevice.py'>}\n",
      "context = <triton._C.libtriton.ir.context object at 0x7ea0ca01b3f0>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mmake_ir\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, options, codegen_fns, module_map, context):\u001b[90m\u001b[39;49;00m\n",
      ">       \u001b[94mreturn\u001b[39;49;00m ast_to_ttir(\u001b[96mself\u001b[39;49;00m.fn, \u001b[96mself\u001b[39;49;00m, context=context, options=options, codegen_fns=codegen_fns,\u001b[90m\u001b[39;49;00m\n",
      "                           module_map=module_map)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE       triton.compiler.errors.UnsupportedLanguageConstruct: at 33:7:\u001b[0m\n",
      "\u001b[1m\u001b[31mE           mask_n = offs_n < N\u001b[0m\n",
      "\u001b[1m\u001b[31mE           mask = mask_m[:, None] & mask_n[None, :]\u001b[0m\n",
      "\u001b[1m\u001b[31mE       \u001b[0m\n",
      "\u001b[1m\u001b[31mE           # Optimize pointer calculations for better memory coalescing\u001b[0m\n",
      "\u001b[1m\u001b[31mE           # Use more efficient broadcasting and stride calculations\u001b[0m\n",
      "\u001b[1m\u001b[31mE           x_ptrs = x_ptr + offs_m[:, None] * stride_xm + offs_n[None, :] * stride_xn\u001b[0m\n",
      "\u001b[1m\u001b[31mE           y_ptrs = y_ptr + offs_m[:, None] * stride_ym + offs_n[None, :] * stride_yn\u001b[0m\n",
      "\u001b[1m\u001b[31mE           output_ptrs = output_ptr + offs_m[:, None] * stride_om + offs_n[None, :] * stride_on\u001b[0m\n",
      "\u001b[1m\u001b[31mE       \u001b[0m\n",
      "\u001b[1m\u001b[31mE           # Optimize for contiguous memory access when possible\u001b[0m\n",
      "\u001b[1m\u001b[31mE           # For row-major matrices with unit stride in the inner dimension\u001b[0m\n",
      "\u001b[1m\u001b[31mE           if stride_xn == 1 and stride_yn == 1 and stride_on == 1:\u001b[0m\n",
      "\u001b[1m\u001b[31mE              ^\u001b[0m\n",
      "\u001b[1m\u001b[31mE       chained boolean operators (A or B or C) are not supported; use parentheses to split the chain.\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m../../../miniconda3/lib/python3.13/site-packages/triton/compiler/compiler.py\u001b[0m:100: UnsupportedLanguageConstruct\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m evals/tmpn_y4ccf3/test_add_kernel.py::\u001b[1mtest_add[64-128-64-128-float16]\u001b[0m - triton.compiler.errors.UnsupportedLanguageConstruct: at 33:7:\n",
      "\u001b[31m!!!!!!!!!!!!!!!!!!!!!!!!!! stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\n",
      "\u001b[31m====================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[33m130 deselected\u001b[0m\u001b[31m in 2.23s\u001b[0m\u001b[31m =======================\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-26 14:44:18,168 - INFO - Time spent in evaluation: 22.33 seconds\n",
      "2025-11-26 14:44:18,169 - INFO - Evaluated program 9d28b1fd-7edf-4bbc-85ea-5fa4879088ee in 22.33s: success=1.0000, final_score=0.7582, performance_metrics=0.7582, correctness_score=1.0000, combined_score=0.7582, benchmark_results=['Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.009100 ms, speedup: 0.7582x.'], baseline_comparison=Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.009100 ms, speedup: 0.7582x. Speedup=0.7582x (baseline: 0.006900ms, current: 0.009100ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 0.7582x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None\n",
      "2025-11-26 14:44:18,719 - INFO - Time spent in evaluation: 23.89 seconds\n",
      "2025-11-26 14:44:18,719 - INFO - Evaluated program ac399f2a-b1f6-4547-8fc8-bea5bcaadb86 in 23.89s: success=1.0000, final_score=0.9718, performance_metrics=0.9718, correctness_score=1.0000, combined_score=0.9718, benchmark_results=['Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.007100 ms, speedup: 0.9718x.'], baseline_comparison=Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.007100 ms, speedup: 0.9718x. Speedup=0.9718x (baseline: 0.006900ms, current: 0.007100ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 0.9718x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None\n",
      "2025-11-26 14:44:18,719 - INFO - Child programs evaluated in 50.20 seconds\n",
      "2025-11-26 14:44:18,719 - INFO - Updated sampling model 0 with reward 1.0298507462686566\n",
      "2025-11-26 14:44:18,720 - INFO - Updated sampling model 0 with reward 0.9583333333333334\n",
      "2025-11-26 14:44:18,720 - INFO - Updated sampling model 0 with reward 0.0\n",
      "2025-11-26 14:44:18,721 - INFO - Updated sampling model 0 with reward 1.0147058823529411\n",
      "2025-11-26 14:44:18,721 - INFO - Updated sampling model 0 with reward 0.10534351145038168\n",
      "2025-11-26 14:44:18,722 - INFO - Updated sampling model 0 with reward 0.0\n",
      "2025-11-26 14:44:18,722 - INFO - Updated sampling model 0 with reward 0.9718309859154929\n",
      "2025-11-26 14:44:18,723 - INFO - Updated sampling model 0 with reward 0.7582417582417582\n",
      "2025-11-26 14:44:18,723 - INFO - Iteration 3: Child 9d28b1fd-7edf-4bbc-85ea-5fa4879088ee from parent 1de88931-60a8-4b72-adad-e728f58f9e0e in 93.37s. Metrics: success=1.0000, final_score=0.7582, performance_metrics=0.7582, correctness_score=1.0000, combined_score=0.7582, benchmark_results=['Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.009100 ms, speedup: 0.7582x.'], baseline_comparison=Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.009100 ms, speedup: 0.7582x. Speedup=0.7582x (baseline: 0.006900ms, current: 0.009100ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 0.7582x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None (Œî: success=+0.0000, final_score=-0.2716, performance_metrics=-0.2716, correctness_score=+0.0000, combined_score=-0.2716)\n",
      "2025-11-26 14:44:18,723 - INFO - Using tracked best program: 1de88931-60a8-4b72-adad-e728f58f9e0e\n",
      "2025-11-26 14:44:18,723 - INFO - Evolution complete. Best program has metrics: success=1.0000, final_score=1.0299, performance_metrics=1.0299, correctness_score=1.0000, combined_score=1.0299, benchmark_results=['Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.006700 ms, speedup: 1.0299x.'], baseline_comparison=Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.006700 ms, speedup: 1.0299x. Speedup=1.0299x (baseline: 0.006900ms, current: 0.006700ms), individual_comparisons=[], summary=The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 1.0299x compared to the baseline., safety_validation=This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct., error=None\n",
      "2025-11-26 14:44:18,724 - INFO - Saved best program to /home/sapmajum/neurips/geak-openevolve/tutorial/runs/tutorial_run_20251126_143929/best/best_program.py with program info to /home/sapmajum/neurips/geak-openevolve/tutorial/runs/tutorial_run_20251126_143929/best/best_program_info.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STDERR: \n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpft66wgmd/test_add_kernel.py -k test_performance or test_save_performance_results\n",
      "Running performance tests: pytest -v -x --maxfail=1 /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpqip8_or8/test_add_kernel.py -k test_performance or test_save_performance_results\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 136 items / 7 deselected / 129 selected\n",
      "\n",
      "evals/tmpqip8_or8/test_add_kernel.py::test_performance[64-64-64-64-float16] \u001b[32mPASSED\u001b[0m\u001b[32m \n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpqip8_or8/perf\n",
      "Found 1 JSON files: ['add_kernel_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpqip8_or8/perf/add_kernel_perf.json\n",
      "Performance data structure: ['params', 'ms', 'min_ms', 'max_ms', 'GB/s', 'TFLOPS']\n",
      "Performance: 0.0091ms (from key 'ms')\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Calculated speedup: 0.006900ms / 0.009100ms = 0.7582x\n",
      "Performance test result - returncode: 0\n",
      "Performance test stdout: \u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.13.9, pytest-9.0.1, pluggy-1.5.0 -- /home/sapmajum/miniconda3/bin/python3.13\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/sapmajum/neurips/geak-openevolve\n",
      "configfile: pyproject.toml\n",
      "plugins: timeout-2.4.0, anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 136 items / 7 deselected / 129 selected\n",
      "\n",
      "evals/tmpft66wgmd/test_add_kernel.py::test_performance[64-64-64-64-float16] \u001b[32mPASSED\u001b[0m\u001b[32m \n",
      "Performance test stderr: \n",
      "Looking for performance results in: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpft66wgmd/perf\n",
      "Found 1 JSON files: ['add_kernel_perf.json']\n",
      "Reading performance data from: /home/sapmajum/neurips/geak-openevolve/tutorial/evals/tmpft66wgmd/perf/add_kernel_perf.json\n",
      "Performance data structure: ['params', 'ms', 'min_ms', 'max_ms', 'GB/s', 'TFLOPS']\n",
      "Performance: 0.0071ms (from key 'ms')\n",
      "Loaded baseline latency from file: 0.006900ms\n",
      "Calculated speedup: 0.006900ms / 0.007100ms = 0.9718x\n",
      "\n",
      "Evolution complete!\n",
      "Best program metrics:\n",
      "  success: 1.0000\n",
      "  final_score: 1.0299\n",
      "  performance_metrics: 1.0299\n",
      "  correctness_score: 1.0000\n",
      "  combined_score: 1.0299\n",
      "  benchmark_results: ['Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.006700 ms, speedup: 1.0299x.']\n",
      "  baseline_comparison: Performance report: Kernel parameters: SIZE=4096; M=64; N=64; BLOCK_SIZE_RUNTIME=4096; BLOCK_SIZE_M=64; BLOCK_SIZE_N=64; dtype_str=float16, achieved latency: 0.006700 ms, speedup: 1.0299x. Speedup=1.0299x (baseline: 0.006900ms, current: 0.006700ms)\n",
      "  individual_comparisons: []\n",
      "  summary: The Triton kernel was successfully compiled and launched. The Triton kernel produced correct results. The Triton kernel achieved a speedup of 1.0299x compared to the baseline.\n",
      "  safety_validation: This generated Triton kernel was evaluated safely, with no hard crashes or memory violations. The results were correct.\n",
      "  error: None\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Evolution completed successfully!\n",
      "\n",
      "üìä Results saved to: runs/tutorial_run_20251126_143929\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Run OpenEvolve Evolution\n",
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "if not (INITIAL_KERNEL and EVALUATOR_PATH and CONFIG_FILE):\n",
    "    print(\"‚ùå Missing required components!\")\n",
    "    print(f\"   Kernel:    {INITIAL_KERNEL is not None and Path(INITIAL_KERNEL).exists()}\")\n",
    "    print(f\"   Evaluator: {EVALUATOR_PATH is not None and Path(EVALUATOR_PATH).exists()}\")\n",
    "    print(f\"   Config:    {CONFIG_FILE is not None and Path(CONFIG_FILE).exists()}\")\n",
    "else:\n",
    "    command = [\n",
    "        \"openevolve-run\",\n",
    "        str(INITIAL_KERNEL),\n",
    "        str(EVALUATOR_PATH),\n",
    "        \"--config\", str(CONFIG_FILE),\n",
    "        \"--output\", str(OUTPUT_DIR)\n",
    "    ]\n",
    "    \n",
    "    print(\"üöÄ Starting OpenEvolve Evolution...\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"üì¶ Kernel:    {Path(INITIAL_KERNEL).name}\")\n",
    "    print(f\"‚öôÔ∏è  Evaluator: {Path(EVALUATOR_PATH).name}\")\n",
    "    print(f\"üìã Config:    {Path(CONFIG_FILE).name}\")\n",
    "    print(f\"üìÅ Output:    {OUTPUT_DIR.relative_to(TUTORIAL_DIR)}\")\n",
    "    print(f\"üè† Working Dir: {TUTORIAL_DIR}\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n$ cd {TUTORIAL_DIR}\")\n",
    "    print(f\"$ {' '.join(command)}\\n\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # CRITICAL: Run from tutorial directory where evals/ exists\n",
    "    result = subprocess.run(\n",
    "        command, \n",
    "        capture_output=False, \n",
    "        text=True,\n",
    "        cwd=str(TUTORIAL_DIR)  # Run from tutorial directory\n",
    "    )\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    if result.returncode == 0:\n",
    "        print(\"\\n‚úÖ Evolution completed successfully!\")\n",
    "        print(f\"\\nüìä Results saved to: {OUTPUT_DIR.relative_to(TUTORIAL_DIR)}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Evolution failed with exit code: {result.returncode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487e1254",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddc1001",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b0007e",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
