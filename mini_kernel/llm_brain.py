#!/usr/bin/env python3
"""
LLM Brain - The Intelligence Behind the Mini-Kernel Agent

This module integrates with Claude (via AMD LLM Gateway) to provide:
1. Intelligent bottleneck analysis from profiler output
2. Code generation for optimization strategies
3. Evolutionary optimization (mutation, crossover, selection)

Environment Variables Required:
    MINI_KERNEL_API_KEY: API key for AMD LLM Gateway
    
Optional:
    MINI_KERNEL_API_URL: Custom API URL (default: claude-opus-4-5)

Usage:
    export MINI_KERNEL_API_KEY="your-api-key-here"
    optimizer = AutonomousOptimizer()
    result = optimizer.optimize("/path/to/kernel.py")
"""

import os
import json
import re
import time
import random
import threading
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, field
from pathlib import Path
from datetime import datetime

try:
    import openai
    from tenacity import retry, stop_after_attempt, wait_random_exponential
    HAS_OPENAI = True
except ImportError:
    HAS_OPENAI = False
    print("Warning: openai/tenacity not installed. LLM features disabled.")


@dataclass
class OptimizationCandidate:
    """A candidate optimization generated by the LLM."""
    code: str
    strategy_name: str
    description: str
    expected_improvement: str
    fitness: float = 0.0  # Measured speedup (baseline_time / optimized_time)
    generation: int = 0
    parent_strategies: List[str] = field(default_factory=list)
    
    def __repr__(self):
        return f"Candidate({self.strategy_name}, fitness={self.fitness:.2f}x, gen={self.generation})"


class LLMBrain:
    """
    LLM-powered optimization brain using AMD LLM Gateway.
    
    This is the "thinking" component of the mini-kernel agent that:
    - Analyzes profiler output to understand bottlenecks
    - Generates optimization strategies and code
    - Performs evolutionary optimization (mutation, crossover)
    
    Environment Variables:
        MINI_KERNEL_API_KEY: Required. API key for AMD LLM Gateway
        MINI_KERNEL_API_URL: Optional. API URL (default: claude-opus-4-5 endpoint)
    """
    
    # AMD LLM Gateway configuration
    DEFAULT_API_URL = "https://llm-api.amd.com/AnthropicVertex/deployments/claude-opus-4-5"
    
    def __init__(self, verbose: bool = True):
        self.verbose = verbose
        self.client = None
        self.call_count = 0
        self.total_input_tokens = 0
        self.total_output_tokens = 0
        self._init_client()
        
    def _init_client(self):
        """Initialize OpenAI client for AMD Gateway."""
        if not HAS_OPENAI:
            self._log("‚ö†Ô∏è  OpenAI library not available. LLM features disabled.")
            return
        
        # Get API key from environment
        api_key = os.environ.get("MINI_KERNEL_API_KEY")
        if not api_key:
            self._log("=" * 60)
            self._log("‚ö†Ô∏è  MINI_KERNEL_API_KEY environment variable not set!")
            self._log("")
            self._log("Please set your API key:")
            self._log("  export MINI_KERNEL_API_KEY='your-api-key-here'")
            self._log("")
            self._log("You can get an API key from the AMD LLM Gateway.")
            self._log("=" * 60)
            return
        
        # Get API URL (allow override)
        api_url = os.environ.get("MINI_KERNEL_API_URL", self.DEFAULT_API_URL)
        
        self.headers = {
            'Ocp-Apim-Subscription-Key': api_key,
            'Content-Type': 'application/json',
        }
        
        self.client = openai.OpenAI(
            api_key='dummy',
            base_url=api_url,
            default_headers=self.headers
        )
        
        self._log("üß† LLM Brain initialized")
        self._log(f"   Model: Claude Opus 4.5")
        self._log(f"   API Key: {api_key[:8]}...{api_key[-4:]}")
        self._log(f"   Endpoint: {api_url.split('/')[-1]}")
    
    def _log(self, msg: str, indent: int = 0):
        """Log a message if verbose mode is enabled."""
        if self.verbose:
            prefix = "  " * indent
            print(f"{prefix}{msg}")
    
    def _log_llm_call(self, operation: str, prompt_preview: str = None):
        """Log an LLM API call."""
        self.call_count += 1
        timestamp = datetime.now().strftime("%H:%M:%S")
        self._log(f"")
        self._log(f"  ‚îå‚îÄ LLM Call #{self.call_count} [{timestamp}]")
        self._log(f"  ‚îÇ  Operation: {operation}")
        if prompt_preview:
            preview = prompt_preview[:100].replace('\n', ' ')
            self._log(f"  ‚îÇ  Prompt: {preview}...")
    
    def _log_llm_response(self, response_preview: str = None, tokens: int = 0):
        """Log LLM response."""
        self.total_output_tokens += tokens
        if response_preview:
            preview = response_preview[:150].replace('\n', ' ')
            self._log(f"  ‚îÇ  Response: {preview}...")
        self._log(f"  ‚îÇ  Tokens: ~{tokens}")
        self._log(f"  ‚îî‚îÄ Total calls: {self.call_count}")
    
    @retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(3))
    def _call_llm(self, 
                  prompt: str, 
                  system_prompt: str = None,
                  temperature: float = 0.7,
                  max_tokens: int = 8192,
                  operation: str = "unknown") -> str:
        """Call the LLM API with logging."""
        if not self.client:
            return "LLM not available - please set MINI_KERNEL_API_KEY environment variable"
        
        self._log_llm_call(operation, prompt)
        
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": prompt})
        
        try:
            start_time = time.time()
            response = self.client.chat.completions.create(
                model="claude-opus-4-5",
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens,
            )
            elapsed = time.time() - start_time
            
            # Parse Claude response format
            data = response.model_dump()
            result = data['content'][0]["text"]
            
            # Estimate tokens (rough)
            tokens = len(result) // 4
            self._log_llm_response(result, tokens)
            self._log(f"  ‚îÇ  Time: {elapsed:.1f}s")
            
            return result
            
        except Exception as e:
            self._log(f"  ‚îî‚îÄ ‚ö†Ô∏è  LLM API error: {e}")
            raise
    
    def analyze_profiler_output(self, 
                                profiler_output: str,
                                kernel_code: str = None) -> Dict[str, Any]:
        """
        Use LLM to analyze profiler output and identify bottlenecks.
        
        Args:
            profiler_output: Raw output from rocprof-compute
            kernel_code: Optional kernel source code for context
            
        Returns:
            Dict with bottleneck analysis and recommendations
        """
        self._log("")
        self._log("=" * 60)
        self._log("  üîç BOTTLENECK ANALYSIS (LLM)")
        self._log("=" * 60)
        
        system_prompt = """You are an expert GPU performance engineer specializing in AMD MI300X optimization.
Analyze profiler output and identify performance bottlenecks. Be specific and actionable."""

        prompt = f"""Analyze this rocprof-compute profiler output and identify the PRIMARY bottleneck:

=== PROFILER OUTPUT ===
{profiler_output[:8000]}

{"=== KERNEL CODE ===" + chr(10) + kernel_code[:4000] if kernel_code else ""}

Respond in this JSON format:
{{
    "primary_bottleneck": "latency|memory|compute|lds|occupancy|register|balanced",
    "confidence": 0.0-1.0,
    "key_metrics": {{
        "kernel_time_us": <float>,
        "valu_utilization": <float>,
        "vmem_utilization": <float>,
        "occupancy": <float>
    }},
    "analysis": "<1-2 sentence explanation of why this is the bottleneck>",
    "top_3_recommendations": [
        "<specific optimization 1>",
        "<specific optimization 2>",
        "<specific optimization 3>"
    ]
}}

ONLY output the JSON, nothing else."""

        try:
            response = self._call_llm(
                prompt, system_prompt, 
                temperature=0.3,
                operation="Bottleneck Analysis"
            )
            
            # Extract JSON from response
            json_match = re.search(r'\{[\s\S]*\}', response)
            if json_match:
                analysis = json.loads(json_match.group())
                
                # Log the analysis
                self._log("")
                self._log(f"  üìä Analysis Results:")
                self._log(f"     Bottleneck: {analysis.get('primary_bottleneck', 'unknown').upper()}")
                self._log(f"     Confidence: {analysis.get('confidence', 0):.0%}")
                self._log(f"     Reason: {analysis.get('analysis', 'N/A')}")
                self._log(f"")
                self._log(f"  üí° Recommendations:")
                for i, rec in enumerate(analysis.get('top_3_recommendations', []), 1):
                    self._log(f"     {i}. {rec}")
                
                return analysis
            else:
                return {
                    "primary_bottleneck": "balanced",
                    "confidence": 0.5,
                    "analysis": "Could not parse LLM response",
                    "top_3_recommendations": []
                }
                
        except Exception as e:
            self._log(f"  ‚ö†Ô∏è  Analysis failed: {e}")
            return {
                "primary_bottleneck": "balanced",
                "confidence": 0.0,
                "analysis": f"Error: {e}",
                "top_3_recommendations": []
            }
    
    def generate_optimization(self,
                              kernel_code: str,
                              bottleneck: str,
                              profiler_metrics: Dict[str, Any],
                              previous_attempts: List[OptimizationCandidate] = None,
                              strategy_hint: str = None) -> OptimizationCandidate:
        """
        Generate an optimized kernel using LLM.
        
        This is the core "code generation" capability of OpenEvolve.
        
        Args:
            kernel_code: Original kernel source code
            bottleneck: Identified bottleneck type
            profiler_metrics: Metrics from profiler
            previous_attempts: Previous optimization attempts (for evolution)
            strategy_hint: Optional hint for specific strategy to try
            
        Returns:
            OptimizationCandidate with generated code
        """
        gen_num = len(previous_attempts) if previous_attempts else 0
        
        self._log("")
        self._log(f"  üß¨ GENERATING OPTIMIZATION (Gen {gen_num})")
        self._log(f"     Target bottleneck: {bottleneck.upper()}")
        if strategy_hint:
            self._log(f"     Strategy hint: {strategy_hint}")
        
        system_prompt = """You are an expert GPU kernel optimization engineer for AMD MI300X.
Generate optimized Triton/HIP kernel code that addresses the identified bottleneck.
Your code MUST be complete, syntactically correct, and ready to run."""

        # Build context from previous attempts if available
        evolution_context = ""
        if previous_attempts:
            # Show top 3 previous attempts
            sorted_attempts = sorted(previous_attempts, key=lambda x: -x.fitness)[:3]
            evolution_context = "\n=== PREVIOUS ATTEMPTS (learn from these) ===\n"
            for i, attempt in enumerate(sorted_attempts, 1):
                evolution_context += f"\n--- Attempt {i}: {attempt.strategy_name} (fitness: {attempt.fitness:.2f}x) ---\n"
                evolution_context += f"Description: {attempt.description}\n"
                evolution_context += f"Code preview:\n{attempt.code[:1500]}...\n"
            evolution_context += "\nGenerate a DIFFERENT approach or improve on the best one.\n"

        # Strategy-specific guidance
        strategy_guidance = self._get_strategy_guidance(bottleneck)

        prompt = f"""Optimize this GPU kernel to address the {bottleneck.upper()} bottleneck:

=== ORIGINAL KERNEL ===
{kernel_code}

=== PROFILER METRICS ===
{json.dumps(profiler_metrics, indent=2)}

=== BOTTLENECK: {bottleneck.upper()} ===

{strategy_guidance}

{evolution_context}

{"=== SPECIFIC STRATEGY TO TRY ===" + chr(10) + strategy_hint if strategy_hint else ""}

Generate COMPLETE optimized code with a wrapper class that implements the optimization.
Include timing measurement.

Respond in this format:
```python
# STRATEGY: <name of strategy>
# DESCRIPTION: <what this optimization does>
# EXPECTED_IMPROVEMENT: <e.g., "2-3x for latency-bound kernels">

<complete Python code>
```

The code should:
1. Import all necessary modules
2. Define a class with an optimize() method that returns latency in microseconds
3. Include warmup and timing code
4. Be ready to run without modification

ONLY output the code block, nothing else."""

        try:
            response = self._call_llm(
                prompt, system_prompt, 
                temperature=0.7, 
                max_tokens=8192,
                operation=f"Generate Optimization (Gen {gen_num})"
            )
            
            # Extract code and metadata
            code_match = re.search(r'```python\s*([\s\S]*?)```', response)
            if code_match:
                code = code_match.group(1).strip()
            else:
                code = response.strip()
            
            # Extract metadata from comments
            strategy_match = re.search(r'# STRATEGY:\s*(.+)', code)
            desc_match = re.search(r'# DESCRIPTION:\s*(.+)', code)
            improve_match = re.search(r'# EXPECTED_IMPROVEMENT:\s*(.+)', code)
            
            strategy_name = strategy_match.group(1) if strategy_match else f"llm_gen_{gen_num}"
            
            self._log(f"     Generated: {strategy_name}")
            self._log(f"     Code size: {len(code)} chars")
            
            return OptimizationCandidate(
                code=code,
                strategy_name=strategy_name,
                description=desc_match.group(1) if desc_match else "LLM-generated optimization",
                expected_improvement=improve_match.group(1) if improve_match else "unknown",
                generation=gen_num
            )
            
        except Exception as e:
            self._log(f"  ‚ö†Ô∏è  Generation failed: {e}")
            return OptimizationCandidate(
                code="# Generation failed",
                strategy_name="failed",
                description=str(e),
                expected_improvement="none",
                generation=gen_num
            )
    
    def _get_strategy_guidance(self, bottleneck: str) -> str:
        """Get strategy guidance based on bottleneck type."""
        strategies = {
            "latency": """
=== OPTIMIZATION STRATEGIES FOR LATENCY BOTTLENECK ===
- HIP Graph capture to eliminate kernel launch overhead (HIGHLY EFFECTIVE)
- Multi-stream batched graphs for parallel execution
- Kernel fusion to reduce total kernel launches
- Persistent kernels for repeated operations
- Reduce grid/block overhead with larger work per thread
""",
            "memory": """
=== OPTIMIZATION STRATEGIES FOR MEMORY BOTTLENECK ===
- Vectorized loads (float4, int4) for better bandwidth utilization
- Memory coalescing - ensure threads access contiguous memory
- LDS caching for frequently accessed data
- Prefetching to hide memory latency
- Reduce memory traffic by computing values instead of loading
""",
            "compute": """
=== OPTIMIZATION STRATEGIES FOR COMPUTE BOTTLENECK ===
- Block size tuning for better parallelism
- Use MFMA instructions for matrix operations
- Reduce instruction count with strength reduction
- Loop unrolling for better ILP
- Warp-level primitives for reductions
""",
            "occupancy": """
=== OPTIMIZATION STRATEGIES FOR OCCUPANCY BOTTLENECK ===
- Reduce VGPR usage (fewer local variables, reuse registers)
- Reduce LDS per workgroup
- Tune workgroup size for better occupancy
- Split kernel into smaller pieces
""",
            "lds": """
=== OPTIMIZATION STRATEGIES FOR LDS BOTTLENECK ===
- Add padding to reduce bank conflicts
- Reorganize data layout for conflict-free access
- Use warp-level shuffles instead of LDS where possible
""",
        }
        return strategies.get(bottleneck, "")
    
    def mutate_optimization(self,
                            candidate: OptimizationCandidate,
                            mutation_type: str = "parameter") -> OptimizationCandidate:
        """
        Mutate an existing optimization to explore variations.
        
        This implements the "mutation" operation in evolutionary optimization.
        
        Args:
            candidate: The candidate to mutate
            mutation_type: Type of mutation ("parameter", "algorithm", "hybrid")
        """
        self._log("")
        self._log(f"  üîÄ MUTATION: {candidate.strategy_name}")
        self._log(f"     Type: {mutation_type}")
        self._log(f"     Parent fitness: {candidate.fitness:.2f}x")
        
        mutation_prompts = {
            "parameter": "Change numerical parameters (block sizes, batch sizes, stream counts, unroll factors)",
            "algorithm": "Try a different algorithmic approach while keeping the same optimization goal",
            "hybrid": "Add an additional optimization technique to the existing approach"
        }
        
        mutation_instruction = mutation_prompts.get(mutation_type, mutation_prompts["parameter"])
        
        prompt = f"""You are mutating a GPU kernel optimization to explore better solutions.

=== CURRENT OPTIMIZATION (fitness: {candidate.fitness:.2f}x) ===
Strategy: {candidate.strategy_name}
{candidate.code}

=== MUTATION TYPE: {mutation_type.upper()} ===
{mutation_instruction}

Make ONE significant change to potentially improve performance.
Keep the same general structure but make a meaningful variation.

Output the mutated code in the same format:
```python
# STRATEGY: {candidate.strategy_name}_mut_{mutation_type}
# DESCRIPTION: <what changed from parent>
# EXPECTED_IMPROVEMENT: <expected result>

<mutated code>
```"""

        try:
            response = self._call_llm(
                prompt, 
                temperature=0.8, 
                max_tokens=8192,
                operation=f"Mutation ({mutation_type})"
            )
            
            code_match = re.search(r'```python\s*([\s\S]*?)```', response)
            if code_match:
                code = code_match.group(1).strip()
            else:
                code = response.strip()
            
            strategy_match = re.search(r'# STRATEGY:\s*(.+)', code)
            desc_match = re.search(r'# DESCRIPTION:\s*(.+)', code)
            
            new_name = strategy_match.group(1) if strategy_match else f"{candidate.strategy_name}_mut"
            
            self._log(f"     Result: {new_name}")
            
            return OptimizationCandidate(
                code=code,
                strategy_name=new_name,
                description=desc_match.group(1) if desc_match else f"Mutation of {candidate.strategy_name}",
                expected_improvement="mutation",
                generation=candidate.generation + 1,
                parent_strategies=[candidate.strategy_name]
            )
            
        except Exception as e:
            self._log(f"     ‚ö†Ô∏è  Mutation failed: {e}")
            return candidate  # Return original if mutation fails
    
    def crossover_optimizations(self,
                                parent1: OptimizationCandidate,
                                parent2: OptimizationCandidate) -> OptimizationCandidate:
        """
        Combine two optimizations to create a hybrid.
        
        This implements the "crossover" operation in evolutionary optimization.
        The LLM intelligently combines the best aspects of both parents.
        """
        self._log("")
        self._log(f"  üß¨ CROSSOVER")
        self._log(f"     Parent 1: {parent1.strategy_name} (fitness: {parent1.fitness:.2f}x)")
        self._log(f"     Parent 2: {parent2.strategy_name} (fitness: {parent2.fitness:.2f}x)")
        
        prompt = f"""You are combining two GPU kernel optimizations to create a hybrid solution.

=== PARENT 1 (fitness: {parent1.fitness:.2f}x) ===
Strategy: {parent1.strategy_name}
Description: {parent1.description}
{parent1.code[:3000]}

=== PARENT 2 (fitness: {parent2.fitness:.2f}x) ===
Strategy: {parent2.strategy_name}
Description: {parent2.description}
{parent2.code[:3000]}

=== CROSSOVER INSTRUCTIONS ===
Create a new optimization that combines the best aspects of both parents:
- Take the most effective technique from each
- Ensure they work together correctly
- Handle any conflicts between approaches
- The hybrid should potentially outperform both parents

Output the hybrid code:
```python
# STRATEGY: hybrid_{parent1.strategy_name.split('_')[0]}_{parent2.strategy_name.split('_')[0]}
# DESCRIPTION: <what techniques were combined>
# EXPECTED_IMPROVEMENT: <expected result>

<hybrid code>
```"""

        try:
            response = self._call_llm(
                prompt, 
                temperature=0.7, 
                max_tokens=8192,
                operation="Crossover"
            )
            
            code_match = re.search(r'```python\s*([\s\S]*?)```', response)
            if code_match:
                code = code_match.group(1).strip()
            else:
                code = response.strip()
            
            strategy_match = re.search(r'# STRATEGY:\s*(.+)', code)
            desc_match = re.search(r'# DESCRIPTION:\s*(.+)', code)
            
            new_name = strategy_match.group(1) if strategy_match else "hybrid"
            
            self._log(f"     Result: {new_name}")
            
            return OptimizationCandidate(
                code=code,
                strategy_name=new_name,
                description=desc_match.group(1) if desc_match else f"Hybrid of {parent1.strategy_name} and {parent2.strategy_name}",
                expected_improvement="hybrid",
                generation=max(parent1.generation, parent2.generation) + 1,
                parent_strategies=[parent1.strategy_name, parent2.strategy_name]
            )
            
        except Exception as e:
            self._log(f"     ‚ö†Ô∏è  Crossover failed: {e}")
            # Return better parent if crossover fails
            return parent1 if parent1.fitness >= parent2.fitness else parent2
    
    def get_stats(self) -> Dict[str, Any]:
        """Get LLM usage statistics."""
        return {
            "total_calls": self.call_count,
            "estimated_tokens": self.total_output_tokens,
        }


class OpenEvolveBrain:
    """
    OpenEvolve-style evolutionary optimizer using LLM.
    
    This implements a genetic algorithm for kernel optimization:
    
    1. INITIALIZATION: Generate initial population of optimization strategies
    2. EVALUATION: Run each strategy and measure fitness (speedup)
    3. SELECTION: Keep the best performing strategies
    4. EVOLUTION: Create new strategies via:
       - MUTATION: Modify parameters/algorithm of good strategies
       - CROSSOVER: Combine two good strategies into a hybrid
    5. REPEAT: Until target speedup achieved or max generations
    
    The key insight is that the LLM acts as an intelligent mutation/crossover
    operator that understands GPU optimization, rather than random mutations.
    """
    
    def __init__(self, 
                 population_size: int = 5,
                 generations: int = 10,
                 mutation_rate: float = 0.3,
                 crossover_rate: float = 0.2,
                 elitism: int = 1,
                 verbose: bool = True):
        """
        Initialize OpenEvolve optimizer.
        
        Args:
            population_size: Number of candidates per generation
            generations: Maximum evolution generations
            mutation_rate: Probability of mutation (0-1)
            crossover_rate: Probability of crossover (0-1)
            elitism: Number of best candidates to always keep
            verbose: Enable detailed logging
        """
        self.population_size = population_size
        self.generations = generations
        self.mutation_rate = mutation_rate
        self.crossover_rate = crossover_rate
        self.elitism = elitism
        self.verbose = verbose
        self.llm = LLMBrain(verbose=verbose)
        
        # Evolution history
        self.history = []
        
    def _log(self, msg: str):
        if self.verbose:
            print(msg)
    
    def evolve(self,
               kernel_code: str,
               bottleneck: str,
               profiler_metrics: Dict[str, Any],
               evaluate_fn,  # Function: code -> fitness (speedup)
               baseline_time_us: float,
               target_fitness: float = 1.5) -> OptimizationCandidate:
        """
        Run evolutionary optimization to find best kernel optimization.
        
        Args:
            kernel_code: Original kernel code
            bottleneck: Identified bottleneck type
            profiler_metrics: Profiler metrics dict
            evaluate_fn: Function that takes code and returns fitness (speedup)
            baseline_time_us: Baseline kernel time in microseconds
            target_fitness: Target speedup to achieve (e.g., 1.5 = 50% faster)
            
        Returns:
            Best optimization candidate found
        """
        self._log("")
        self._log("‚ïî" + "‚ïê" * 58 + "‚ïó")
        self._log("‚ïë" + "  üß¨ OPENEVOLVE OPTIMIZATION".center(58) + "‚ïë")
        self._log("‚ïö" + "‚ïê" * 58 + "‚ïù")
        self._log("")
        self._log(f"  Configuration:")
        self._log(f"    Population size: {self.population_size}")
        self._log(f"    Max generations: {self.generations}")
        self._log(f"    Mutation rate:   {self.mutation_rate:.0%}")
        self._log(f"    Crossover rate:  {self.crossover_rate:.0%}")
        self._log(f"    Elitism:         {self.elitism}")
        self._log("")
        self._log(f"  Target:")
        self._log(f"    Baseline:        {baseline_time_us:.2f} Œºs")
        self._log(f"    Target speedup:  {target_fitness:.2f}x")
        self._log(f"    Target time:     {baseline_time_us/target_fitness:.2f} Œºs")
        self._log("")
        
        # =====================================================================
        # PHASE 1: Initialize Population
        # =====================================================================
        self._log("=" * 60)
        self._log("  PHASE 1: INITIALIZE POPULATION")
        self._log("=" * 60)
        
        population = []
        
        # Generate diverse initial strategies
        strategy_hints = self._get_initial_strategies(bottleneck)
        
        for i in range(self.population_size):
            hint = strategy_hints[i % len(strategy_hints)] if strategy_hints else None
            
            self._log(f"\n  [Candidate {i+1}/{self.population_size}]")
            
            candidate = self.llm.generate_optimization(
                kernel_code, bottleneck, profiler_metrics,
                previous_attempts=population,
                strategy_hint=hint
            )
            
            # Evaluate fitness
            self._log(f"     Evaluating...")
            try:
                candidate.fitness = evaluate_fn(candidate.code)
                self._log(f"     ‚úì Fitness: {candidate.fitness:.2f}x speedup")
            except Exception as e:
                candidate.fitness = 0.0
                self._log(f"     ‚úó Evaluation failed: {e}")
            
            population.append(candidate)
            self.history.append({
                "generation": 0,
                "candidate": candidate.strategy_name,
                "fitness": candidate.fitness,
                "operation": "init"
            })
            
            # Early exit if we hit target
            if candidate.fitness >= target_fitness:
                self._log(f"\n  üéØ TARGET ACHIEVED in initialization!")
                self._print_final_report(candidate, baseline_time_us)
                return candidate
        
        # =====================================================================
        # PHASE 2: Evolution Loop
        # =====================================================================
        self._log("")
        self._log("=" * 60)
        self._log("  PHASE 2: EVOLUTION")
        self._log("=" * 60)
        
        best_ever = max(population, key=lambda x: x.fitness)
        
        for gen in range(self.generations):
            self._log("")
            self._log(f"  ‚îå‚îÄ Generation {gen + 1}/{self.generations} " + "‚îÄ" * 35)
            self._log(f"  ‚îÇ  Best so far: {best_ever.strategy_name} ({best_ever.fitness:.2f}x)")
            
            new_population = []
            
            # Elitism: Keep best candidates
            sorted_pop = sorted(population, key=lambda x: -x.fitness)
            for i in range(min(self.elitism, len(sorted_pop))):
                new_population.append(sorted_pop[i])
                self._log(f"  ‚îÇ  [Elite] {sorted_pop[i].strategy_name} ({sorted_pop[i].fitness:.2f}x)")
            
            # Generate new candidates
            candidate_num = len(new_population)
            while len(new_population) < self.population_size:
                candidate_num += 1
                op = random.random()
                
                if op < self.crossover_rate and len(population) >= 2:
                    # CROSSOVER: Combine two parents
                    self._log(f"  ‚îÇ")
                    self._log(f"  ‚îÇ  [Candidate {candidate_num}] Crossover")
                    
                    # Tournament selection for parents
                    parents = self._tournament_select(population, 2)
                    candidate = self.llm.crossover_optimizations(parents[0], parents[1])
                    operation = "crossover"
                    
                elif op < self.crossover_rate + self.mutation_rate:
                    # MUTATION: Modify existing candidate
                    self._log(f"  ‚îÇ")
                    self._log(f"  ‚îÇ  [Candidate {candidate_num}] Mutation")
                    
                    parent = self._tournament_select(population, 1)[0]
                    mutation_type = random.choice(["parameter", "algorithm", "hybrid"])
                    candidate = self.llm.mutate_optimization(parent, mutation_type)
                    operation = f"mutation_{mutation_type}"
                    
                else:
                    # NEW: Generate fresh candidate
                    self._log(f"  ‚îÇ")
                    self._log(f"  ‚îÇ  [Candidate {candidate_num}] New Generation")
                    
                    candidate = self.llm.generate_optimization(
                        kernel_code, bottleneck, profiler_metrics,
                        previous_attempts=population
                    )
                    operation = "new"
                
                # Evaluate
                self._log(f"  ‚îÇ     Evaluating...")
                try:
                    candidate.fitness = evaluate_fn(candidate.code)
                    self._log(f"  ‚îÇ     ‚úì Fitness: {candidate.fitness:.2f}x")
                except Exception as e:
                    candidate.fitness = 0.0
                    self._log(f"  ‚îÇ     ‚úó Failed: {str(e)[:50]}")
                
                new_population.append(candidate)
                self.history.append({
                    "generation": gen + 1,
                    "candidate": candidate.strategy_name,
                    "fitness": candidate.fitness,
                    "operation": operation
                })
                
                # Update best
                if candidate.fitness > best_ever.fitness:
                    best_ever = candidate
                    self._log(f"  ‚îÇ     ‚≠ê NEW BEST!")
                
                # Early exit
                if candidate.fitness >= target_fitness:
                    self._log(f"  ‚îÇ")
                    self._log(f"  ‚îî‚îÄ üéØ TARGET ACHIEVED!")
                    self._print_final_report(candidate, baseline_time_us)
                    return candidate
            
            population = new_population
            
            # Generation summary
            gen_best = max(population, key=lambda x: x.fitness)
            gen_avg = sum(c.fitness for c in population) / len(population)
            self._log(f"  ‚îÇ")
            self._log(f"  ‚îÇ  Generation Summary:")
            self._log(f"  ‚îÇ    Best:    {gen_best.fitness:.2f}x ({gen_best.strategy_name})")
            self._log(f"  ‚îÇ    Average: {gen_avg:.2f}x")
            self._log(f"  ‚îî‚îÄ" + "‚îÄ" * 50)
        
        # =====================================================================
        # PHASE 3: Final Report
        # =====================================================================
        self._print_final_report(best_ever, baseline_time_us)
        
        return best_ever
    
    def _tournament_select(self, population: List[OptimizationCandidate], n: int) -> List[OptimizationCandidate]:
        """Select n candidates using tournament selection."""
        selected = []
        for _ in range(n):
            # Tournament of 3
            tournament = random.sample(population, min(3, len(population)))
            winner = max(tournament, key=lambda x: x.fitness)
            selected.append(winner)
        return selected
    
    def _get_initial_strategies(self, bottleneck: str) -> List[str]:
        """Get diverse initial strategy hints based on bottleneck."""
        strategies = {
            "latency": [
                "HIP Graph capture to eliminate launch overhead",
                "Multi-stream batched graph execution",
                "Kernel fusion with adjacent operations",
                "Persistent kernel pattern",
                "Increase work per thread to amortize launch cost"
            ],
            "memory": [
                "Vectorized loads using float4",
                "Memory coalescing optimization",
                "LDS caching for reused data",
                "Prefetching with async copy",
                "Reduce memory traffic by recomputing"
            ],
            "compute": [
                "Block size tuning for occupancy",
                "MFMA instruction utilization",
                "Loop unrolling for ILP",
                "Warp-level primitives",
                "Strength reduction"
            ],
            "occupancy": [
                "Reduce VGPR usage",
                "Reduce LDS per workgroup",
                "Workgroup size tuning",
                "Register spilling optimization"
            ],
            "lds": [
                "Bank conflict reduction with padding",
                "Warp shuffle instead of LDS",
                "Data layout reorganization"
            ],
            "balanced": [
                "HIP Graph capture",
                "Block size tuning",
                "Memory coalescing",
                "Vectorized operations"
            ]
        }
        return strategies.get(bottleneck, strategies["balanced"])
    
    def _print_final_report(self, best: OptimizationCandidate, baseline_us: float):
        """Print final optimization report."""
        self._log("")
        self._log("‚ïî" + "‚ïê" * 58 + "‚ïó")
        self._log("‚ïë" + "  üèÅ OPTIMIZATION COMPLETE".center(58) + "‚ïë")
        self._log("‚ïö" + "‚ïê" * 58 + "‚ïù")
        self._log("")
        self._log(f"  Best Solution:")
        self._log(f"    Strategy:    {best.strategy_name}")
        self._log(f"    Generation:  {best.generation}")
        self._log(f"    Fitness:     {best.fitness:.2f}x speedup")
        self._log(f"")
        self._log(f"  Performance:")
        self._log(f"    Baseline:    {baseline_us:.2f} Œºs")
        if best.fitness > 0:
            self._log(f"    Optimized:   {baseline_us/best.fitness:.2f} Œºs")
            self._log(f"    Improvement: {(best.fitness-1)*100:.1f}%")
        else:
            self._log(f"    Optimized:   N/A (evaluation failed)")
            self._log(f"    Improvement: 0% (try different strategies)")
        self._log("")
        
        if best.parent_strategies:
            self._log(f"  Lineage: {' ‚Üí '.join(best.parent_strategies)} ‚Üí {best.strategy_name}")
            self._log("")
        
        # LLM stats
        stats = self.llm.get_stats()
        self._log(f"  LLM Usage:")
        self._log(f"    Total calls: {stats['total_calls']}")
        self._log(f"    Est. tokens: {stats['estimated_tokens']}")
        self._log("")
        self._log("=" * 60)
    
    def get_evolution_history(self) -> List[Dict]:
        """Get the full evolution history."""
        return self.history


# Convenience function for quick optimization
def optimize_with_llm(kernel_path: str,
                      profiler_output: str,
                      evaluate_fn,
                      baseline_time_us: float,
                      target_speedup: float = 1.5,
                      generations: int = 5,
                      population_size: int = 3) -> OptimizationCandidate:
    """
    Quick optimization using LLM brain.
    
    Args:
        kernel_path: Path to kernel file
        profiler_output: Raw profiler output
        evaluate_fn: Function to evaluate candidates (code -> speedup)
        baseline_time_us: Baseline time in microseconds
        target_speedup: Target speedup
        generations: Number of evolution generations
        population_size: Candidates per generation
        
    Returns:
        Best optimization candidate
    """
    kernel_code = Path(kernel_path).read_text()
    
    # Analyze bottleneck
    llm = LLMBrain()
    analysis = llm.analyze_profiler_output(profiler_output, kernel_code)
    
    bottleneck = analysis.get("primary_bottleneck", "balanced")
    metrics = analysis.get("key_metrics", {})
    
    # Run evolution
    evolver = OpenEvolveBrain(
        population_size=population_size,
        generations=generations,
        verbose=True
    )
    
    return evolver.evolve(
        kernel_code=kernel_code,
        bottleneck=bottleneck,
        profiler_metrics=metrics,
        evaluate_fn=evaluate_fn,
        baseline_time_us=baseline_time_us,
        target_fitness=target_speedup
    )


if __name__ == "__main__":
    # Test LLM connectivity
    print("Testing LLM Brain connectivity...")
    print()
    print("Make sure to set your API key:")
    print("  export MINI_KERNEL_API_KEY='your-api-key-here'")
    print()
    
    brain = LLMBrain()
    
    if brain.client:
        # Test simple call
        test_prompt = "Say 'Hello from Claude!' in exactly those words."
        response = brain._call_llm(test_prompt, temperature=0.0, max_tokens=50, operation="Test")
        print(f"\nResponse: {response}")
        
        # Print stats
        print(f"\nStats: {brain.get_stats()}")
    else:
        print("LLM not initialized. Please set MINI_KERNEL_API_KEY.")
